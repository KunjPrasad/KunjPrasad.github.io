<!--
    HTML book section: Entity in 1-way interaction to Productionizing Backend Development, by Kunj Prasad on Github.
    Copyright (C) 2020  Kunj Prasad

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published
    by the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-->
<article>
	<aside class="shown-individually-but-hidden-in-ebook"><i><strong>Read it in ebook <a href="/productionizing/productionizing-backend-development/#1609472905">here</a></strong></i></aside>
	<h2>Entity</h2>
	<p id="1610064998">As mentioned in the <a href="#1611510000" data-nav-id="1611200362">schema section</a> of the data storage glossary, the initial steps in database design involves creating the conceptual design, followed by logical design. Techniques from domain driven design and database normalization is applied in doing so. In current software landscape, it is very likely that an <a href="#1609290898" data-nav-id="1608344385">object-oriented paradigm</a> is used for the development of backend code for the business application. In this paradigm, the database tables in the logical design maps to a class, and a row in the table maps to an object of corresponding class. This object is called as an Entity or a Model (also see <a href="https://stackoverflow.com/questions/2550197/whats-the-difference-between-entity-and-class" target="_blank">this question on StackOverflow</a>). The mapping between an entity and a database table row, allowing an object to be saved as a row, and for a row to be read and converted to an object is achieved through use of software called an <a href="https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping" target="_blank">object-relational mapping tool, or an ORM</a>.  When working on a backend application, it is strongly preferred to use a database and framework with ORM support. Fortunately, this support is already available in commonly used frameworks. <strong>For purpose of this ebook, it is assumed that the backend application is developed using a programming language and a framework that provides ORM support.</strong></p>
	<p id="1610065800">A quick side note: Database froms an important part of backend development. Database related concerns are covered in more depth in a separate ebook: <a href="/productionizing/productionizing-database-schema" target="_blank">Productionizing Database Schema</a>. Readers are suggested to refer it as needed. The topics covered in this book are not dependent on conent of "Productionizing Database Schema" e-book. So, readers can refer it after finishing this e-book.</p>
	
	<h3>Using domain driven design</h3>
	<p id="1612753728">As mentioned in the <a href="#1611510000" data-nav-id="1611200362">schema section</a>, domain driven design is applied when forming the conceptual model. In context of the "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" section of the example application, realize that a "user" is central to all applications. This is a top-level domain. One sub-domain for the application is banking service, like, creating an account, depositing or withdrawing money from the account. Another sub-domain is optional life-insurance service. <strong>Domain driven design suggests that the database tables and corresponding entities made to for an application domain are bounded to that context alone (see <a href="https://martinfowler.com/bliki/BoundedContext.html" target="_blank">Bounded context</a>) and must not get shared with other domains.</strong> When designing the entities and database table, this means that "bank account" entity must not directly have insurance details in one of its columns, nor should it have a foreign key to entry in the insurance table; And same consideration also applies for the insurance table.</p>
	<p id="1613440831">Here's something to think: The "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" says "All account holders are given an option to buy additional life insurance...". Can there be users who are not account holders? For example, administrative staff at bank. Let's say they are not required to have a bank account, i.e. the bank is not forcing its employees to open an account with it. Can these employees also apply for insurance? And why is this being mentioned when the requirement doesn't mention anything about non-account-holding users? Two reasons: (1) to highlight that as part of software development, it is necessary to clarify requirements. What is provided as requirements need not be the final thing and it can still change; And, (2) to highlight that if this is something that can never happen, then an alternate, equally possible design could be to define our top level domain to be "bank account" which joins together the "user" data along with the "bank account" data because doing so is not prohibited by the requirements. We can as well add insurance information in the same domain and say that the business has just one domain. So, what's the line to identify if there's one domain or multiple - this is discussed <a href="#1613442382" data-nav-id="1609472905">below</a>.</p>
	
	<h3>Normalizing tables</h3>
	<p>In addition to the discussion about <a href="#1611407572" data-nav-id="1611200362">database normalization</a> under data-storage glossary, this section uses the "<a href="#1613439952" data-nav-id="1612649521">Requirements - Part II</a>" of the example application to highlight few additional points.</p>
	
	<h4>Example of normalization</h4>
	<p id="1613440014">To achieve the requirements and maintain 1NF form, a new table (let's call it "AccountTransaction") must be made rather than adding a list of transactions within a single column in the "BankAccount" table. The "AccountTransaction" can have a foreign key to "BankAccount" table to identify which account the transaction corresponds to. Since there can be only at most 1 transaction for a user in a day, the "AccountTransactions" table can store the "transaction date", and define that the combination of (user, transaction date) is unique. With this record, we can store the transaction amount, let's say, positive for deposit and negative for withdraw. This is a simple example of normalizing table design. Here's a question: Why not store the start and end balance for the transaction rather than storing the change in balance? Hint: it denormalizes the table, discussed <a href="#1613445267" data-nav-id="1609472905">later</a>. On the flip side, consider a different scenario with a small requirement change: Let's say we were required to also store the exact time the transaction took place - which can still be at most once a day. Generally, this is done by having a field called "create_datetime" in the table which captures the datetime when a record is made. Here's the tricky bit: We already saved the date when the transaction was made; It is the transaction date, and it, together with account user field is a unique combination. So would saving the "create_datetime" repeat the data already saved in "transaction date", making the table un-normalized? This seems similar to what happened earlier where saving the start and end balance in a transaction denormalized the data. This is a weird case with the answer being "technically yes, but practically no", and is discussed <a href="#1613520117" data-nav-id="1609472905">here</a>.</p>
	
	<h4>Denormalization</h4>
	<p id="1613445267">A discussion on normalization isn't complete without also considering its limitations, and where denormalization comes in. It is mentioned in a <a href="#1611408137" data-nav-id="1611200362">subsection</a> under RDBMS section in data-storage glossary that normalization comes at cost of performance. With reference to the <a href="#1613440014" data-nav-id="1609472905">above example</a>, how can this be seen? Consider the question posed whether the "AccountTransaction" record should store the change in balance, or whether it should store the start and end balance. In ideal case of data normalization, the "AccountTransaction" table should store the change in balance. This, in combination with the final balance stored in the "bank account" table is sufficient to recreate the account balance at any point of time. However, if the use case is such that users query for "AccountTransaction" entries every so often and also expect to see the corresponding balance, then storing the start and end balance, or just the start balance and the change in balance is a better way to go that is more aligned with business requirements. On that note, realize how it was pushed above in an silent and really unassuming way that the bank account record should store the final balance, but why so? Why not instead just store the initial balance, and then use the list of transactions associated with the account to calculate the final balance? It is because in real world, people are mostly concerned with knowing the latest balance of the account and not what they started with, or anytime in past. While it can be computed using starting balance and list of "AccountTransaction" entries, doing so is computationally expensive and becomes even more expensive with every new transaction. To summarize this discussion: don't simply try to have a normalized or denormalized design. Identify what is needed first and corresponding trade-offs. Finally, choose the path that is most aligned with the business requirements.</p>
	
	<h5>Other examples of denormalization</h5>
	<p id="1613520117">What are few more examples of denormalization? Consider the question in the <a href="#1613440014" data-nav-id="1609472905">above example</a> of storing both "created_datetime" and "created_date". Ideally, this is denormalized data because same data piece has been repeated in two separate columns. It breaks 3NF requirement because now, these 2 columns have a relation between them that is independent of the unique combination. However, since the current databases don't allow simply having a datetime column and make a date-type unique index on it, so it becomes a practical necessity to have this denormalized design. A quick side note: this use case shows that there may be certain use cases where denormalization is forced into the database design. However, there is a programmatic way to restore the normalization again, as discussed <a href="#1613746290" data-nav-id="1609472905">later</a>. Another tricky example of denormalization is when a table has two columns, one for storing file-name, and other for storing file-path, and the file-path text includes file-name with/without the extension. This is also an example where two columns have a relation between them and they are unrelated to the unique combination of the record. Another place where denormalized design stands out is in collecting metrics. Since a bank account consists of list of "AccountTransaction" entries, an <a href="#1613521031" data-nav-id="1608303678">OLAP type request</a> can be made to collect the count of transactions made by the user. A possible implementation design could be to denormalize the "bank account" table by adding a couting column that is incremented by 1 on each transaction. This being said, realize that reporting data is generally collected via <a href="#1608688160" data-nav-id="1608344358">cron jobs</a> to allow the long running OLAP type queries to continue processing before the results are obtained. Also, for businesses that have grown to a scale where having such reports are an essential part of their operation, they also invest in <a href="https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/" target="_blank">data lakes</a> for OLAP request processing. The OLTP requests are served using the normalized data and OLAP requests are served using the denormalized data, which themselves are formed by periodically syncing from the data in the normalized database.</p>
	
	<h4>Not relational table</h4>
	<p id="1613443573">As part of the requirement, it is needed to collect the "AccountTransaction" for each account. Let's say that under normal circumstances, the account holders will never want to see the account transaction details, and they only want to know the final details. Instead, the account transactions data is used only for auditing purpose, or to settle exteremely infrequent disputes with the customers. Even with this modified requirement, the previously developed design of having a separate account transaction table with foreign key to bank account works! Let's take it one step further by requiring that since we are "auditing" entry changes, it is needed to also audit the changes in user, account, and insurance tables. One way is to make separate audit tables corresponding to each table and store data in there, but this becomes too unwieldy, and will continue to become more cumbersome with addition of every new table. Another option could be to have a single table with a column storing table name (let's call this as column-A), anothe column storing row-id of the record in the corresponding table (whose name is stored in column-A) that is being changed (let's call this as column-B), and a third column holding the changes. This design is still able to accomplish all the requirements because the combination of column-A and column-B uniquely identifies the database record getting modified. However, unlike traditional tables, column-B will not be a foreign key because it does not link to column in any one table. This is a "not relational" table: it behaves like there is a relation, but there actually isn't any. Side-note: I don't know if "not relational table" is the correct term; I couldn't find any existing name for it and "non relational term" seems to convey the idea</p>
	<p id="1613708229">Since the id column of non-relational table (column-B in above example) is not related to another table via foreign key relationship, the entry (in non relational table) will not get deleted or anyway affected if the data in other table is changed. This can be advantageous when the non-relational table is used to store auditing records because one can now be assured that entries in audit table will never change once it is created (Side-note: Add some notion of "block" and cryptography onto it, and you'll get a blockchain. If your business highly values the need for auditing transparency, suggest it and explore the possibilities). The same feature can also become a huge design drawback, so be very sure when using "not relational". A good rule of thumb is that any <a href="#1613521031" data-nav-id="1608303678">OLTP request</a> related data must not be stored in "not relational" table(s).</strong></p>
	
	<h5>Audit entries table: A classic "not relational" table</h5>
	<p id="1613443385"><a href="#1613443573" data-nav-id="1609472905">Audit tables</a> are mentioned in <a href="#1608738330" data-nav-id="1608344358">a section</a> under the housekeeping glossary and have been briefly covered <a href="#1613443573" data-nav-id="1609472905">previously</a>; we go into bit more in-depth in this section. The goal of this table is to keep a record of all changes that are made to any record in any table. At a minimum, it requires 3 columns: the name of table where the record exists that is being changed (let's call the column in audit table holding this value as column-A), the id of the record being changed within the table where it exists (let's call the column in audit table holding this value as column-B), and a column holding the changes made on the record. Two additional field that one can immediately think of are: user-id for the user who initiated the request that triggered the change and the datetime when the change is being done (..which is also the create-datetime of the audit entry record).</p>
	<ul id="1613711464">Let's explore some questions related to audit table:
		<li>Audit table entry already stores the time when an entry is modified. Should the table whose entry is getting modified also store this value? As mentioned <a href="#1613708229" data-nav-id="1609472905">previously</a>, if the modification time is related to OLTP processing, then yes, the table whose entry is getting modified should also store it. Using the <a href="#1613440014" data-nav-id="1609472905">example discussed previously</a>, let's say for some reason you need to make an entry in "AccountTransaction" table and also an entry in the audit table. For the "AccountTransaction" table, it is necessary to store the create date entry because it is part of the unique combination (user making transaction + date when transaction made). Thus, storing the create date in the "AccountTransaction" table is needed to successfully process an OLTP request, and so, it is ok to store create date information in both tables. In the same example, it is also ok to store different version of the same data in the two tables, i.e. store a value as a datetime type in audit table, but only as date type in the other table.</li>
		<li>In the <a href="#1613440014" data-nav-id="1609472905">discussion of previous example</a>, the transaction table stored both create-date and create-datetime. Storing of create-date in the transaction table is needed because it is part of the unique index, but why have it also store a create-datetime which seems to be audit related? The simple answer is that the storage of create datetime in both the transaction table and also the audit table is an example of data denormalization, and so, designing in this manner is related to if there's a use case for it or not. If there's a need to get the create and/or last modified datetime as part of some OLTP request processing, then storing it is a good idea. Just a reminder: the discussion on whether doing storing both the create-date and create-datetime denormalizes the table is presented <a href="#1613520117" data-nav-id="1609472905">here</a>.</li>
		<li>It is said that when making audit table entries, the user-id for the user whose request caused modifications in a table record can also be saved. What happens if the change is initiated by some <a href="#1608688160" data-nav-id="1608344358">housekeeping task run by the system as a cron job</a>? As mentioned in details in <a href="#1613710989" data-nav-id="1609472950">a section under the user auth/auth page</a>, one must run such task by invoking a web-request as much possible. If not possible to do so, then another option to use is setting some <a href="#1613746933" data-nav-id="1609385771">environment variable(s)</a> when starting the task and read it when executing the task. A last option could simply be to set some default value in the code when change is not triggered by any request or user. However, this option should be avoided as much possible.</li>
		<li>In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination defining a record in the table. So, what is the unique combination for an entry in the audit table? This depends on how the application is used. It might even be possible for there to be no such uniqueness, as discussed <a href="#1613747301" data-nav-id="1609472905">here</a>.</li>
	</ul>
	
	<h4>Un-unique table</h4>
	<p id="1613747301"></p>
<!--
Its not that the table have "non unique" entries which implies uniqueness is possible but not used.. it is un-unique because of inability to even define a uniqueness criteria

Transactions table where there can be many transactions.. what's unique? - nothing!! - same can also happen when taking notes. This is also not an aspect behavior but a core business logic. Two things can happen: (1) there is no constraint, like preferred card: users can do multiple concurrent operations at same time, balance can go positive, negative.. there is no constraint; - als in audit table or, (2) use optimistic / pessimistic lock for serializability. For create/delete, you'll have to lock on a parent context (is it a 2 way interaction)

For most practical cases, there won't be more than 1 modification of a record per user and/or per millisecond. This can be used to define the unique constraint
-->


<h4>Normalization and agile development</h4>
	<p id="1613442382"></p>
<!--
When in agile process.. can any aspect of normalization be done later? I'd say focus of getting 1NF, 3NF, 5NF form because they make relations more explicit and prevent it from being hidden. 2NF, 4NF are useful to split one table in two, but that can also be done at a later stage as you application evolves
	-->
	
	Use table and field level comment
	
	field name suffix
	
	DB constraints: failure of unique constraint cannot be checked anywhere in the code without running in race conditions and is done first by DB only
	
	field value constraint / validation : programmatically
	-- always start with as strong constraint possible; weaken it only if needed later. Don't weaken it at early stage
	-- (use id=1613746290) say it's if constraint is defined by core requirements otherwise not possible in sql; referential checks -- with referential checks, some denormalization need no longer be denormalization again.. because reference checks make sure everything is consistent. This can help bring back "programmatic normalization" to db-denormalized-design (relate to 1613520117). Also discuss updating a field via code rather than allowing via entity.. effectively making it read only in code. But then make sure to not bypass it.. same holds for all referential checks 
	-- updatable = false
	-- html escaping/unescaping should be under dto.. not model's responsibility!! TODO - add in dto. However.. controlling list of accept tags (it should have accept list of tags rather than deny list) is model responsibility
	-- clean vs save
	<!--
	Use blank still, not null -- check with business requriements though. This does not extend to all fields that are string valued, for example, don't use empty datetime field instead of null.. because empty datetime field is an ill-formatted entry. 
	--|----|---- This further related to: As much possible, add default value to a field if applicable. For example, you're making a campaign and want to count people contacted ~~> default=0! Maybe having "null" indicates that campain has been setup but not started.. but doing so is now indicative of even worse thing.. using a field for more than 1 purpose, i.e. if it's null, then campaign hasn't started. But if it is non-null, it has started, and can have value=0 or 1.. Why not just have a separate status column to identify the status. What if in future, you start a campaign, but want to rollback or pause for some time.. you'll reset it to null and lose data?
	
	-- DateTime field, always in UTC. Save timezone as needed - in separate field in data model. Also identify if timezone captured in one domain applies to other tables
	-->
	
	custom field getter / setter - allows for encryption
	-- custom getter:  If a model has fields that override value of a preceeding model, then define custom getter such that it reads the overriden value if available, else read the original value.
	
	keep separate id
	<!--
	-- Why hiding db id is good
* https://stackoverflow.com/questions/396164/exposing-database-ids-security-risk -- best answer, it is a business intelligence security risk!
* https://stackoverflow.com/questions/9904396/is-it-a-bad-practice-to-expose-db-internal-ids-in-urls
			-- Above says to only use Slugs in url. OK - consider when you have a foreign key relation. Now, Since slugs are unique.. do you make a "Foreign key" relation using "id" or using "slug"?
			--|---- I'd say this is where having some understanding of what a "slug" is - would be helpful. See https://stackoverflow.com/questions/427102/what-is-a-slug-in-django -- which shows how slug can be a nifty url line. Now, one could think that, say, if you're writing comments on a post of a given "slug", you'll talk about it as comment on post "about that slug". So, from users perspective, the relation should use slug. This also matches the "idea" that "id" field is just an internal representation and "slug" is what user sees - so slug is what keeps "relations" between data! However, from DB/service perspective, you now have a choice - either you say that (a) you do a foreign key on slug, and return slug. The advantage: when returning slug foreign key, you won't have to do another query.. that value is already in the table. HOWEVER.. if you're looking from the perspective where slugs can become long text so that they look nice in url, then "indexing" over long string can get problematic, and it can be much faster to make foreign key relations using "id", have foreign key index made using "integer" valued id - and then join on it. In such cases, doing a foreign key on "id" is much more beneficial. There is an intermediary case, say, when you have tables with many foreign keys - in this case, even though an integer index lookup is fast, there may be many such lookups needed and that'll slow things down. 
			--|---- A RELATED HUGE ADVANTAGE: Now you can use slug for foreign key. This way, when a query is made on child table, you can return parent's slug back without doing a join query, because child table already has it. Furthermore, if you delve back into actual rationale behind having a slug (https://stackoverflow.com/questions/427102/what-is-a-slug-in-django) - you'll notice that "slug" is supposed to provide context to a resource, so it is natural that every other related resource references the parent-resource using "slug" field (rather than "id" field) - to maintain the contextual coverage. Note that doing so does NOT prevent you from going back and using "id" instead for foreign key - since slugs are unique.. and not changed once it is set (See next point)
			--|----|---- DO NOT DO ABOVE IF YOU'VE USED NATURAL KEY FOR SLUG - for same reason as you never use natural key for making "id" - because natural keys almost always change in span of product, and then you're left scrambling to change all tables ..or even worse, they go from being unique to non-unique.
			-- Disadvantages: 
			--|---- (1) Anyone knowing the "slug" of 1st table can now immediately know about the slugs used elsewhere :: BUT then.. having unknowable slugs shouldn't be your only security aspect
			--|---- (2) What if the structure started as parent > child relation, but later more tables' foreign key were added. NOTE: (a) If, when adding other foreign key, you change the slug to be like `{foreignKey#1|foreignKey#2|...}`, that's bad - don't change the slug once it is set. That being done.. sure the original intent of the table was to have a parent > child relation, but now it grew beyond it.. that's fine.. the "slug" field still remains unique - which it should by definition - nothing wrong with it.
	-->
	
	abstract class/mixins for common fields
	<!--
	One example: audit entries: Should created, last_modified be part of table or only of audit table??  Link to above entries
	-->
	
	standard data : enum vs new table 
	-- standard table as 6NF form because of low cardinality of data; link to wiki: https://en.wikipedia.org/wiki/Cardinality_(SQL_statements)
	-- migration
	-- TODO: add 2way model+model: standard data + other table: like a single table inheritance, so clean() can get complex - like a delegation
	-- TODO: add 3way model+model+service: If standard data for a row changes, that is not multi table inheritance but a workflow, and Finite state machine considerations come in
	<!--
	Link to non relational table:: 1613443573 - use enum for joining
	
	See #1613440014 in this page.. emphasize to not overuse a column. Don't be +ve for deposit and -ve for withdraw. What if someone confuses: +ve for given to customer and -ve for taken from customer. Explicitly define enum. Generally, don't override column value meaning: goes to SOLID - one column value should mean 1 thing
	

	Using Enum rather than standard table creates problems in that old migration files would need changing. Polymorphic is like having different small db table that got joined using a column as a discriminator. The differene between this vs business processing is that i former, the discriminator column does not change. If dealing with former, then you'll need to keep your db table design most generic and then add specific valiation for each case.
	-- This is another reason to prefer storing constant data in table rather than in enum.. because once in Enum, it sort of becomes hidden.. specially the portion that different columns should not have relation between each other.
	
	What are considerations when designing a table for polymorphic entity? It can be modeled via a single table design with one column containing discriminator for different types. NOTE that what differentiates this from a db table for entity that can go through various stages, is that for the former, the enum valued column does not change its value after created. For the polymorphic table.. 
			--|----|---- add a separate validation constrain for each case. 
			--|----|---- Even more important question is how to design the table. Should it contain just one column which contains just the id and no explict foreign key link and the table to which that id corresponds to can change depending on polymorphic type.. or should there be an explicit foreign key dependency added? It depends on the use case. If what you are trying to do is (i) an aspect behavior and not a business behavior, (ii) deletion of original data does not cascade down to deletion of data in this table, (iii) you have no validation requirements on this table based on columns.. then you can store generic id without creating link, else always create link. An example of this is if you want to audit-track changes in model.
			--|----|---- -- When adding a new enum (or even a standard table entry), be careful of adding it to code. Because DB runs before application, the application won't be able to read new value. this can happen both if using standard data table or enum. Best do migration and code changes in separate deployment. If doing so does not fail in lower env, then it's ready to go for prod
	-->
	
	
	
	<h3>Keep model field as much constrained</h3>
	<p id="1612756799">In context of the <a href="#1612649521" data-nav-id="1612649521">example application</a>, particularly the "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" section, a "user" will have a username. Let's say the username is stored as a string within the entity, and as a text in database, as is generally done. Here's a question: does it allow having all <a href="https://home.unicode.org/" target="_blank">unicode characters</a>, or just a-z? How about A-Z in capitals? What about special characters like &gt;, &lt;, etc.? - But if these are allowed, then the application may become vulnerable to <a href="#1608866075" data-nav-id="1608343369">XSS attack</a>. <strong>It is suggested that when defining an entity field, it should be such that only the expected values are allowed in the database table.</strong> Maybe down the line, you get a specific customer complaint of how their data is not getting saved and they would like the database to allow storing additional values. For example, you allowed users to store a-z, A-Z, 0-9 in username, which worked good initially. However, when your business expanded to Germany, the users complained about not being able to add umlauts. The suggestion is to expand your entity definition when a complaint comes, and to not do it pre-emptively when it's not going to be used. If your application's current use case is that it'll get usernames containing a-z, A-Z, 0-9 characters, then just allow only those characters to be saved.</p>
	<!-- Mention above that while constraining prevents xss attacks.. it should not be considered mdel's responsibility to fend off all attacks. Not should fending attack be taken as main reason for constraining. The only reason it is done is because it matches modeling - that's it. Fending off attacks is a nice result of that. However, proper attack mitigation should only be kept at relevant layers. For a web-based attack, don't have DB layer take responsibility.. but do so in web interfacing layers.. like controllers and dto -->
	
	<!--
	Follow up to 1612753728: 2way repository + service (This is indirect 3way since repo connects with entity): A service can touch different models and cover various context.
	
	Follow up to 1612753728: 2 way model + model: every model across a domain boundary should have a corresponding new table, with one-way or two-way sync between the two. Combine it with "a table in a domain should only reference others from same domain" -- the syncs form legal rules of use. This can however get tedious and that's where legal agreement comes, following which you can squash the 2 forms to one. However, if squashing, be areful about how the 2 will then interplay with a 3rd domain where the "squash" is also getting sync'd. You want to have clear policies. Or, maybe, the other table in different domain is a view of first table.
	--|---- handles pii concerns. Give example of teacher / student / classroom-as-contract; and how last one can cause extra tables that promote security, but based on legal it can be squashed
	--|---- 3 way: model + model + user : is the "LoginAs" or "ViewAs" behavior. If doing so, maybe just having a "View" (and not a table) that does not allow saving data is useful. Can give different authorization for the view
	--|----|---- "data ownership driven design"; domain profile as corollary of "user" in different domains; 3rd party integration should be seen as different user and so if a data is sent out to it, there should be a new table at boundary
	
	Follow up to 1612753728: advanced/code arrangement: keep each context code in separate folder - has implications in changing from monolith to microservice; incl. follow up to 2way repo+service in that if service uses multiple contexts, keep it separate, or either define one context as being super to another.
	
	Follow up to 1612756799: 2way model+dto: Know how to constrain model vs how to constrain dto
	
	-->
	
	
	
	
	
	
	<!--

	
	2 way (Model-Model):
	-- make audit entries in same transaction as DB changes. One more reason to prefer a single transaction
	--|---- From cis-20: maintenance, monitoring and analysis of audit log.. run as background service. Additional background service can be running transactional outbox conformance.
	
	-- Model model validation: Finite state machine (FSM), PDA. Mention how this is different from traditional REST design and so it causes friction in implementation
	--|---- Keep model level validation and save() separate --- realize, save() related to repository, but validation related to model
	--|---- Understand why the need for separation -- This istaken from own Django notes but can help here (-- Model.clean() contains validations that apply at model level. Likely, this is the place to add referential checks, or any checks that should hold at DB level but likely isn't getting applied due to limitation of SQL language. On the other hand, Form.clean() is to clean the data that is read in the form from user-request. For example, if your form take a time-in, time-out.. then Form.clean() would contain validation like the date-time is not in future.. but Model.clean() will contain validation like time-in < time-out . Note how Form.clean() is user-data and business-process related, whereas Model.clean() is model-definition related. This also explain why `ModelForm` in Django calls `Model.clean()` in its `self._post_clean()` method, which is run separately after the form's `self.clean_form()` method ..and these are different from form's `full_clean()` which by its name, must do all sort of cleaning.)
	
	
	2-way (Model-Auth): 
	-- althought it is mentione separately, it should happen almost immediately as part of data model design
	-- Data ownership driven design.
	-- analyze requests with data ownership in mind. Start with data-ownership first design (good example on back forth communication storage, like in chat -- how to make it PII based - helps with take sanitize. Identify which party accesses which data). Ownership should flow down links. So, manyToMany is like a sink for PII and a good boundary between different roles. You must be very clear on ownership and backed by legal if you are going up up from manyToMany back. The conclusion you come to here must also match for corresponding audit log table
	-- PII Take and Sanitize (if you have separate data domain, this is easier)
	-- If getting multiple data by 3rd party api, store them in separate table and then link to it. This allows easier control if data policies change in future
	-- be careful defining authorization for contract based relation: 
			--|---- Say you have a client and worker. When the two are in contract, then the client can see worker relation. But, if the contract is terminated for any reason, then the client shouldn't be able to do so. This means: (1) have a separate endpoint for clinet where worker's data is available. DOn't bundle it with some other endpoint allowing worker access to the data even after contract is over; (2) have a different authorization to acess the data via endpoint - don't just look for client-role on user making the request, but also if the client is allowed data acess for worker slug in path param. ALSO - best do this check as a permission and not within view because (a) this definition, as a permission is more apt, and, (b) view methods must be declarative in nature
			--|---- ALSO, a second design consideration for "time-bound-contract" type behavior is -- never give slug of one party out to another. Think of it like this.. if you enter into a contract with a 3rd party app to get your name, age from Facebook in exchange for taking some quiz.. but instead Facebook also gives it your "id/slug" and now this site becomes the go-to place where other 3rd party give a Facebook-id and get historical data. Then did Facebook do anything wrong? Yes -- **it shouldn't have given out your unique identifier that remains for perpetuity out to a service with which you have a temporary contract**. The better model design is to make a contract table that has foreign key from 3rd party app and from your profile. Now, what goes to 3rd party app is not you id/slug but the slug of contract. If they want your details.. they are given other fields like name, etc.. which can be general and not constrained to be unique. Here, you can control the degree of personalization on data outflow - maybe just give out first name not full name, maybe just the zip code and not exact coordinates. This way, the 3rd party cannot make something tailored to the user of given slug in their code -- which means, things can still get personalized but not individualized (separate topic: unless facebook offers that feature.. but then, its under their control which is still better than letting it out in wild). With the new model, you become "user associated with a contract", rather than "user with that slug.." which gives your application better control rather than have the providers take control.
	
	
	2way (model+repository): Optimistic vs pessimistic lock. Optimistic clearly in 2way interaction. Pessimistic seems to be just related to repository, but realize that you can lock a top level table to control locks on everything below - and so repo code should do that early on. See data-storage glossary. It has 2 links; also the waybackMachine link on transaction has some good details on when to use what
	
	
	2way (model+dto)
	since timezone is gathered separately, return it's value separately.
	
	
	
	2way (entity + test):
	-- Choose your test fixture utility such that the test dtaa it creates also verify the referential relations
	
	
	
	3way (model+controller+dto)
	the controller may require returning datetime in a timezone different from what is captured in different data domain. Ex.: the teacher and school are in different timezone but are physically close. Here, school start time is in school timezone, but you want to send alert to teacher in their timezone.
	
	
	
	
	3way (Model-Model-controller)
	-- PUT call, being idempotent, should allow you to break constraint of Finite state machine. POST, PATCH gets affected by FSM and so they should be the verbs used in corresponding endpoint. Even delete.. if some state does not allow sudden delete, then it should not be via DELETE operation. 
	-- What about PATCH call? PATCH is in itself non-idempotent. But recall that a past rule says to always return same data - so same data should also go out in PATCH call. Being a model serializer, PATCH will also use same structure in request (as in response) to get data, but now unlike PUT calls, it can only take partial fields. So, how does controller know what action to take ..and what's difference between PATCH vs FSMinducing @action endpoints. Hence: PATCH should allow partial updates where you are modifying one or other portion of data, but it should not cause a business processing. Like, iif you accept time-in, time-out.. PATCh can be used to update just one field. Contrast that with calls to "business process" this data, like, approve / deny, etc. That shouldn't be done by PATCH but via @action. So use PATCH if that does not modify the "business status" associated with the entity.
	
	
	3way (Model+Auth+Controller):
	PII TAKE and SANITIZE
	-- SANITIZE calls : PII should sanitize only the necessary columns, not relations.
			
	
	
	
	-->
	
</article>
