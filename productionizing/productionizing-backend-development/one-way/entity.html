<!--
    HTML book section: Entity in 1-way interaction to Productionizing Backend Development, by Kunj Prasad on Github.
    Copyright (C) 2020  Kunj Prasad

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published
    by the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-->
<article>
	<aside class="shown-individually-but-hidden-in-ebook"><i><strong>Read it in ebook <a href="/productionizing/productionizing-backend-development/#1609472905">here</a></strong></i></aside>
	<h2>Entity</h2>
	<p id="1610064998">As mentioned in the <a href="#1611510000" data-nav-id="1611200362">schema section</a> of the data storage glossary, the initial steps in database design involves creating the conceptual design, followed by logical design. Techniques from domain driven design and database normalization is applied in doing so. In current software landscape, it is very likely that an <a href="#1609290898" data-nav-id="1608344385">object-oriented paradigm</a> is used for the development of backend code for the business application. In this paradigm, the database tables in the logical design maps to a class, and a row in the table maps to an object of corresponding class. This object is called as an Entity or a Model (also see <a href="https://stackoverflow.com/questions/2550197/whats-the-difference-between-entity-and-class" target="_blank">this question on StackOverflow</a>). The mapping between an entity and a database table row, allowing an object to be saved as a row, and for a row to be read and converted to an object is achieved through use of software called an <a href="https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping" target="_blank">object-relational mapping tool, or an ORM</a>.  When working on a backend application, it is strongly preferred to use a database and framework with ORM support. Fortunately, this support is already available in commonly used frameworks. <strong>For purpose of this ebook, it is assumed that the backend application is developed using a programming language and a framework that provides ORM support.</strong></p>
	<p id="1610065800">A quick side note: Database froms an important part of backend development. Database related concerns are covered in more depth in a separate ebook: <a href="/productionizing/productionizing-database-schema" target="_blank">Productionizing Database Schema</a>. Readers are suggested to refer it as needed. The topics covered in this book are not dependent on conent of "Productionizing Database Schema" e-book. So, readers can refer it after finishing this e-book.</p>
	
	<h3>Using domain driven design</h3>
	<p id="1612753728">As mentioned in the <a href="#1611510000" data-nav-id="1611200362">schema section</a>, domain driven design is applied when forming the conceptual model. In context of the "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" section of the example application, realize that a "user" is central to all applications. This is a top-level domain. One sub-domain for the application is banking service, like, creating an account, depositing or withdrawing money from the account. Another sub-domain is optional life-insurance service. <strong>Domain driven design suggests that the database tables and corresponding entities made to for an application domain are bounded to that context alone (see <a href="https://martinfowler.com/bliki/BoundedContext.html" target="_blank">Bounded context</a>) and must not get shared with other domains.</strong> When designing the entities and database table, this means that "bank account" entity must not directly have insurance details in one of its columns, nor should it have a foreign key to entry in the insurance table; And same consideration also applies for the insurance table.</p>
	<p id="1613440831">Here's something to think: The "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" says "All account holders are given an option to buy additional life insurance...". Can there be users who are not account holders? For example, administrative staff at bank. Let's say they are not required to have a bank account, i.e. the bank is not forcing its employees to open an account with it. Can these employees also apply for insurance? And why is this being mentioned when the requirement doesn't mention anything about non-account-holding users? Two reasons: (1) to highlight that as part of software development, it is necessary to clarify requirements. What is provided as requirements need not be the final thing and it can still change; And, (2) to highlight that if this is something that can never happen, then an alternate, equally possible design could be to define our top level domain to be "bank account" which joins together the "user" data along with the "bank account" data because doing so is not prohibited by the requirements. We can as well add insurance information in the same domain and say that the business has just one domain. So, what's the line to identify if there's one domain or multiple - this is discussed <a href="#1613442382" data-nav-id="1609472905">below</a>.</p>
	
	<h3>Normalizing tables</h3>
	<p>In addition to the discussion about <a href="#1611407572" data-nav-id="1611200362">database normalization</a> under data-storage glossary, this section uses the "<a href="#1613439952" data-nav-id="1612649521">Requirements - Part II</a>" of the example application to highlight few additional points.</p>
	
	<h4>Example of normalization</h4>
	<p id="1613440014">To achieve the requirements and maintain 1NF form, a new table (let's call it "AccountTransaction") must be made rather than adding a list of transactions within a single column in the "BankAccount" table. The "AccountTransaction" can have a foreign key to "BankAccount" table to identify which account the transaction corresponds to. Since there can be only at most 1 transaction for a user in a day, the "AccountTransactions" table can store the "transaction date", and define that the combination of (user, transaction date) is unique. With this record, we can store the transaction amount, let's say, positive for deposit and negative for withdraw. This is a simple example of normalizing table design. Here's a question: Why not store the start and end balance for the transaction rather than storing the change in balance? Hint: it denormalizes the table, discussed <a href="#1613445267" data-nav-id="1609472905">later</a>. On the flip side, consider a different scenario with a small requirement change: Let's say we were required to also store the exact time the transaction took place - which can still be at most once a day. Generally, this is done by having a field called "create_datetime" in the table which captures the datetime when a record is made. Here's the tricky bit: We already saved the date when the transaction was made; It is the transaction date, and it, together with account user field is a unique combination. So would saving the "create_datetime" repeat the data already saved in "transaction date", making the table un-normalized? This seems similar to what happened earlier where saving the start and end balance in a transaction denormalized the data. This is a weird case with the answer being "technically yes, but practically no", and is discussed <a href="#1613520117" data-nav-id="1609472905">here</a>.</p>
	<p id="1613883782">In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. An additional benefit of doing so is that it provides stability under concurrent request processing, i.e., if multiple requests comes to server at same time to add same data, then only the first of those requests will get processed. Any subsequent ones will fal because the database will report failure of uniqueness constraint since a record with intended data already exists in the database.</p>
	
	<h4>Denormalization</h4>
	<p id="1613445267">A discussion on normalization isn't complete without also considering its limitations, and where denormalization comes in. It is mentioned in a <a href="#1611408137" data-nav-id="1611200362">subsection</a> under RDBMS section in data-storage glossary that normalization comes at cost of performance. With reference to the <a href="#1613440014" data-nav-id="1609472905">above example</a>, how can this be seen? Consider the question posed whether the "AccountTransaction" record should store the change in balance, or whether it should store the start and end balance. In ideal case of data normalization, the "AccountTransaction" table should store the change in balance. This, in combination with the final balance stored in the "bank account" table is sufficient to recreate the account balance at any point of time. However, if the use case is such that users query for "AccountTransaction" entries every so often and also expect to see the corresponding balance, then storing the start and end balance, or just the start balance and the change in balance is a better way to go that is more aligned with business requirements. On that note, realize how it was pushed above in an silent and really unassuming way that the bank account record should store the final balance, but why so? Why not instead just store the initial balance, and then use the list of transactions associated with the account to calculate the final balance? It is because in real world, people are mostly concerned with knowing the latest balance of the account and not what they started with, or anytime in past. While it can be computed using starting balance and list of "AccountTransaction" entries, doing so is computationally expensive and becomes even more expensive with every new transaction. To summarize this discussion: don't simply try to have a normalized or denormalized design. Identify what is needed first and corresponding trade-offs. Finally, choose the path that is most aligned with the business requirements.</p>
	
	<h5>Other examples of denormalization</h5>
	<p id="1613520117">What are few more examples of denormalization? Consider the question in the <a href="#1613440014" data-nav-id="1609472905">above example</a> of storing both "created_datetime" and "created_date". Ideally, this is denormalized data because same data piece has been repeated in two separate columns. It breaks 3NF requirement because now, these 2 columns have a relation between them that is independent of the unique combination. However, since the current databases don't allow simply having a datetime column and make a date-type unique index on it, so it becomes a practical necessity to have this denormalized design. A quick side note: this use case shows that there may be certain use cases where denormalization is forced into the database design. However, there is a programmatic way to restore the normalization again, as discussed <a href="#1613746290" data-nav-id="1609472905">later</a>. Another tricky example of denormalization is when a table has two columns, one for storing file-name, and other for storing file-path, and the file-path text includes file-name with/without the extension. This is also an example where two columns have a relation between them and they are unrelated to the unique combination of the record. Another place where denormalized design stands out is in collecting metrics. Since a bank account consists of list of "AccountTransaction" entries, an <a href="#1613521031" data-nav-id="1608303678">OLAP type request</a> can be made to collect the count of transactions made by the user. A possible implementation design could be to denormalize the "bank account" table by adding a couting column that is incremented by 1 on each transaction. This being said, realize that reporting data is generally collected via <a href="#1608688160" data-nav-id="1608344358">cron jobs</a> to allow the long running OLAP type queries to continue processing before the results are obtained. Also, for businesses that have grown to a scale where having such reports are an essential part of their operation, they also invest in <a href="https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/" target="_blank">data lakes</a> for OLAP request processing. The OLTP requests are served using the normalized data and OLAP requests are served using the denormalized data, which themselves are formed by periodically syncing from the data in the normalized database.</p>
	
	<h4>Not relational table</h4>
	<p id="1613443573">As part of the requirement, it is needed to collect the "AccountTransaction" for each account. Let's say that under normal circumstances, the account holders will never want to see the account transaction details, and they only want to know the final details. Instead, the account transactions data is used only for auditing purpose, or to settle exteremely infrequent disputes with the customers. Even with this modified requirement, the previously developed design of having a separate account transaction table with foreign key to bank account works! Let's take it one step further by requiring that since we are "auditing" entry changes, it is needed to also audit the changes in user, account, and insurance tables. One way is to make separate audit tables corresponding to each table and store data in there, but this becomes too unwieldy, and will continue to become more cumbersome with addition of every new table. Another option could be to have a single table with a column storing table name (let's call this as column-A), anothe column storing row-id of the record in the corresponding table (whose name is stored in column-A) that is being changed (let's call this as column-B), and a third column holding the changes. This design is still able to accomplish all the requirements because the combination of column-A and column-B uniquely identifies the database record getting modified. However, unlike traditional tables, column-B will not be a foreign key because it does not link to column in any one table. This is a "not relational" table: it behaves like there is a relation, but there actually isn't any. Side-note: I don't know if "not relational table" is the correct term; I couldn't find any existing name for it and "non relational term" seems to convey the idea</p>
	<p id="1613708229">Since the id column of non-relational table (column-B in above example) is not related to another table via foreign key relationship, the entry (in non relational table) will not get deleted or anyway affected if the data in other table is changed. This can be advantageous when the non-relational table is used to store auditing records because one can now be assured that entries in audit table will never change once it is created (Side-note: Add some notion of "block" and cryptography onto it, and you'll get a blockchain. If your business highly values the need for auditing transparency, suggest it and explore the possibilities). The same feature can also become a huge design drawback, so be very sure when using "not relational". A good rule of thumb is that any <a href="#1613521031" data-nav-id="1608303678">OLTP request</a> related data must not be stored in "not relational" table(s).</strong></p>
	
	<h5>Audit entries table: A classic "not relational" table</h5>
	<p id="1613443385"><a href="#1613443573" data-nav-id="1609472905">Audit tables</a> are mentioned in <a href="#1608738330" data-nav-id="1608344358">a section</a> under the housekeeping glossary and have been briefly covered <a href="#1613443573" data-nav-id="1609472905">previously</a>; we go into bit more in-depth in this section. The goal of this table is to keep a record of all changes that are made to any record in any table. At a minimum, it requires 3 columns: the name of table where the record exists that is being changed (let's call the column in audit table holding this value as column-A), the id of the record being changed within the table where it exists (let's call the column in audit table holding this value as column-B), and a column holding the changes made on the record. Two additional field that one can immediately think of are: user-id for the user who initiated the request that triggered the change and the datetime when the change is being done (..which is also the create-datetime of the audit entry record).</p>
	<ul id="1613711464">Let's explore some questions related to audit table:
		<li>Audit table entry already stores the time when an entry is modified. Should the table whose entry is getting modified also store this value? As mentioned <a href="#1613708229" data-nav-id="1609472905">previously</a>, if the modification time is related to OLTP processing, then yes, the table whose entry is getting modified should also store it. Using the <a href="#1613440014" data-nav-id="1609472905">example discussed previously</a>, let's say for some reason you need to make an entry in "AccountTransaction" table and also an entry in the audit table. For the "AccountTransaction" table, it is necessary to store the create date entry because it is part of the unique combination (user making transaction + date when transaction made). Thus, storing the create date in the "AccountTransaction" table is needed to successfully process an OLTP request, and so, it is ok to store create date information in both tables. In the same example, it is also ok to store different version of the same data in the two tables, i.e. store a value as a datetime type in audit table, but only as date type in the other table.</li>
		<li>In the <a href="#1613440014" data-nav-id="1609472905">discussion of previous example</a>, the transaction table stored both create-date and create-datetime. Storing of create-date in the transaction table is needed because it is part of the unique index, but why have it also store a create-datetime which seems to be audit related? The simple answer is that the storage of create datetime in both the transaction table and also the audit table is an example of data denormalization, and so, designing in this manner is related to if there's a use case for it or not. If there's a need to get the create and/or last modified datetime as part of some OLTP request processing, then storing it is a good idea. Just a reminder: the discussion on whether doing storing both the create-date and create-datetime denormalizes the table is presented <a href="#1613520117" data-nav-id="1609472905">here</a>.</li>
		<li>It is said that when making audit table entries, the user-id for the user whose request caused modifications in a table record can also be saved. What happens if the change is initiated by some <a href="#1608688160" data-nav-id="1608344358">housekeeping task run by the system as a cron job</a>? As mentioned in details in <a href="#1613710989" data-nav-id="1609472950">a section under the user auth/auth page</a>, one must run such task by invoking a web-request as much possible. If not possible to do so, then another option to use is setting some <a href="#1613746933" data-nav-id="1609385771">environment variable(s)</a> when starting the task and read it when executing the task. A last option could simply be to set some default value in the code when change is not triggered by any request or user. However, this option should be avoided as much possible.</li>
		<li>In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. So, what is the unique combination for an entry in the audit table? This depends on how the application is used. It might even be possible for there to be no such uniqueness, as discussed <a href="#1613747301" data-nav-id="1609472905">here</a>.</li>
	</ul>
	
	<h4>Un-unique table</h4>
	<p id="1613747301">In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. However, there's also a comment in there that having a unique combination is not always possible. This section explores cases when this may happen. Consider the <a href="#1613443385" data-nav-id="1609472905">audit table discussed above</a>. An audit entry is made when a record in some other table is created or modified, and it has no other business use case. Thus, under the assumption that there won't be more than 1 modification of a record per user and/or per millisecond, a four-field combination of unique constraint based on table name, id of record in that table, time of audit entry and the user who made the request can be used. However, this is still a weak definition of uniqueness and breaks down if the user makes a multiple concurrent requests to update data and it simply creates multiple audit table entries. Ideally, uniqueness constraint should also provide safety against concurrent processing, as discussed <a href="#1613883782" data-nav-id="1609472905">above</a>, but that doesn't happen here. Consider another example where you are in customer service, and you receive an incoming message when a POST request is made by an user to certain REST endpoint. The goal is to collect all messages sent by a user. Once again, there's no unique criteria that can be defined. A user can concurrently send similar messages with only slightly different content and it will get still recorded within the database in multiple table entries. The database won't raise a failure saying: "Hey customer! you've already sent a similar message, so I'll reject other messages because they seem to be repetition rather than you sending a new message". In this example, a table that is used in business process (unlike audit table which is not part of a business process, but of related housekeeping task, like, auditing) is still unable to identify any unique criteria over the data in a table row. From above examples, it is inferred that if a database table is such that it could have been equally well replaced by a messaging system, then it will not have any unique constraints defined on it (..and this also seems to be a logical expectation). In this book, they are defined as "un-unique" tables because of inability to even define a uniqueness constraint for such tables.</p>
	<p id="1613885516">If these tables could be replaced by a message queue, then why not simply do such a thing? One: Using of a message queue may not be possible due to lack of infrastructure availability, or lack of developers, or any other reason. Second: To perform a transaction spanning over a database and a message queue means to do a <a href="#1612128885" data-nav-id="1611200362">distributed transaction</a> - which are more involved and hard to setup. Within the <a href="#1609350800" data-nav-id="1608344385">microservice architecture</a>, there exists a design pattern called <a href="https://microservices.io/patterns/data/transactional-outbox.html" target="_blank">"Transactional Outbox Pattern"</a> that aims to completely do off with distributed transactions. On the flip side, if uniqueness criteria cannot be identified for a database table, then also realize that it could possibly be replaced by a message queue.</p>

	<h4>Normalization and agile development</h4>
	<p id="1613442382">One of the key components in modern <a href="https://en.wikipedia.org/wiki/Software_development" target="_blank">software development</a> practices is the use of <a href="https://en.wikipedia.org/wiki/Agile_software_development" target="_blank">Agile software development</a>. Discussion on agile practices is a very broad and tangential topic to what this book intends to achieve and so readers are ecourage to use their favorite search engines to explore the topic. A key feature of agile development is to iteratively discover new features, build on it, test it and deploy it. The question to consider is whether agile development practices interfere with the ability to have a properly normalized database schema because a proper normalization requires complete knowledge of the business processes. For example, in a <a href="#1613440831" data-nav-id="1609472905">previous discussion</a> on domain driven design, it is identified as a design alternative to only have single top level data domain. However, that may need changing at a later time as requirements become more complex. Also, it may be the case that the product owners want to explore addition of a new feature to test, but don't want to commit to have that design get permanently baked inside the database svhema. In this case, new tables should be added in a manner such that it can be removed later on. It may even be preferable to simply add some new columns rather than creating new table. Let's consider different normal forms to explore if there's an answer to balance between normalization and agile development practices.</p>
	<p id="1613927237">Just to mention, examples for different normal forms are discussed in <a href="#1613523454" data-nav-id="1611200362">this section</a> of data storage glossary. 1NF is necessary and should not be skipped. It is also simple to have the database schema in 1NF by using foreign keys. 2NF requires that all other columns relate to the complete unique key combination. This is something that may no longer hold as the database schema evolves during the agile software develpment or if some feature is added for initial testing and is not yet fully baked-in as a business process. With 2NF, even if it gets broken, it's always possible to do custom data migrations and restore 2NF form by decomposing single table into multiple tables. In other words, it is always possible to move from non-2NF design to a 2NF design, and to do in a simple manner and without data loss. So, having a 2NF form can be relaxed and brought in after a business process feature has been established; Hopefully, sooner than later else the data migrations would become long and time consuming. 3NF requires that there is no relation between the non-unique columns of a table. If not maintained, then it can get hard to identify what all relations are there and the custom data migration to fix the 3NF form can become complex. Even worse, the database may have inconsistent entries where the relation between the non-unique columns weren't checked when entering the data. Due to the complexity of fixing a non-3NF design, it is strongly suggested to maintain it when evolving the database schema. When adding a new column during agile development, make sure that it relates to the unique key of table only and not to some other non-unique column. For 4NF and 5NF forms, similar arguments as used for 2NF and 3NF correspondingly can be reused and applied on to the columns that form the unique key combination for a table. Hence, maintaining 4NF can be skipped and maintaining 5NF should be pursued during database schema design evolution.</p>
	
	<h3>Using table and field comments</h3>
	<p id="1613930963">Once the database schema is made, the next step is to create the tables and corresponding columns. In doing so, it is suggested to include both table and column level contents at same time when creating a table, or anytime before the table is used elsewhere - even for foreign key constraint. The comments re-affirm the reasons for choosing the table and column design, and also acts as documentation for any one within and outside the team to understand the purpose of the table. The reason to define the table comment before the table is used elsewhere is to prevent the comment text from having an inconsistent content. Consider the example where a column of table-1 is used as a foreign key in table-2. For this to happen, table-1 must be defined before table-2. If that's the case, then how is it possible for table-1 comments, which should explain the purpose for having the table, contain text about table-2 or its descendents that are not yet defined. This inconsistency in the text content is avoided by having the table comment be defined before the table is used elsewhere.</p>
	
	<h3>Naming</h3>
	<h4>Table name</h4>
	<p id="1615260470">In a <a href="#1611110640" data-nav-id="1608344385">sub-section under the object oriented programming paradigm in the architecture glossary, it is suggested that the class name must be single because as object of the class would represents one such real-world entity. Since ORMs map classes to database tables, a singular noun should be used for table name to achieve close match between the entity class name and the corresponding database table name.</p>
	
	<h4>Column name suffix</h4>
	<p id="1613932814">The <a href="#1613930963" data-nav-id="1609472905">previous section</a> suggests adding comments on all columns for a table to help communicate the role and use of a column. However, IDEs (i.e. integrated development environment, commonly used by software developers to improve coding process) don't have plugin to hook into the database and show these comments to user, and so, the intent of a column may not always get communicated to the developer during coding. To handle this scenario, it is suggested to use suitable suffixes in column name. For example, if a column stores datetime when an entry is created, then name it as "createDateTime" (if using camel case; for snake case, this can be "create_datetime"), rather than naming it as "createDate" or "createTime". Now, anyone looking at the data model will immediately realize that the field store dateTime value rather than a date or a time type data. If possible, the standardization of name suffixes and even of the complete column names should be pursued at the organization wide level. One more thing to keep in consideration is that since an <a href="https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping" target="_blank">ORM</a> maps the column to a field in the entity object, the column should be named such that it is a noun and not a verb. This is in keeping with naming practices for an object discussed <a href="#1611110640" data-nav-id="1608344385">in a subsection</a> within OOP section of the architecture glossary.</p>
	<ul id="1613946477">Some of the suffixes that can be standardized are:
		<li>Using "datetime" vs "date" vs "time" for column that correspondingly contain entries of type datetime, or date, or time. Also, be careful naming field that have a corollary in daily use, like, name as field as "birthDate" and not as "birthDay", even though in daily use, everyone says "birthDay" and not "birthDate".</li>
		<li>Using "code" or "type" for column containing enumerated type data - but pick one and use it consistently. More on enumerated type data is discussed <a href="#1613947022" data-nav-id="1609472905">later</a>. The suffix "name" and "description" also gets used when describing a particular enumerated date type entry. For example, the bank account type can be CHECKING or SAVING. These are 2 "type" or "code" values. An equally good alternative could have been to use code values "C" and "S" for the two bank account types. For type "C", the corresponding name can be something like "Preferred Checking Account Type" with a "description" field describing the features of the account.</li>
		<li>Use "indicator" or "flag" for storing boolean values.</li>
		<li>Use "uri" or "url" suffix if it contains information about the path to find some resource.</li>
		<li>Use context appropriate, unambiguous and non-abbreviated suffixes when possible. For example, using "phone_number" as field name or as a column name suffix if storing a phone number.</li>
		<li>Use suffixes that end with a number when storing a list or object type entry but when normalizing the columns to a separate table does not makes sense. For example, when storing the street address, one can have 2 columns and name them as "address_1" and "address_2".</li>
		<li>Using "id" or "identifier" for the column containing the identifier - but pick one and use it consistently. More on "identifier" column is discussed <a href="#1613947629" data-nav-id="1609472905">later</a>. If the identifier column is used as a foreign key, then name the corresponding column as`{tableName}Identifier`. For example, the column in "account transaction" table that is a foreign key to the account table should be named as "accountIdentifier" or "accountId"</li>
		<li>Using "slug" for a slug type column. More on "slug" column is discussed <a href="#1613946647" data-nav-id="1609472905">later</a>.</li>
	</ul>
	
	<h3>Table constraints</h3>
	<p id="1614191105">Constraints can be used to limit the type of data that can go into a table. This ensures the accuracy and reliability of the data in the table. Constraints can be applied at individual column level or at table level. The database rejects any <a href="#1611510020" data-nav-id="1611200362">transaction</a> made to add or modify data in a table such that the table constraints are violated. The "atomicity" (reference: <a href="#1612128885" data-nav-id="1611200362">ACID properties</a>) behavior of a transaction implies that when a transaction is rejected, then all changes made as part of the transaction is also rolled back. Since a transaction may itself comprise of multiples changes on one/many tables, a related question is if the constraint check is done after each change or after the transaction as a whole? This relates to the idea of "deferrable constraints", for example, as dicussed <a href="https://oracle-base.com/articles/8i/constraint-checking-updates#Deferred" target="_blank">here</a>. The available set of sql constraints are defined <a href="https://www.w3schools.com/sql/sql_constraints.asp" target="_blank">here</a>: Not-null, Default, Unique, Primary-key, Foreign-key, Check, Default.</p>
	
	<h4>Not-null constraint and Default</h4>
	<p id="1614198575">The <a href="https://www.w3schools.com/sql/sql_notnull.asp" target="_blank">not-null</a> constraint is a column level constrainst that enforces the column to always contain a value when inserting a new record, or when updating a record. If not set, the the column can store null values. If the business logic is such that a default value should be added if nothing is provided, then the "<a href="https://www.w3schools.com/sql/sql_default.asp" target="_blank">default</a>" constraint is applied. This means that there is never a case where both non-null and default constraints are applied to a column (I'm not sure if that'll raise an error, but it will definitely raise many eyebrows!!). <strong>If a column accepts null values, then, as much possible, strive to associate a default value to the column.</strong> This is because null values behave differently that non-null values (see <a href="https://www.sqlservercentral.com/articles/database-design-follies-null-vs-not-null" target="_blank">here</a>). The comparisions, query, updates will be lot more error free if a lesser number of nullable columns are used in a table.</p>
	
	<h4>Unique constraint</h4>
	<p id="1614197083">In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. This is enforced by defining a <a href="https://www.w3schools.com/sql/sql_unique.asp" target="_blank">unique constraint</a> on the table which ensures that all values in a column / columns over which the constraint is defined, are different. The uniqueness constraint itself utilizes a <a href="https://www.tutorialspoint.com/sql/sql-indexes.htm" target="_blank">table index</a> to identify that the entries are all unique. It should be noted that in the request processing pipeine, i.e. from user making a request, up to receiving response, the database is the first component that can identify whether an entry being persisted has duplicate value for a column / columns. Hence, <strong>extra code that is run web application should never be considered as a viable alternative instead of defining unique constraints.</strong></p>
	<ul id="1614199777">A few more things to keep in consideration when working with unique constraints:
		<li>If a table has more than one unique constraint, then it is either not 2NF and/or not 4NF normalized. As discussed <a href="#1613927237" data-nav-id="1609472905">previously</a>, this is not something that needs to be immediately corrected when developing codes based on agile practices. However, it should be rectified sooner than later.</li>
		<li>This is an important one: How does the unique constraint behave with null values? Since the database treats "null" as not being any value, 2 null values cannot be compared (reference: <a href="https://www.sqlservercentral.com/articles/database-design-follies-null-vs-not-null" target="_blank">here</a>; Also, this is why the SQL query for null checks use "{column} IS NULL" rather than "{column}=NULL"). Since the 2 null values cannot be compared, so "NULL == NULL" is false, which means <strong>one can add any number of null values in a column and they will all be considered unique!</strong> One can mitigate this behavior by adding not-null criteria over all columns on which the uniqueness is defined. On the other hand, this also gives a non-standard way to have a group level uniqueness. For example, let's say you are collecting information on different activity groups in a school, where one student is a president in each group. There is a notion of uniqueness in that no more than 1 student can be president. However, this uniqueness exists on a "per activity group" basis. One way to solve this is to define a uniqueness criteria over 2 fields, say (group-name, is-president), where group-name is string-valued, and is-president is boolean-valued, and the web-application either puts true (for student who is president) or null (for other students). This will still pass uniqueness criteria since only one student will have true value for it, and all others will be null. This being said, it's not a good practice to do so: (1) How will you now support 2 presidents and both should be different? (2) The solution relies on 2 null values being considered unique. This is not something that SQL standards support. Hence, the solution relies on database implementation quirks which may change in future, or even change from one database to another. (3) This solution itself won't support changing from one president to another within the same transaction unless deferred constraints are used, which does not work for certain databases, as discussed <a href="#1614193129" data-nav-id="1609472905">later</a>. (4) In addition to having unique constraint over (group-name, is-president), one can also define a unique constraint on same table over (group-name, student) since a student can join a group as a member only once. So now, same table has 2 unique constraints which is identified above as being an improper design. With all these problem points, is there an alternate option to use? Yes, it is discussed <a href="#1614440386" data-nav-id="1609472905">later</a>.</li>
	</ul>
	
	<h4>Primary key constraint</h4>
	<p id="1614196319">The <a href="https://www.w3schools.com/sql/sql_primarykey.asp" target="_blank">PRIMARY KEY constraint</a> uniquely identifies each record in a table. It defines the column/columns whose value uniquely identify a row in the table. For this reason, the primary key cannot be null, and must be unique. A <a href="https://www.javatpoint.com/sql-composite-key" target="_blank">composite primary key</a> is when a combination of two or more columns in a table are used to uniquely identify each row in the table. While the combined value must be unique, it is not necessary that the data in individual column is unique. One example is if combination of date and time columns (..rather than a single datetime column) is used to define uniqueness. Different entries can be made for the same date but different time, and also, multiple entries made at same time of day, but for different dates. In either case, the combination of date and time for each entry will be unique and can serve as a composite primary key.</p>
	<p id="1614202345">The column(s) being used for definition of the primary key can also be classified as being a "<a href="https://en.wikipedia.org/wiki/Natural_key" target="_blank">natural key</a>" or a "<a href="https://en.wikipedia.org/wiki/Surrogate_key" target="_blank">surrogate key</a>" (additional reference: <a href="https://www.mssqltips.com/sqlservertip/5431/surrogate-key-vs-natural-key-differences-and-when-to-use-in-sql-server/" target="_blank">here</a>). Let's use previous example and say that we need to use a combination of (date, time) as primary key. What's new is that the date portion must also have a text column which describes the date, like, for "2020-05-20", it says "5th of May, 2020". A simple fix is to make a new table, let's say "DescriptiveDate" which has 2 columns, 1 containing the date value "2020-05-20", and the other containing the text "5th of May, 2020". With this change, the new primary key can be made by using the combination of (<a href="#1614204120" data-nav-id="1609472905">foreign key</a> to "DescriptiveDate", time). Here's the question: Within the "DescriptiveDate" table, it is possible to either turn "2020-05-20" into a primary key; Or, add a new "identifier" column takes numeric value, and it can made into a "primary key", along with adding a uniqueness constraint on date column that contains "2020-05-20" value. Taking the first route of turning "2020-05-20" into a primary key is an example of natural key. Latter is the example of a surrogate key. This topic is discussed further in a <a href="#1614542613" data-nav-id="1609472905">later section</a> and it is suggested to <strong>always use a surrogate key and never a natural key.</strong></p>
	
	<h4>Foreign key constraint</h4>
	<p id="1614204120">A <a href="https://www.w3schools.com/sql/sql_foreignkey.asp" target="_blank">foreign key constraint</a> is used to link two tables together, with the foreign key value in one table referring to the <a href="#1614196319" data-nav-id="1609472905">primary key</a> in another table. In that another table, the entries being referred to are unique since they each have a different primary key. However, the foreign key column need not have unique entries. When the foreign key column is not constrained to be unique, then it forms a "Many-to-one" or "<a href="https://en.wikipedia.org/wiki/One-to-many_(data_model)" target="_blank">One-to-many</a>" relation between the two table. A good way to remember the relationship is by inserting words "this" and "that", i.e., rewording "One to many" as "One [of this] to many [of that]", which means, one entry in "this" table has a relationship to many entries in "that" table, which implies, "that" table has a foreign key column with non unique entries that contain primary key to "this" table entries. So, if table-A has "one to many" relation with table-B, then table-B has "many to one" relation with table-A. On the other hand, when a foreign key column is constrained to have unique entries, it is a "<a href="https://en.wikipedia.org/wiki/One-to-one_(data_model)" target="_blank">One to one</a>" relation between the two table. Just to mention again, there can be some cases where one may want to store the primary key for a table but without creating a foreign key relation, as described <a href="#1613443573" data-nav-id="1609472905">above</a>.</p>
	<p id="1614456323">Another question about foreign key: Should it be null? This is different from whether a foreign key column can be null, to which the answer is yes, it can be null. But even if allowed, should it be null? This <a href="https://stackoverflow.com/questions/7573590/can-a-foreign-key-be-null-and-or-duplicate" target="_blank">StackOverflow thread</a> contains real world example where foreign key can be null. However, I'd not recommend following the suggestions in the thread, and instead, would suggest to never allow a foreign key column to have null values. A foreign key is used to identify a "dependency" relation of one table (i.e., the one containing the foreign key column, also called as the child table) on another (i.e., the one whose primary key is used as a foreign key, also called the parent table). A null valued cell in foreign key column implies that there is no such relation. However, if there's no relation, then why even add a foreign key column? If there is a possibility that the child table can exist independently before it is related to the parent table, then instead of a null valued foreign key, a preferable design should be to have a join table that relates the various tables. This way, each table can exist independently and at some later point, also form a relation among them. As an example, consider <a href="https://stackoverflow.com/questions/7573590/can-a-foreign-key-be-null-and-or-duplicate/7574042#7574042" target="_blank">this post in the thread</a>. For this case, the reason to not have a nullable foreign key is in line with one of the comments for the post suggesting that a new "ProposalAssignedTo" table should be made. Additionally, the proposed design in the post is also not easily modifiable if the requirements suddenly change allowing for a sales proposal to be related to multiple sales representative. One more issue with the propsed design is that the sales table will have one unique constraint based on sales proposal, let's say a combination of (clientId, salesCampaignName), and then another unique criteria after the sales representative is identified, based on (clientId, salesCampaignName, salesRepresentativeId). As mentioned <a href="#1614199777" data-nav-id="1609472905">earlier</a>, if there are two unique constraints in a table, then it is likely not normalized. Hence if there is a table (table-A) such that: (1) it may or may not have a dependency on entry in another table (table-B), and, (2) it has a non-trivial business use for both cases, i.e. when its foreign key column is null or non null, then it is better to model it with 3 tables: table-A (Without foreign key column), table-B, and a table-C that has non-null columns for foreign key to table-A and table-B, and with the combination of the 2 foreign keys as being unique. Even with the changes, the criteria that only 1 sales representative can be assigned hasn't yet been incorporated. Doing so requires additional discussion which is covered <a href="#1614440386" data-nav-id="1609472905">later</a>. Another example that comes close to describing a valid case for using nullable foreign key is in a <a href="https://stackoverflow.com/questions/7573590/can-a-foreign-key-be-null-and-or-duplicate/34682951#34682951" target="_blank">different post in the same thread</a>. However, even for this situation one may avoid having a nullable foreign key column by using a multiple table inheritance design (discussed <a href="#1615078115" data-nav-id="1609472905">below</a>) rather than having a single table inheriance design as mentioned in the table.</p>
	
	<h4>Check constraint</h4>
	<p id="1614440246">The <a href="https://www.w3schools.com/sql/sql_check.asp" target="_blank">check constraint</a> is used to limit the value range that can be placed in a column. It can be defined both at a table or at a column level. When defined on a single column, it allows only certain values for this column. When defined on a table, it limits the values in certain columns based on values in other columns for the entry. A simple use case is applying check constraint on column that store enumerated values. If one or multiple columns being used in the constraint can have null values, then do verify that the constraint is defined in a way such that it is upheld for null values.</p>
	
	<h4>Deferred constraint and database dependency</h4>
	<p id="1614193129">Note that some databases, like MySQL, does not allow constraints to be deferred, as discussed in this <a href="https://stackoverflow.com/questions/5014700/in-mysql-can-i-defer-referential-integrity-checks-until-commit" target="_blank">StackOverflow post</a>. Hence, if your business logic requires making operations such that the constraint check should be deferred, then realize that the ability to complete the operation will get coupled together with the type of database being used. Since such couplings are not a good implementation practice because it prevents the application from changing / upgrading databases, so, it is strongly suggested to not use any business logic that requires deferred constraint. Another important reason to avoid having deferred constraints is that as the business operation grows, it might happen in future that a single service is split into 2 <a href="#1609350800" data-nav-id="1608344385">microservices</a>, and each given ownership of a portion of original data and corresponding tables. If the tables involved in some transaction gets split up between different microservice, then it won't be possible to maintain the contraints without performing a <a href="#1612128885" data-nav-id="1611200362">distributed transaction</a> which is an expensive and not a performant operation. Also, for microservice implementation, it is a good and recommended practice that one microservice does not directly touch the database / tables of another microservice. Bottom line: If you are using deferred constraint, then have a wider discussion with developers and product. Maybe there's a better implementation or maybe you realize that the product does not need the operation that calls for having a deferred constraint. If this doesn't work, then use deferred constraint (..because the business should continue) and write about it to inform others. I won't go further because I've always only ever had the need for adding a deferred constraint once, and in that case, I stopped at the first step.</p>
	
	<h3>Column data type</h3>
	<p>With the column name and constraints defined, a natural next step is to identify the type of data stored in a column. This section identified considerations that must be kept in mind regarding the type of data that should be stored for certain columns. 
	
	<h4>Identifier and Slug</h4>
	<p id="1613947629">Every table record must have a unique and non-null primary key associated with it. One way to do so is by defining a <a href="https://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_6015.htm" target="_blank">database sequence</a> and querying it for values. The values obtained from a sequence monotonically increases and is not rolled back even if the transaction fails. To keep this behavior consistent, the sequence should also be defined as being non-cyclic. This enables using a sequence to provide numeric values for use as primary key in one/many tables. I've not seen of any particular pro/cons of using same sequence to generate primary key for multiple table. As <a href="#1613946477" data-nav-id="1609472905">discussed previously</a>, a common convention is to name the table column that stores this value as "identifier" or "id". When defining the "identifier" column, it is a good practice to allow it to store large numbers (for example, using BigInteger data type), because you don't want to be in a stage where you initially defined it as integer type, forgot about it till you've had 2 billion table entries, and then suddenly the application stops because the upper limit of integer is hit and so, it is not allowing new entries to be stored. That would be bad because any table alteration done at that stage would need to run for all 2 billion entries - which is too much of a down time. Another important thing to simulatneously do is to add a constraint that the column values should be less than an upper limit. This goes in line with a discussion covered <a href="#1612756799" data-nav-id="1609472905">later</a> that all table columns should be constrained as much possible. Since the identifier column is getting values from a sequence with an upper limit, so, it is valid to assume that the column values will always be less than some upper limit. This also makes it explicit that the entity class being used to model the column should have a data type that can safely reach the corresponding limit.</p>
	<p id="1614542613">Defining the primary key using a sequence is an example of a surrogate key. A <a href="#1614202345" data-nav-id="1609472905">previous discussion</a> gives an example of using a unique, non-null data column in the table as primary key. A related question is that if the primary key constraint has the same behavior as a unique, non-null column (discussed <a href="#1614196319" data-nav-id="1609472905">previously</a>), and if every table should have at least one unique constraint (discussed <a href="#1614197083" data-nav-id="">previously</a>), then why not use the unique column data itself as a natural key for the primary key constraint? This are a couple of reasons for why natural key shouldn't be used and instead a surrogate key should be used for defining the primary key: (1) After the value in the unique column changes to a new unique value, and if natural key is used, then this will trigger cascading changes in all other tables that has a foreign key to this entry. This will slow down the database while the changes are being made and it can additionally interfere with other requests in flight. However, the cascading changes are avoided if the primary key and unique data columns are kept separate. (2) From the viewpoint of database, using a natural key makes it ambiguous if a request is trying to update the value of a unique column, or if it is trying to change the primary key of a record. Former is natural to occur for some business processing, but the latter is almost never done and so, it should raise a flag that likely some inappropriate operation is being done. By using a surrogate key, these two concerns are kept separate from one another. One may even develop the application in a way to never modify the primary key after a record has been made. (3) When the primary key constraint is defined, an underlying index is also made. <a href="https://dba.stackexchange.com/questions/137945/indexes-integer-vs-string-performance-if-the-number-of-nodes-is-the-same" target="_blank">This StackOverflow post</a> suggests that the index performance for numeric column is much better than a text or varchar type column. The performance downgrade from using a text valued natural key rather than a numeric valued surrogate key will further add up for every foreign key reference made to this table. (4) When developing in an agile environment, it may happen that a column that was initially identified as being unique no longer remains unique at a later point in time. Maybe, instead of one, it is a combination of two columns that end up defining uniqueness at a later time. Such changes are hard to incorporate if natural key was used for the primary key constraint, rather than using a surrogate key.</p>
	
	<h5>Slug</h5>
	<p id="1613946647">Let's say that a user made a request to create data in the database. To be able to retrieve the data in future, the server must return some value or token in the response that it sends to user, such that the value can be sent back to server in future requests to identify the data that has been created and to return it. The question is: what value should the server send back? One option is to send the primary key field itself because it is unique and identifies the data entry. However, as discussed in these two StackOverflow posts <a href="https://stackoverflow.com/questions/396164/exposing-database-ids-security-risk" target="_blank">here</a> and <a href="https://stackoverflow.com/questions/9904396/is-it-a-bad-practice-to-expose-db-internal-ids-in-urls" target="_blank">here</a>, <strong>it is a business intelligence risk to return the <a href="#1613947629" data-nav-id="1609472905">identifier column</a> values back to the user.</strong> As an alternative, the recommended practice is to send something called a "slug" back to the user. The term "slug" comes from the world of newspaper production and is an informal name given to a story during the production process. As an article / story winds its path from the reporter  through to editor through to the "printing presses", it is referenced by its slug. For example, instead of saying "Have you fixed the errors in story number 123", it is instead said "Have you fixed the errors in the 'kate-and-william' story?", with 'kate and william' being the slug (Reference: <a href="https://stackoverflow.com/questions/427102/what-is-a-slug-in-django" target="_blank">this StackOverflow post</a>; Although the term "slug" is more commonly used when developing using the Django framework, it's use in this ebook is general is nature. It is not meant to imply that the discussions related to "slug" and its use should be ignored is Django framework is not being used). For the purpose of current discussion, a "slug" is defined as a text valued, unique, non-null field that is associated with every database entry. It can be considered as a more human-friendly tag for a table data rather than referencing it via the number in "identifier" column which is more database friendly. However, in the absence of having a more business context appropriate way to generate slug for a database entry, a <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier" target="_blank">UUID</a> or text fields of certain length can also be used. Since slugs are random values, they don't leak business intelligence data that might happen when identifier column values are returned in response.</p>
	
	<h5>Identifier versus slug</h5>
	<p id="1614571666">If slug field is unique and non-null, and can also be returned back to user for reference in future requests, then why even have a separate identifier column and why not only use a slug column? The main reason is that the slug field can be seen as a best-attempt to form a text valued natural key for a table entry. Thus, the reasons <a href="#1614542613" data-nav-id="1609472905">discussed above</a> for not using a natural key as a primary key constraint also applies towards reasons for not using a slug field as a replacement for the identified field. This also means that slug fields should not be used for foreign key relation, even though it is the slug value that is eventually returned to the user. However, this feature introduces a slight performance degradation when processing request. Let's say as a response to a request, the data in some child and parent table (a "child" table is one that contains foreign key to the parent table entry) needs to be returned back to user. Since it is the "slug" field which is returned in the response, so the database must perform a join operation to get the child table entry and the corresponding parent table entry, and then return the slugs for the entries in the response. Had it been ok to simply return the value in identifier column, that could have been read directly from the foreign key column of the child table entry. Hence, a slight database performance degration due to extra join since we want to return "slug" values rather than "identifiers". That being said, since the index over number valued columns are much more performant, it does not degrade the overall request processing performance. Also, in a request processing pipeline, making HTTP calls are many order of magnitudes slower than having to perform an extra join operation, and so business web application should not used the latter as a reason to instead return identifier values in response.</p>
	
	<h5>Three unique constraints per table</h5>
	<p id="1614573090">In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. In a <a href="#1614199777" data-nav-id="1609472905">previous section</a>, this criteria is further strengthened and it is asserted that a normalized table should only have 1 unique constraint. However, with recent discussion about the identifier and slug columns, this criteria should be updated to: <strong> Each table should have 1 primary key constraint over a number valued column (which is unique and not null), 1 unique and not null constraint over slug field, and finally, one more unique constraint derived from the role of the table in the overall business process.</strong></p>
	
	<h4>Text optional-valued fields</h4>
	<p id="1614199557">Let's say you are trying to model a feedback form with an optional comment field. One way is to have a database table consist of this text response field along, a primary key, and a foreign key to user that is giving the feedback. Here's the question: When no ffedback is given, then should the text response column be allowed to have null value, or should a default value of "empty string" be added. One may say that null value means the user hasn't yet answered the question (maybe, because they haven't seen it as yet), but then what does an empty string mean? ..that the user answered, and the answer they gave is nothing. And how is this different from a user that did not answer? Let's  ask a related question: Let's say a webpage is made to display this text data in a html &lt;input&gt; element. When the feedback field has no data, and let's say the corresponding value stored in table is null, then the html &lt;input&gt; element will still show an empty box, which is same as if it received empty string as the value from server. So, when the server data is presented on a website, having null versus an empty string for an optional text field does not make a difference. Hence, if a table column contains optional text, then a good design is to set a default value of empty string and not allow it to store null value. This also follows from a statement made <a href="#1614198575" data-nav-id="1609472905">earlier</a> that whenever possible, a default value should be added in the column. This suggestion is also mentioned in <a href="https://docs.djangoproject.com/en/3.1/ref/models/fields/#null" target="_blank">Django docs</a>.</p>
	
	<h4>Date vs Datetime vs ZonedDateTime</h4>
	<p id="1614824110">"To time or not to time" would be one of the big questions you'll come across when developing schema. The advantage of not storing time, and just the date portion, is that the indexes will be comparatively smaller. It is easier to query for entries matching a particular date, rather than them having dateTime entries in range from midnight of a given date up to midnight of the next date. Try doing the same if you now want entries on one of the dates in a list, and it becomes clear very quickly that wherever possible, it is advantageous to only store date. That being said, storing date and not time, means there is a loss of data that could have been collected and probably could be useful later. Hence, "To time or not to time" is a question that will test your understanding of business requirements being modeled in database tables. The question becomes more pervasive with the realization that a "date" data-type does not define a timezone, but a "dateTime" does. Consider an extremely simple question just waiting to be answered: What is the date on 14th of March, 2021? Is the answer an obvious "14th of March, 2021"? Not quite. Let's expand the question: "What is the date in New Delhi (India) on 14th of March, 2021 in Seattle, Washington (US)?" Now the answer is not unambiguous. At 2AM on 14th of March, 2021 in Seattle, the date is 14th of March in New Delhi (India). But at 11PM on 14th of March, 2021 in Seattle, the date is 15th of March, 2021 in New Delhi (India). So, it seems that as long there is a time-component provided, everything is back to a happy state. How about "What is the date in New Delhi (India) on 14th of March, 2021 in Seattle, Washington (US) at 12:30AM"? The answer seems like a sureshot "14th of March, 2021", but chances are some applications would break - the ones which are good will break - because 14th of March, 2021 marks the start of daylight savings and so 12:30AM isn't uniquely defined. Is it 12:30AM Pacific Standard Time (or, PST), or 12:30AM Pacific Daylight Time (or, PDT)? This matters because the answer to "What is the date in New Delhi (India) on 14th of March, 2021 in Seattle, Washington (US) at 10:40AM PDT" is 14th of March, 2021 (because it'll be 11:10PM in India), but the answer to "What is the date in New Delhi (India) on 14th of March, 2021 in Seattle, Washington (US) at 10:40AM PST" is 15th of March, 2021 (because it'll be 12:10AM for the next day in India). Ok - but is it necessary to provide timezone and could this issue not be solved by simply using the timezone for the corresponding time, so 10:40AM on 14th of March, 2021 is clearly going to be in PDT and not PST? There are 2 issues: (1) The timezone isn't defined for when the timezone cross over is happening. (2) if a user queues up this request, say, on 1st of March, 2021, then what is the definition of "correct timezone to use" - should it be the date in the question (i.e., 14th of March, 2021) or date when the question was queued up (1st of March, 2021). There is no single answer for it because it depends on business use case. Bottom line: You either deal with "date without time zone" or "dateTime with time zone" - there's no middle.</p>
	<p id="1614827655">So, you started with wanting to store date, got some business use case and quickly switched to storing dateTime, just to find timezone come uninvited. What now? What now is to understand the devil. First thing first, timezone have traditionally been defined as the constant offset with <a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time" target="_blank">UTC</a> (side-note, and to up the confusion: UTC is not <a href="https://en.wikipedia.org/wiki/Greenwich_Mean_Time" target="_blank">GMT</a>; side-note#2, and to some consolation: UTC will be your best friend in dealing with the timezone craziness!). This is not totally true. As shown in above example, there are changes from daylight saving. For the same longitude, cities that lie close to Earth's equator, will typically not have daylight saving, whereas those close to poles will have it. And then there's <a href="https://stackoverflow.com/questions/35462876/python-pytz-timezone-function-returns-a-timezone-that-is-off-by-9-minutes/50613134#50613134" target="_blank">this StackOverflow post</a> which identifies that the definition of a timezone can change over time! With this understanding, here are some of the helpful tips to navigate this quagmire: (1) If you need to only store date and not time, then just store date. However, realize that you're missing out the time data. Also, with date alone, one cannot define timezone, and so "date" and "location" based queries won't mix. For example: If you want restaurants in Dallas, TX and San Francisco, CA that is open even after 11PM local time on a certain date, that'll be an ill formed query, because, as explained via example above, 11PM in San Francisco, CA means it's the next date in Dallas. The restrictions due to storing date type data does not mean that it's an all-out bad option. For one, you can always build your application with just date portion. When you hit a roadblock due to new business requirements, then modify to use a datetime column and append "00:00:00" (i.e. midnight) to all date entries, and you've got dateTime type data now. (2) All the examples above show that when storing dateTime, then timezone should also be stored. But how? Storing offset from UTC is not a correct way to store timezone, although that is what most database applications will offer. The suggested solution is a 2-part: (a) Always store all your dateTime entries in database in UTC, no exception, and, (b) add a separate timezone column where needed, and use it to translate to/from the UTC zone dateTime stored in database. Due to relation between different table, it might be possible that many child tables use the same timezone column defined in a parent table. So, realistically, you'll just have a few timezone columns and not one for every dateTime column made in the schema. (3) For storing timezone values, use text-valued "TZ database name" from <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones" target="_blank">list of timezones</a> and don't use constant offset value. For example, use values like "America/Chicago" or "Asia/Seoul".</p>
	
	<h4>Enumerated data</h4>
	<p id="1613947022">An enumerated data is one that can only take certain fixed values. Almost always, they are text valued fields and are represented in the entity class using an <code>Enum</code> data type. These values can be used to associate special business related meaning to the table entry. In context of the <a href="#1612649521" data-nav-id="1612649521">example application</a>, particularly the "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" section, these values can be used to identify a bank account as either being a "CHECKING" or "SAVING" type account. As another example, let's consider the scenario described <a href="#1613440014" data-nav-id="1609472905">above</a> that suggests to store positive values if a deposit was done and negative values if a withdrawl is done. However, for someone looking it data for the first time, it can be confusing because a positive value might equally mean that money was given back to customer which is opposite of the intended use. Since "DEPOSIT" and "WITHDRAW" are a business concept / term in themselves, and the amount deposited/withdrawn is a different concept, a better design would be instead have two columns, one containing a non-negative amount transacted and the other being the transaction type whichcan be "DEPOSIT" or "WITHDRAW". Dong so makes the tables more intuitive. A word of caution: don't do both of having an enumerated deposit / withdraw type column, and also store the transacted amount as being positive or negative because then there is a correlation between the two columns (i.e. if transaction type is "DEPOSIT", then amount transacted is positive, and if transaction type is "WITHDRAW", then amount transacted is negative), and this breaks 3NF normalization.</p>
	
	<h5>How to implement?</h5>
	<p id="1615044545">A question: why use values like "CHECKING", "SAVING", rather than smaller codes like "C", "S", or even numbers like 0, 1? Compared to codes like "C", "S", the use of full name is better because it gives someone looking at database entries a quick idea about the data being stored. This can be useful in avoiding communication pitfalls, specially as the team grows. Additionally, as the functionalities offered by the web application increases, it is more probable for collisions between different small-length codes to happen compared to if the full code name is used (for example, "C" for credit card account?). It may also be possible that some other table ends up using same small code (like, "C" for child insurance that the member has selected) which has a different meaning than the code used in another table. Using same code values is just something that can increase the potential for miscommunication and for them leading to errors. How about using values like 0, 1 instead? This design also suffers from the same problem as using small codes; And one more problem that it suggests presence of an implicit order among different options which need not be true and/or may change in future. For example, let's say the codes 0, 1 are used for checking and savings account. Maybe a requirement comes to allow checking account to automatically pull money from savings to cover overdraft, but auto money movement from checking to savings is not allowed. Someone may look at the requirement, and account-codes, and deduce that an account type with a certain code can pull money from any account types with a higher code. This achieves the desired behavior, but is done by using an ordered relation between the values 0 (the code for checking account type) and 1 (the code for savings account type), which wasn't the original intention for using these code values. That can become a potential problem. Let's say in future, a "CREDIT-CARD" type account is made with code=2, then it will not be able to pull money from checking or savings. Maybe that's the intention. Or, maybe the intention is to allow it to do so, in which case someone needs to study the how the codes are being used throughout the codebase and identify that it should be given a value of -1. What if the goal is to allow these accounts to pull money from checking but not from savings? Therefore, if you're trying to model "enumerated" data, do not use "ordinal" values to achieve the goal.</p>
	<p id="1615044550">There are 2 ways to include enumerated data: (1) use an <code>Enum</code> field in the entity class that gets stored (or, technical term "serialized") in the database as a string, and, (2) create a new table containing these enumerated data in different rows and then add a foreign key reference to those rows wherever it's needed. In both cases, a <a href="#1614440246" data-nav-id="1609472905">check constraint</a> can also be added to the column which stores the name of enumerated type. An advantage of using the first option is that all the data is already on the server and in-memory when the application is deployed. The <code>Enum</code> entry to use is queried from the corresponding <code>Enum</code> class. This contrast with the second option of making a new table wherein a join operation must be done everytime it is referenced by some entity. Here, the enumerated data is obtained by querying from database. However, the fix to lower performance of second option due to join calls is simple: Cache all row from the corresponding enumerated data table when the application is deployed and read from it! ORMs provide ability to do so. An advanage of the second option is that it is possible to modify enumerated data details in the database while the application is running and the changes get automatically picked up in subsequent calls (for example, instead of labeling the account type as "SAVINGS", you want it labeled as "SAVING", without an extra "S" at end). If using Enum type data in the application, doing this change would require making a code change, committing it, and then deploying the code again. But then, doing a redeployment is not a hard thing. An advantage of using the first option is that if any table uses the enumerated field, then a default value can also be assigned to it (because all possible <code>Enum</code> values are already defined, and one of those can be used as a default). With the second option, it is still possible to assign default value but only if a natural key is used when defining the primary key for the new table. However, doing so goes against a <a href="#1614542613" data-nav-id="1609472905">previous suggestion</a> to only use numeric valued primary key. This being said, one must also be cognizant of issues around adding an enumerated default value for a column. One way to identify the default value is to not use a specific enum entry and instead use the corresponding string value with which the enum entry gets persisted in table. Doing so causes duplication, i.e. same string value is defined twice, once with the <code>Enum</code> entry and then as the string value for use as default value. This can be problematic because the relation may get broken in future. Other option is to define <code>Enum</code> class in the application and use of its entry as a default value. The problem here is that if the entries in the <code>Enum</code> class changes in future, then all historical <a href="#1614440610" data-nav-id="1609472905">migrations</a> done previously where that value could be used would need to be changed. Another point to consider is that when using the first option, then it is easier for the developers to see the list of enumerated options. However, when using the second option, it is easier for external teams to identify the enumerated data entries because it can be queried in the database, and they won't have to search for it in the codebase. In the end, there are positive and negative points to both approaches - pick the one that you feel most comfortable with, and then stick to that approach. A small digression: note that using the second option of creating a different table for low <a href="https://en.wikipedia.org/wiki/Cardinality_(SQL_statements)" target="_blank">cardinality</a> enumerated data is one of the few good use cases for having a 6NF normalization. Database schema normalization is otherwise stopped at 5NF normalization (<a href="#1613523454" data-nav-id="1611200362">reference</a>).</p>
	
	<h5>Enumerated data and Inheritance</h5>
	<p id="1615078115"><a href="#1613947022" data-nav-id="1609472905">Earlier discussions</a> identified the use of enumerated data type to capture type or status of some business process. Realize that by doing so, this field can be used to achieve "<a href="https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)" target="_blank">Inheritance</a>" behavior in entity class(es). For example, consider if "checking account" and "savings account" are defined as two concrete implementation of some "account" abstract class. One way to model this is by having the database schema contain two separate tables for checking and savings account. An alternate design is to use a single database table to store all account data, and to identify whether they are checking or savings type account by adding an enumerated "account type" column. This is called <a href="https://en.wikipedia.org/wiki/Single_Table_Inheritance" target="_blank">single table inheritance</a> design (additional reference: <a href="https://en.wikibooks.org/wiki/Java_Persistence/Inheritance#Single_Table_Inheritance" target="_blank">here</a>) which is typically the simplest and the best performing solution. Single table inheritance design can be contrasted the multiple table inheritance design (reference: <a href="https://en.wikibooks.org/wiki/Java_Persistence/Inheritance#Joined,_Multiple_Table_Inheritance" target="_blank">here</a>) where data columns that are common to all the concrete entity class implementations are stored in one table and the data columns unique to each entity is then stored in separate tables. This could be a preferred design is the different concrete implementation have very different columns and it is more intuitive and space saving compared to storing different fields in single table. Due to the need for joins, the multiple table inheritance design does not have good query performance compared to single table inheritance design (..that being said, don't let it stop you from exploring the design because database latencies form a very small fraction compared to network calls). </p>
	<p id="1615177377">Let's consider the "<a href="#1613439952" data-nav-id="1612649521">Requirements - Part II</a>" of the example application where it is asked that the users can create messages, that can then be followed up. The two types of message have different requirements on what additional information must be provided and who is allowed to follow up on the message. The wide difference between the two implementation details is a good reason to model it as a multiple table inheritance. One example on how this can be implemented is: there can be a "CommonMessage" table with a column for numeric valued identifier (that acts as primary key), a foreign key column for the backAccount of user who created the message, and an enumerated data column for the message type. Two separate tables, "OtherMessage" and "TransactionMessage", can be made such that "OtherMessage" table contains a foreign key to the customer representative agent who handled the issue, and "TransactionMessage" table contains a non-nullable foreign key to the disputed transaction entry and a npn-nullable foreign key to the banck official who handled the issue. Both tables also contain a foreign key column to an entry in the "CommonMessage" table. With this design, when user submits a message, then the web application code should either insert an "OtherMessage" and corresponding "CommonMessage" entry, or it should insert a "TransactionMessage" and the corresponding "CommonMessage" entry. When developing the application code, additional care must be taken that it is never allowed to directly insert/delete into the "CommonMessage" table. This ensures that for every "CommonMessage" entry, there is strictly one (i.e., no less than one, no more than one) of either an "OtherMessage" or a "TransactionMessage" entry. One more thing to note is that at every place where a foreign key column is used, it is also not allowed to have null values. This aligns with <a href="#1614456323" data-nav-id="1609472905">previous discussions</a> that foreign key columns should not be nullable. In addition to inserting records, another use case is that it should be possible to query all messages regardless of its type. How does this model support that use case? To do so, one must query on the "CommonMessage" table and then left join with "OtherMessage" and "TransactionMessage" table. As mentioned above, by controlling how entries are added to these tables, it is ensured that each "CommonMessage" entry will have either an "OtherMessage" entry or a "TransactionMessage" entry. Notice how the "CommonMessage" entity is never directly used for writing data to the database and is used only for reading data, and "OtherMessage" or "TransactionMessage" is not directly used for reading data from the database and is only used for writing data to the database. This notion of you using a different model to update information than the model used to read information is called <a href="https://martinfowler.com/bliki/CQRS.html" target="_blank">Command Query Responsibility Segregation, or CQRS</a>. This is a level-up from method level command-query separation within a single class, discussed in a <a href="#1610226800" data-nav-id="1608344385">sub-section</a> under OOP in the architecture glossary; In here, a different entity class (and not just a different method) is used when inserting or retrieving data. A heads up, this concept will get another level up in a <a href="#1615299781" data-nav-id="1615299814">later chapter</a>.</p>
	
	
	TODO -- how to do same with single table
	
	TODO -- look at "7573590/can-a-foreign-key-be-null-and-or-duplicate/34682951#34682951" on this page.. is that wrong
	
	
	
	
	standard data : enum vs new table 
	-- Follow up on one-way/entity/#1615078115: add 2way model+model: standard data + other table: like a single table inheritance, so clean() can get complex - like a delegation -- or, from #1615078115 maybe this should be 2 way model + repo: wherein for single inheritance table same table can be used for store and query. But for multi table inheritance.. only always use the concrete models for storing, but can use the abstract model for query - if wanting to get all entries - even of different type - for same table
	-- Follow up on one-way/entity/#1615078115: add 3way model+model+service: If standard data for a row changes, that is not multi table inheritance but a workflow, and Finite state machine considerations come in
	
	
	<!--
	Link to non relational table:: 1613443573 - use enum for joining
	
	
	Using Enum rather than standard table creates problems in that old migration files would need changing. Polymorphic is like having different small db table that got joined using a column as a discriminator. The differene between this vs business processing is that i former, the discriminator column does not change. If dealing with former, then you'll need to keep your db table design most generic and then add specific valiation for each case.
	-- This is another reason to prefer storing constant data in table rather than in enum.. because once in Enum, it sort of becomes hidden.. specially the portion that different columns should not have relation between each other.
	
	What are considerations when designing a table for polymorphic entity? It can be modeled via a single table design with one column containing discriminator for different types. NOTE that what differentiates this from a db table for entity that can go through various stages, is that for the former, the enum valued column does not change its value after created. For the polymorphic table.. 
			--|----|---- add a separate validation constrain for each case. 
			--|----|---- Even more important question is how to design the table. Should it contain just one column which contains just the id and no explict foreign key link and the table to which that id corresponds to can change depending on polymorphic type.. or should there be an explicit foreign key dependency added? It depends on the use case. If what you are trying to do is (i) an aspect behavior and not a business behavior, (ii) deletion of original data does not cascade down to deletion of data in this table, (iii) you have no validation requirements on this table based on columns.. then you can store generic id without creating link, else always create link. An example of this is if you want to audit-track changes in model.
			--|----|---- -- When adding a new enum (or even a standard table entry), be careful of adding it to code. Because DB runs before application, the application won't be able to read new value. this can happen both if using standard data table or enum. Best do migration and code changes in separate deployment. If doing so does not fail in lower env, then it's ready to go for prod
	-->
	
	
	
	
	
	<h3>Migration</h3>
	<p id="1614440610"></p>
	
	<!-- 
	Say, word is borrowed from Django -- https://docs.djangoproject.com/en/3.1/topics/migrations/#module-django.db.migrations
	
	standard table and data come first -- because entries made by standard table can be used as default in normal table -- or should it?
	
	Everything above is database side.. then migration happens.. then application side code. Migration also involves adding standard data.
	Migrations in agile env.. do it time based.. rather than table based.. (1) because that is natural progression, (2) can group it by release. Add ticket name. Best example is of django migration.
	
	Don't change file afer migration
	-->
	
	
	
	
	
	
	abstract class/mixins for common fields
	<!--
	One example: audit entries: Should created, last_modified be part of table or only of audit table??  Link to above entries. Use common field for identifier also
	-->
	
	
	custom field getter / setter - allows for encryption
	-- custom getter:  If a model has fields that override value of a preceeding model, then define custom getter such that it reads the overriden value if available, else read the original value.
	
	
	field value constraint / validation : programmatically -- i.e. ORM constraints
	-- (use id=1613746290) say it's if constraint is defined by core requirements otherwise not possible in sql; referential checks -- with referential checks, some denormalization need no longer be denormalization again.. because reference checks make sure everything is consistent. This can help bring back "programmatic normalization" to db-denormalized-design (relate to 1613520117). Also discuss updating a field via code rather than allowing via entity.. effectively making it read only in code. But then make sure to not bypass it.. same holds for all referential checks. Relate to 1613930963: If there is a column or table level validation, then that should get expressed in corresponding comment
	-- updatable = false
	-- html escaping/unescaping should be under dto.. not model's responsibility!! TODO - add in dto. However.. controlling list of accept tags (it should have accept list of tags rather than deny list) is model responsibility
	-- clean vs save
	-- follow up to #1615177377 -- each concrete table and corresponding entity class can have its own validation

	<!--
	Use blank still, not null -- check with business requriements though. This does not extend to all fields that are string valued, for example, don't use empty datetime field instead of null.. because empty datetime field is an ill-formatted entry. 
	--|----|---- This further related to: As much possible, add default value to a field if applicable. For example, you're making a campaign and want to count people contacted ~~> default=0! Maybe having "null" indicates that campain has been setup but not started.. but doing so is now indicative of even worse thing.. using a field for more than 1 purpose, i.e. if it's null, then campaign hasn't started. But if it is non-null, it has started, and can have value=0 or 1.. Why not just have a separate status column to identify the status. What if in future, you start a campaign, but want to rollback or pause for some time.. you'll reset it to null and lose data?
	
	-- DateTime field, always in UTC. Save timezone as needed - in separate field in data model. Also identify if timezone captured in one domain applies to other tables. continue discussion in id=1613932814. Use zoned datetime is your datetime has zone string also.. but this may be restrictive as pytc has diiferent timezone and that need not always be certain negative distance from utc. If you are programmatically saying that everything is stored as utc.. then, don't add zoned in column name.. because what it stored is naive value.. but the program interprets it in a zone.
	
	Use id=1614440386:: Continue discussion from id=1614199777 on alternative design for scenario.. based on -- have a stats column which makes things denormalized (discussed in 1613520117).. restoring normalization via only updating the column programmatically (link to corresponding id).. and satisfying criteria by adding a check constraint. This also fulfills condition of always having 1 unique constraint. 
	--|---- Incl. discussion from 1614456323 -- on how to exand table for different count of sales rep getting associated. 
	--|---- Incl. discussion from 1614456323 -- on having multiple foreign key such that only one is non-null -- and how this relates to adding relations back in "not-relational" table. 
	--|---- What if it was requirement that two of them are non-null. one example could be trying to model an "agreement between parties" where you need to have consensus among certain number of parties. Here, do a combination of application based constraint enforcement + use of stats column with cehck constraint.. also in such cases.. can move the collection of foreign key column of which some can be nullable - to a separate column.. and then simply use that as a foreign key in other table. Can even "not-normalize" it to add generality to the behavior -- if allowed so by the business use case. On that note.. realize that application code can even add "relational" behavior to not-normalized table entry.. but best to let database do what it can.. and only bring logic up to application level for what cannot be done at DB level
	-->
	
	
	
	
	
	
	
	
	<h3>Keep entity field as much constrained</h3>
	<p id="1612756799">In context of the <a href="#1612649521" data-nav-id="1612649521">example application</a>, particularly the "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" section, a "user" will have a username. Let's say the username is stored as a string within the entity, and as a text in database, as is generally done. Here's a question: does it allow having all <a href="https://home.unicode.org/" target="_blank">unicode characters</a>, or just a-z? How about A-Z in capitals? What about special characters like &gt;, &lt;, etc.? - But if these are allowed, then the application may become vulnerable to <a href="#1608866075" data-nav-id="1608343369">XSS attack</a>. <strong>It is suggested that when defining an entity field, it should be such that only the expected values are allowed in the database table.</strong> Maybe down the line, you get a specific customer complaint of how their data is not getting saved and they would like the database to allow storing additional values. For example, you allowed users to store a-z, A-Z, 0-9 in username, which worked good initially. However, when your business expanded to Germany, the users complained about not being able to add umlauts. The suggestion is to expand your entity definition when a complaint comes, and to not do it pre-emptively when it's not going to be used. If your application's current use case is that it'll get usernames containing a-z, A-Z, 0-9 characters, then just allow only those characters to be saved.</p>
	<!-- Mention above that while constraining prevents xss attacks.. it should not be considered mdel's responsibility to fend off all attacks. Not should fending attack be taken as main reason for constraining. The only reason it is done is because it matches modeling - that's it. Fending off attacks is a nice result of that. However, proper attack mitigation should only be kept at relevant layers. For a web-based attack, don't have DB layer take responsibility.. but do so in web interfacing layers.. like controllers and dto 
	To add: constrain using combination of db constraints + application/ORM constraints
	See 1614456323 -- it gives an example of where foreign key can be null vs when it should not be
	-->
	
	
	
	
	
	<!--
	Follow up to 1612753728: 2way repository + service (This is indirect 3way since repo connects with entity): A service can touch different models and cover various context.
	
	Follow up to 1612753728: 2 way model + model: every model across a domain boundary should have a corresponding new table, with one-way or two-way sync between the two. Combine it with "a table in a domain should only reference others from same domain" -- the syncs form legal rules of use. This can however get tedious and that's where legal agreement comes, following which you can squash the 2 forms to one. However, if squashing, be areful about how the 2 will then interplay with a 3rd domain where the "squash" is also getting sync'd. You want to have clear policies. Or, maybe, the other table in different domain is a view of first table.
	--|---- handles pii concerns. Give example of teacher / student / classroom-as-contract; and how last one can cause extra tables that promote security, but based on legal it can be squashed
	--|---- 3 way: model + model + user : is the "LoginAs" or "ViewAs" behavior. If doing so, maybe just having a "View" (and not a table) that does not allow saving data is useful. Can give different authorization for the view
	--|----|---- "data ownership driven design"; domain profile as corollary of "user" in different domains; 3rd party integration should be seen as different user and so if a data is sent out to it, there should be a new table at boundary
	
	Follow up to 1612753728: advanced/code arrangement: keep each context code in separate folder - has implications in changing from monolith to microservice; incl. follow up to 2way repo+service in that if service uses multiple contexts, keep it separate, or either define one context as being super to another.
	
	Follow up to 1612756799, 1614440246: 2way model+dto: Know how to constrain model vs how to constrain dto
	
	-->
	
	
	<!--

	
	2 way (Model-Model):
	-- make audit entries in same transaction as DB changes. One more reason to prefer a single transaction
	--|---- From cis-20: maintenance, monitoring and analysis of audit log.. run as background service. Additional background service can be running transactional outbox conformance.
	
	-- Model model validation: Finite state machine (FSM), PDA. Mention how this is different from traditional REST design and so it causes friction in implementation
	--|---- Keep model level validation and save() separate --- realize, save() related to repository, but validation related to model
	--|---- Understand why the need for separation -- This istaken from own Django notes but can help here (-- Model.clean() contains validations that apply at model level. Likely, this is the place to add referential checks, or any checks that should hold at DB level but likely isn't getting applied due to limitation of SQL language. On the other hand, Form.clean() is to clean the data that is read in the form from user-request. For example, if your form take a time-in, time-out.. then Form.clean() would contain validation like the date-time is not in future.. but Model.clean() will contain validation like time-in < time-out . Note how Form.clean() is user-data and business-process related, whereas Model.clean() is model-definition related. This also explain why `ModelForm` in Django calls `Model.clean()` in its `self._post_clean()` method, which is run separately after the form's `self.clean_form()` method ..and these are different from form's `full_clean()` which by its name, must do all sort of cleaning.)
	
	
	2-way (Model-Auth): 
	-- althought it is mentione separately, it should happen almost immediately as part of data model design
	-- Data ownership driven design.
	-- analyze requests with data ownership in mind. Start with data-ownership first design (good example on back forth communication storage, like in chat -- how to make it PII based - helps with take sanitize. Identify which party accesses which data). Ownership should flow down links. So, manyToMany is like a sink for PII and a good boundary between different roles. You must be very clear on ownership and backed by legal if you are going up up from manyToMany back. The conclusion you come to here must also match for corresponding audit log table
	-- PII Take and Sanitize (if you have separate data domain, this is easier)
	-- If getting multiple data by 3rd party api, store them in separate table and then link to it. This allows easier control if data policies change in future
	-- be careful defining authorization for contract based relation: 
			--|---- Say you have a client and worker. When the two are in contract, then the client can see worker relation. But, if the contract is terminated for any reason, then the client shouldn't be able to do so. This means: (1) have a separate endpoint for clinet where worker's data is available. DOn't bundle it with some other endpoint allowing worker access to the data even after contract is over; (2) have a different authorization to acess the data via endpoint - don't just look for client-role on user making the request, but also if the client is allowed data acess for worker slug in path param. ALSO - best do this check as a permission and not within view because (a) this definition, as a permission is more apt, and, (b) view methods must be declarative in nature
			--|---- ALSO, a second design consideration for "time-bound-contract" type behavior is -- never give slug of one party out to another. Think of it like this.. if you enter into a contract with a 3rd party app to get your name, age from Facebook in exchange for taking some quiz.. but instead Facebook also gives it your "id/slug" and now this site becomes the go-to place where other 3rd party give a Facebook-id and get historical data. Then did Facebook do anything wrong? Yes -- **it shouldn't have given out your unique identifier that remains for perpetuity out to a service with which you have a temporary contract**. The better model design is to make a contract table that has foreign key from 3rd party app and from your profile. Now, what goes to 3rd party app is not you id/slug but the slug of contract. If they want your details.. they are given other fields like name, etc.. which can be general and not constrained to be unique. Here, you can control the degree of personalization on data outflow - maybe just give out first name not full name, maybe just the zip code and not exact coordinates. This way, the 3rd party cannot make something tailored to the user of given slug in their code -- which means, things can still get personalized but not individualized (separate topic: unless facebook offers that feature.. but then, its under their control which is still better than letting it out in wild). With the new model, you become "user associated with a contract", rather than "user with that slug.." which gives your application better control rather than have the providers take control.
	-- 5 Ws of PII
Who? What? Why? When? Where?
[When + Where: Should be consistent across all DTOs for org - for same
role] : Governor
---- Privacy depends on country laws, but with privacy becoming
important.. keep it in focus and also to transparently communicate it
to users.. and reflect the same in data model and in table / column
comments

	
	
	2way (model+repository): Optimistic vs pessimistic lock. Optimistic clearly in 2way interaction. Pessimistic seems to be just related to repository, but realize that you can lock a top level table to control locks on everything below - and so repo code should do that early on. See data-storage glossary. It has 2 links; also the waybackMachine link on transaction has some good details on when to use what. Link to app-level concurrency handling by introducing serializability. top level table locking -- also good if using statistic denorm column in top row. If using any app-level constraint using multiple data, then do lock. if you additionally need versioning, use optimistic lock
	
	
	2way (model+dto)
	since timezone is gathered separately, return it's value separately.
	
	2way (model+controller): For const data, keep your service as source of truth.. and expose a url to return data to users.. thus, the const data at server is the sole location of truth
	
	
	
	2way (entity + test):
	-- Choose your test fixture utility such that the test dtaa it creates also verify the referential relations
	
	
	2way (model + service): If you are using an enum valued column for some status that changes with business processing, then always have a different status for every single external call. If you use case is that you'll go through multiple stages quickly.. even then, don't use it as excuse to only have single status
	
	
	
	3way (model+controller+dto)
	the controller may require returning datetime in a timezone different from what is captured in different data domain. Ex.: the teacher and school are in different timezone but are physically close. Here, school start time is in school timezone, but you want to send alert to teacher in their timezone.
	
	
	
	
	3way (Model-Model-controller)
	-- PUT call, being idempotent, should allow you to break constraint of Finite state machine. POST, PATCH gets affected by FSM and so they should be the verbs used in corresponding endpoint. Even delete.. if some state does not allow sudden delete, then it should not be via DELETE operation. 
	-- What about PATCH call? PATCH is in itself non-idempotent. But recall that a past rule says to always return same data - so same data should also go out in PATCH call. Being a model serializer, PATCH will also use same structure in request (as in response) to get data, but now unlike PUT calls, it can only take partial fields. So, how does controller know what action to take ..and what's difference between PATCH vs FSMinducing @action endpoints. Hence: PATCH should allow partial updates where you are modifying one or other portion of data, but it should not cause a business processing. Like, iif you accept time-in, time-out.. PATCh can be used to update just one field. Contrast that with calls to "business process" this data, like, approve / deny, etc. That shouldn't be done by PATCH but via @action. So use PATCH if that does not modify the "business status" associated with the entity.
	
	
	3way (Model+Auth+Controller):
	PII TAKE and SANITIZE
	-- SANITIZE calls : PII should sanitize only the necessary columns, not relations.
			
	
	
	
	-->
	
</article>
