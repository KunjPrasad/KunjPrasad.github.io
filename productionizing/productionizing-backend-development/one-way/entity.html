<!--
    HTML book section: Entity in 1-way interaction to Productionizing Backend Development, by Kunj Prasad on Github.
    Copyright (C) 2020  Kunj Prasad

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published
    by the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-->
<article>
	<aside class="shown-individually-but-hidden-in-ebook"><i><strong>Read it in ebook <a href="/productionizing/productionizing-backend-development/#1609472905">here</a></strong></i></aside>
	
	<nav class="article-toc">
		<h2>Table of contents</h2>
		<a href="#1610064998" data-nav-id="1609472905">Entity</a>
		<ul>
			<li><a href="#1612753728" data-nav-id="1609472905">Using domain driven design</a></li>
			<li>Normalizing tables<ul>
				<li><a href="#1613440014" data-nav-id="1609472905">Example of normalization</a></li>
				<li><a href="#1613445267" data-nav-id="1609472905">Denormalization</a><ul>
					<li><a href="#1613520117" data-nav-id="1609472905">Other examples of denormalization</a></li>
				</ul></li>
				<li><a href="#1613443573" data-nav-id="1609472905">Not relational table</a><ul>
					<li><a href="#1613443385" data-nav-id="1609472905">Audit entries table: A classic "not relational" table</a></li>
				</ul></li>
				<li><a href="#1613747301" data-nav-id="1609472905">Un-unique table</a></li>
				<li><a href="#1613442382" data-nav-id="1609472905">Normalization in agile development</a></li>
			</ul></li>
			<li><a href="#1613930963" data-nav-id="1609472905">Using table and field comments</a></li>
			<li>Naming<ul>
				<li><a href="#1615260470" data-nav-id="1609472905">Table name</a></li>
				<li><a href="#1613932814" data-nav-id="1609472905">Column name suffix</a></li>
			</ul></li>
			<li><a href="#1614191105" data-nav-id="1609472905">Table constraints</a><ul>
				<li><a href="#1614198575" data-nav-id="1609472905">Not-null constraint and Default</a></li>
				<li><a href="#1614197083" data-nav-id="1609472905">Unique constraint</a></li>
				<li><a href="#1614196319" data-nav-id="1609472905">Primary key constraint</a></li>
				<li><a href="#1614204120" data-nav-id="1609472905">Foreign key constraint</a></li>
				<li><a href="#1614440246" data-nav-id="1609472905">Check constraint</a></li>
				<li><a href="#1614193129" data-nav-id="1609472905">Deferred constraint and database dependency</a></li>
			</ul></li>
			<li>Column data type<ul>
				<li><a href="#1613947629" data-nav-id="1609472905">Identifier and Slug</a><ul>
					<li><a href="#1613946647" data-nav-id="1609472905">Slug</a></li>
					<li><a href="#1614571666" data-nav-id="1609472905">Identifier versus Slug</a></li>
					<li><a href="#1614573090" data-nav-id="1609472905">Three unique constraints per table</a></li>
				</ul></li>
				<li><a href="#1614199557" data-nav-id="1609472905">Text optional-valued fields</a></li>
				<li><a href="#1614824110" data-nav-id="1609472905">Date vs Datetime vs ZonedDateTime</a></li>
				<li><a href="#1613947022" data-nav-id="1609472905">Enumerated data</a><ul>
					<li><a href="#1615044545" data-nav-id="1609472905">How to implement?</a></li>
					<li><a href="#1615078115" data-nav-id="1609472905">Enumerated data and Inheritance</a></li>
				</ul></li>
			</ul></li>
			<li><a href="#1614440610" data-nav-id="1609472905">Migration</a><ul>
				<li><a href="#1616262915" data-nav-id="1609472905">Migration in agile environment</a></li>
			</ul></li>
			<li>Entity class design<ul>
				<li><a href="#1616345107" data-nav-id="1609472905">Super class</a></li>
				<li><a href="#1616347263" data-nav-id="1609472905">Custom fields vs custom getters and setters</a></li>
				<li><a href="#1616555826" data-nav-id="1609472905">Programmatic constraint</a><ul>
					<li><a href="#1616556905" data-nav-id="1609472905">Prefer check constraint if possible</a></li>
					<li><a href="#1616634984" data-nav-id="1609472905">Referential checks</a></li>
					<li><a href="#1613746290" data-nav-id="1609472905">Constraint on create and update</a></li>
					<li><a href="#1616833826" data-nav-id="1609472905">Modeling locks</a></li>
				</ul></li>
				<li><a href="#1616830940" data-nav-id="1609472905">Non-updatable field</a></li>
				<li><a href="#1616831542" data-nav-id="1609472905">Constraining vs Saving</a></li>
			</ul></li>
			<li><a href="#1612756799" data-nav-id="1609472905">Keep entity as much constrained</a></li>
		</ul>
	</nav>
	
	<h2>Entity</h2>
	<p id="1610064998">As mentioned in the <a href="#1611510000" data-nav-id="1611200362">schema section</a> of the data storage glossary, the initial step in database design involves creating the conceptual design, followed by creating the logical design. Techniques from domain driven design and database normalization are applied in this design step. In the current landscape of software development, it is very likely that an <a href="#1609290898" data-nav-id="1608344385">object-oriented paradigm</a> is used for the development of backend code for the business application. In this paradigm, a database table in the logical design maps to a class, and a row in the table maps to an object of the corresponding class. This object is called an Entity or a Model (also see <a href="https://stackoverflow.com/questions/2550197/whats-the-difference-between-entity-and-class" target="_blank">this question on StackOverflow</a>). The mapping between an entity and a database table row allows an object to be saved as a row, and for a row to be read and converted to an object. This is achieved through use of software called an <a href="https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping" target="_blank">object-relational mapping</a> tool, or an ORM. When developing a web application, it is strongly preferred to use a <a href="#1617405655" data-nav-id="1608344368">web application framework</a> that provides ORM support for the database being used. Fortunately, many of the modern frameworks provide an ORM support. <strong>For purpose of this ebook, it is assumed that the backend application is developed using an object oriented programming language and a web application framework that provides ORM support.</strong></p>
	<p id="1610065800">A quick side note: Database froms an important part of backend development. Database related concerns are covered in more depth in a separate ebook: <a href="/productionizing/productionizing-database-schema" target="_blank">Productionizing Database Schema</a>. Readers are suggested to refer it as needed. The topics covered in this book are not dependent on conent of "Productionizing Database Schema" e-book. So, readers can refer it after finishing this e-book.</p>
	
	<h3>Using domain driven design</h3>
	<p id="1612753728">As mentioned in the <a href="#1611510000" data-nav-id="1611200362">schema section</a> of the data storage glossary, domain driven design is applied when forming the conceptual model. To understand this with an example, let's consider that the business goal is to achieve "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" section of the example application. For this requirement, realize that the concept of a "User"  is used by all business domains, i.e. all different groups of related activities / processes that can occur in the business application. This common use throughout all domains makes "User" a "top-level domain". Drilling down into individual process, one business domain is the banking service which consists of related activities, like, opening a new account, depositing or withdrawing money from the account. Another domain is optional life-insurance service. <strong>Domain driven design suggests that the database tables and the corresponding entity classes made for a business domain must be bounded only to that domain (see <a href="https://martinfowler.com/bliki/BoundedContext.html" target="_blank">Bounded context</a>) and must not be shared with other domains.</strong> Having this separation promotes parallelism in software development because each team can focus only on the database tables related to the one business domain being managed by the team. Less influence from external teams on the design of database tables associated with a domain also promotes easier maintenance, easier design extension and an ownership towards the design. In context of this example, having a domain driven design means that the entities and database table must be designed in a way that the "bank account" entity must not contain insurance details in any of its columns, nor should it have a foreign key to entry in the insurance table; And same consideration also applies for the insurance table.</p>
	<p id="1617244412">If there is a business concept and corresponding database table that is used by multiple business domains, then all the involved teams must meet together to identify and agree on the structure and use of that table. An ultimate case of this is the top-level domain whose design should be agreeable to all teams. For a multi-domain entity, meeting the constraint of maintaining a bounded context imposes an additional requirement that a table being used by more than one domain must not contain reference to the table used strictly by a single domain. However, it is allowed to have references going the other way. For example, a "user" entity, being a multi-domain entity common to both the "bank account" and "lie insurance" domains, must not contain references to either one of "bank account" or "life insurance" concepts and corresponding entities. However, it is ok for a "bank account" can contain reference to a "user". Should the "life insurance" domain ever need to access the bank account details of the user, it shouldn't try to do so directly, and instead query the "bank account" domain to provide it with relevant details. To facilitate the query execution, it can provide one or multiple concepts that are common between these two domains, which, in this case, is "user".</p>
	<p id="1613440831">Above said, the demarcation between the different domains may not always be clear. Here's something to think: The "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" says that "All account holders are given an option to buy additional life insurance...". Can there be users who are not account holders? For example, administrative staff at bank. Let's say they are not required to have a bank account, i.e. the bank is not forcing its employees to open an account with it. Can these employees also apply for insurance? Also, why is such a question even being discussed when the requirement doesn't mention anything about non-account-holding users? This is done to highlight two points. One is to highlight that as part of software development, it is necessary to clarify requirements. What is provided as requirements need not be final, it needs to be "clarified" more, and the requirements can change as discussions proceed. Next is to highlight a possible design alternative for the case where all users are also account holders. The alternate design is to define "bank account" as the top level domain which joins together the "user" data along with the "bank account" data because doing so is not prohibited by the requirements. We can as well add insurance information in the same domain and say that the business has just one domain. Rather than being fastidious about trying to identify the ideal breakdown of various domains, it is suggested that one should start with a domain model that satisfies the business requirement as the time. As new requirements are identified, the database tables can be decomposed to maintain normalization as discussed <a href="#1613442382" data-nav-id="1609472905">later</a>, and the domains can also be decomposed along with the tables based on analysis done at that time.</p>
	
	<h3>Normalizing tables</h3>
	<p>This section builds on the discussion about <a href="#1611407572" data-nav-id="1611200362">database normalization</a> under data-storage glossary. It also uses the "<a href="#1613439952" data-nav-id="1612649521">Requirements - Part II</a>" of the example application to highlight additional points on database normalization.</p>
	
	<h4>Example of normalization</h4>
	<p id="1613440014">This section gives some example of database normalization in action. To achieve the business requirements and maintain 1NF form, a new table (let's call it <code>AccountTransaction</code>) must be made rather than adding a list of transactions within a single column in the <code>BankAccount</code> table. The <code>AccountTransaction</code> will have a foreign key to <code>BankAccount</code> table to identify which account the transaction corresponds to. To realize the constraint that there can be only at most 1 transaction for a user in a day, the <code>AccountTransactions</code> table can store the "transaction date", and define that the combination of (user, transaction date) as unique. Within <code>AccountTransactions</code>, a column can also be made to store the transaction amount. Let's say that the transaction amount can be positive for deposits and negative for withdraws. The design produced so far is an example of a very simple schema design and also incorporates basic elements of database normalization. Here's a question: Why not store the start and end balance for the transaction rather than storing the change in balance? Hint: it denormalizes the table, and is discussed <a href="#1613445267" data-nav-id="1609472905">later</a>. Consider a different scenario with a minor change in the requirement: Let's say we were required to also store the exact time the transaction took place; The transactions can still be made at most once a day. This new requirement can be modeled by having a field called <code>createDatetime</code> in the table which captures the datetime when a record is made. Here's the tricky bit: We already saved the date when the transaction was made; It is the transaction date, and it, together with account user field is a unique combination. So would saving the <code>createDatetime</code> repeat the data already saved in "transaction date", and denormalize the table? Technically speaking, the answer is yes. However, this is a weird case because it seems that the requirement is forcing us to have a denormalized design. This is discussed in more details <a href="#1613520117" data-nav-id="1609472905">later</a>.</p>
	
	<h4>Denormalization</h4>
	<p id="1613445267">A discussion on normalization isn't complete without also considering its limitations, and where denormalization comes in. It is mentioned in a <a href="#1611408137" data-nav-id="1611200362">subsection</a> under RDBMS section in data-storage glossary that normalization comes at cost of performance. With reference to the <a href="#1613440014" data-nav-id="1609472905">above example</a>, is there a way to see the performance tradeoff being incurred to maintain normalization? Consider the question posed earlier: Should the <code>AccountTransaction</code> record store the change in balance, or should it instead store the start and end balance? If the <code>AccountTransaction</code> table is designed to only store the change in balance, then, such a design, in combination with the final balance stored in the <code>BankAccount</code> table, is able to idenify the account balance for the "bank account" at every point of time. There is no data duplication in any tables, and this is a normalized design. However, if the business use case is that users may query for <code>AccountTransaction</code> entries very often and they also expect to see the corresponding end balance, the above design is not performant because to construct the account balance for a past transaction, the web application will have to pull all records from the database and crunch numbers using those data, which will be CPU intensive. Instead , consider a design that stores the end balance and the transacted amount in the <code>AccountTransaction</code>. With the new design, only one <code>AccountTransaction</code> entry needs to be read and it can provide relevant details to the user. However, this new design is not normalized because there is a redendancy of data; One may calculate the end balance of a transaction by adding the transaction amount to the end balance of previous transaction, or one may directly read the value from the column. In comparison, the old design is normalized and there is no data redundancy, but is non-performant.</p>
	<p id="1617249805">Realize that above also contains a second and very subtle example in support of the statement that that some designs are more attuned than others to handling a use cases. Here's the hint: Why is it that the normalized design above suggests storing the end value in the "bank account"? An equally valid design can be to instead store the start balance when the account was opened. In this case too, the list of account transactions can be used to identify the final account balance after every transaction. An "end balance" rather than a "start balance" is stored because in real world, users are generally concerned with knowing their most recent bank account balance and not the value that they started with. So, the design of storing the ending balance rather than storing the start balance is more attuned to handling the expected business use cases. While the end balance can be computed using starting balance and list of "AccountTransaction" entries, doing so is computationally expensive and becomes even more expensive with every new transaction. This design also hides an example of performance boost via denormalization. The start balance for an account can be defined to always be 0 because a new account should't have any balance. Hence, the end balance column is a actually a redundant data because it should ideally be same as the sum of all amounts transacted since the account was created. But then, doing and on-the-fly calculation of the end balance will be extremely resource-intensive and not performant. It is instead, simpler and faster to just store the end balance with the account, so users can query it when needed.</p>
	
	<h5>Other examples of denormalization</h5>
	<p id="1613520117">What are few more examples of denormalization? Consider the question in the <a href="#1613440014" data-nav-id="1609472905">above example</a> of storing both <code>createDatetime</code> and <code>createDate</code>. Ideally, this is denormalized data because same data piece has been repeated in two separate columns. It breaks 3NF requirement because now, these 2 columns have a relation between them that is independent of the unique combination. However, since the current databases don't allow simply having a datetime column and make a date-type unique index on it, so it becomes a practical necessity to have this denormalized design. A quick side note: this example shows that there may be certain use cases where denormalization is forced into the database design. However, there is a programmatic way to restore the normalization again, and it is discussed <a href="#1613746290" data-nav-id="1609472905">later</a>. Another tricky example of denormalization is when a table has two columns, one for storing file-name, and other for storing file-path, and the file-path column value includes file-name with/without the extension. This is also an example where two columns have a relation between them and they are unrelated to the unique combination of the record. Another place where denormalized design stands out is in collecting metrics. Since a bank account consists of list of <code>AccountTransaction</code> entries, an <a href="#1613521031" data-nav-id="1608303678">OLAP type request</a> can be made to collect the count of transactions made by the user. One implementation is to calculate this value every time its needed, which is not hard or even non-performant, and can be using SQL statement like <code>SELECT COUNT(*) FROM... WHERE ...</code>. Just for the sake of giving an example, another possible design can be to denormalize the "bank account" table by adding a couting column that is incremented by 1 on each transaction. A side note: realize that reporting data is generally collected via <a href="#1608688160" data-nav-id="1608344358">cron jobs</a> that allow running OLAP type queries for a long time. The cron jobs are unlike a web server which is used to primarily serves OLTP type requests, and which will timeout and close a request if it keeps running for a long time. For businesses that have grown to a scale where having such reports are an essential part of their operation, they also invest in <a href="https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/" target="_blank">data lakes</a> for OLAP request processing. Thus, the OLTP requests are served using the normalized data from the database and OLAP requests are served using the denormalized data hosted on a different storage than OLTP data, and which are formed by periodically syncing from the data in the normalized database and doing pre-processing it to add denormalized fields.</p>
	
	<h4>Not relational table</h4>
	<p id="1613443573">As part of the requirement, it is needed to collect the <code>AccountTransaction</code> for each account. Let's say that under normal circumstances, the account holders will never want to see the account transaction details, and they only want to know the final details. Instead, the account transactions data is used only for auditing purpose, or to settle exteremely infrequent disputes with the customers. Even with this modified requirement, the previously developed design of having a separate account transaction table with foreign key to bank account works! Let's take it one step further by requiring that since we are "auditing" entry changes, it is needed to also audit the changes in user, account, and insurance tables. One way is to make separate audit tables corresponding to each table and store data in there, but this becomes too unwieldy, and will continue to become more cumbersome with addition of every new table. Another option could be to have a single table with a column storing table name (let's call this as column-A), anothe column storing row-id of the record in the corresponding table (whose name is stored in column-A) that is being changed (let's call this as column-B), and a third column holding the changes. This design is still able to accomplish all the requirements because the combination of column-A and column-B uniquely identifies the database record getting modified. However, unlike traditional tables, column-B will not be a foreign key because it does not link to column in any one table. This is a "not relational" table: it behaves like there is a relation, but there actually isn't any. Side-note: I don't know if "not relational table" is the correct term; I couldn't find any existing name for it and "non relational term" seems to convey the idea</p>
	<p id="1613708229">Since the id column of non-relational table (column-B in above example) is not related to another table via foreign key relationship, the entry (in non relational table) will not get deleted or anyway affected if the data in other table is changed. This can be advantageous when the non-relational table is used to store auditing records because one can now be assured that entries in audit table will never change once it is created (Side-note: Add some notion of "block" and cryptography onto it, and you'll get a blockchain. If your business highly values the need for auditing transparency, suggest it and explore the possibilities). The same feature can also become a huge design drawback, so be very sure when using "not relational". A good rule of thumb is that any <a href="#1613521031" data-nav-id="1608303678">OLTP request</a> related data must not be stored in "not relational" table(s).</strong></p>
	
	<h5>Audit entries table: A classic "not relational" table</h5>
	<p id="1613443385"><a href="#1613443573" data-nav-id="1609472905">Audit tables</a> are mentioned in <a href="#1608738330" data-nav-id="1608344358">a section</a> under the housekeeping glossary and have been briefly covered <a href="#1613443573" data-nav-id="1609472905">previously</a>; we go into bit more in-depth in this section. The goal of this table is to keep a record of all changes that are made to any record in a table used as part of any business processing. At a minimum, it requires 3 columns: the name of table where the record exists that is being changed (let's call the column in audit table holding this value as column-A), the id of the record being changed within the table where it exists (let's call the column in audit table holding this value as column-B), and a column holding the changes made on the record. Two additional field that one can immediately think of are: user-id for the user who initiated the request that triggered the change and the datetime when the change is being done (..which is also the create-datetime of the audit entry record). One more field can be stored which is a bit of an advanced functionality; If the business application allows a user with higher/privileged permission to impersonate another user or group when they interact with the busines application, then an "on behalf of" column can also be added. This is also useful to capture background processing initiated by the system after the user has requested for a processing to happen asynchronously.</p>
	<ul id="1613711464">Let's explore some questions related to audit table:
		<li>Audit table entry already stores the time when an entry is modified. Should the table whose entry is getting modified also store this value? As mentioned <a href="#1613708229" data-nav-id="1609472905">previously</a>, if the modification time is related to OLTP processing, then yes, the table whose entry is getting modified should also store it. Using the <a href="#1613440014" data-nav-id="1609472905">example discussed previously</a>, let's say for some reason you need to make an entry in "AccountTransaction" table and also an entry in the audit table. For the "AccountTransaction" table, it is necessary to store the create date entry because it is part of the unique combination (user making transaction + date when transaction made). Thus, storing the create date in the "AccountTransaction" table is needed to successfully process an OLTP request, and so, it is ok to store create date information in both tables. In the same example, it is also ok to store different version of the same data in the two tables, i.e. store a value as a datetime type in audit table, but only as date type in the other table.</li>
		<li>In the <a href="#1613440014" data-nav-id="1609472905">discussion of previous example</a>, the transaction table stored both create-date and create-datetime. Storing of create-date in the transaction table is needed because it is part of the unique index, but why have it also store a create-datetime which seems to be audit related? The simple answer is that the storage of create datetime in both the transaction table and also the audit table is an example of data denormalization, and so, designing in this manner is related to if there's a use case for it or not. If there's a need to get the create and/or last modified datetime as part of some OLTP request processing, then storing it is a good idea. Just a reminder: the discussion on whether doing storing both the create-date and create-datetime denormalizes the table is presented <a href="#1613520117" data-nav-id="1609472905">here</a>.</li>
		<li>It is said that when making audit table entries, the user-id for the user whose request caused modifications in a table record can also be saved. What happens if the change is initiated by some <a href="#1608688160" data-nav-id="1608344358">housekeeping task run by the system as a cron job</a>? As mentioned in details in <a href="#1613710989" data-nav-id="1609472950">a section under the user auth/auth page</a>, one must run such task by invoking a web-request as much possible. If not possible to do so, then another option to use is setting some <a href="#1613746933" data-nav-id="1609385771">environment variable(s)</a> when starting the task and read it when executing the task. A last option could simply be to set some default value in the code when change is not triggered by any request or user. However, this option should be avoided as much possible.</li>
		<li>In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. So, what is the unique combination for an entry in the audit table? This definition of uniqueness in audit table depends on how the application is used and what type of data it is getting. It might even be possible for there to be no such uniqueness, as discussed <a href="#1613747301" data-nav-id="1609472905">here</a>.</li>
	</ul>
	
	<h4>Un-unique table</h4>
	<p id="1613747301">In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. However, there's also a comment in there that having a unique combination is not always possible. This section explores cases when this may happen. Consider the <a href="#1613443385" data-nav-id="1609472905">audit table discussed above</a>. An audit entry is made when a record in some other table is created or modified, and it has no other business use case. Thus, under the assumption that there won't be more than 1 modification of a record per user and/or per millisecond, a four-field combination of unique constraint based on table name, id of record in that table, time of audit entry and the user who made the request can be used. However, this is still a weak definition of uniqueness and breaks down if the user makes a multiple concurrent requests to update data and it simply creates multiple audit table entries. As discussed in a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, uniqueness constraint should also provide safety against concurrent processing. However, that is not something that happens over here. Consider another example where you work as a customer service representative, and you receive an incoming message from the POST request made by an user on to some REST endpoint. Your goal is to collect all messages sent by a user. Once again, there's no unique criteria that can be defined on the messages being sent by the user. A user can concurrently send similar messages with only slightly different content and it will get still recorded within the database in multiple table entries. The database won't raise a failure saying: "Hey customer! you've already sent a similar message, so I'll reject other messages because they seem to be repetition rather than you sending a new message". In this example, a table that is used in business process (unlike audit table which is not part of a business process, but of related housekeeping task, like, auditing) is still unable to identify any unique criteria over the data in a table row. From above examples, it is inferred that if a database table is such that it could have been equally well replaced by a messaging system, then it will not have any unique constraints defined on it (..and this also seems to be a logical expectation). In this book, they are defined as "un-unique" tables because of inability to even define a uniqueness constraint for such tables.</p>
	<p id="1613885516">If these tables could be replaced by a message queue, then why not simply do such a thing? One: Using of a message queue may not be possible due to lack of infrastructure availability, or lack of developers, or any other reason. Second: To perform a transaction spanning over a database and a message queue means to do a <a href="#1612128885" data-nav-id="1611200362">distributed transaction</a> - which are more involved and hard to setup. Within the <a href="#1609350800" data-nav-id="1608344385">microservice architecture</a>, there exists a design pattern called <a href="https://microservices.io/patterns/data/transactional-outbox.html" target="_blank">"Transactional Outbox Pattern"</a> that aims to completely do off with distributed transactions. On the flip side, if uniqueness criteria cannot be identified for a database table, then also realize that it could possibly be replaced by a message queue.</p>

	<h4>Normalization in agile development</h4>
	<p id="1613442382">One of the key components in modern <a href="https://en.wikipedia.org/wiki/Software_development" target="_blank">software development</a> practices is the use of <a href="https://en.wikipedia.org/wiki/Agile_software_development" target="_blank">Agile software development</a>. Discussion on agile practices is a very broad and tangential topic to what this book intends to achieve and so readers are ecourage to use their favorite search engines to explore the topic. A key feature of agile development is to iteratively identify new features, build on it, test it and deploy it; Then identify patterns in interaction of the users with this new feature, and enhance the feature or add more features. Something to consider: Does agile development practices interfere with the ability to have a properly normalized database schema because a proper normalization requires complete knowledge of the business processes which won't happen if features are iteratively developed in smaller chunks? For example, in a <a href="#1613440831" data-nav-id="1609472905">previous discussion</a> on domain driven design, it is identified that one may choose to only have a single top level data domain. However, as more requirements are added, the various sub-domains of the business application may be better identified and a need to decompose the original data domain may come up. Another scenario that gnereally happens is that the product owners want to explore addition of a new features to test whether users would like it or not, and they don't want to commit having the test feature become tightly ingrained in the main database schema. Such cases preclude the ability to have a properly defined schema because one may get asked in future to rollback any newly added feature. In this case, new tables should be added in a manner such that it can be removed later on. It may even be preferable to simply add some new columns rather than creating new table. So, is there any guideline on how to balance normalization in agile development practices.</p>
	<p id="1613927237">Just to mention, examples for different normal forms are discussed in <a href="#1613523454" data-nav-id="1611200362">this section</a> of data storage glossary. 1NF is necessary behaior and should not be skipped. It is also simple to have the database schema in 1NF by using foreign keys. 2NF requires that all other columns relate to the complete unique key combination. This is something that may no longer hold as the database schema evolves during the agile software develpment or if some feature is added for initial testing and is not yet fully baked-in as a business process. With 2NF, even if it gets broken, it's always possible to do custom data migrations and restore 2NF form by decomposing single table into multiple tables. In other words, it is always possible to move from non-2NF design to a 2NF design, and to do in a simple manner and without data loss. So, having a 2NF form can be relaxed and brought in after a business process feature has been established; Hopefully, sooner than later else the data migrations would become long and time consuming. 3NF requires that there is no relation between the non-unique columns of a table. If not maintained, then it can get hard to identify what all relations are there and the custom data migration to fix the 3NF form can become complex. Even worse, the database may have inconsistent entries where the relation between the non-unique columns weren't checked when entering the data. Due to the complexity of fixing a non-3NF design, it is strongly suggested to maintain it when evolving the database schema. When adding a new column during agile development, make sure that it relates to the unique key of table only and not to some other non-unique column. For 4NF and 5NF forms, similar arguments as used for 2NF and 3NF correspondingly can be reused and applied on to the columns that form the unique key combination for a table. Hence, maintaining 4NF can be skipped and maintaining 5NF should be pursued during database schema design evolution.</p>
	
	<h3>Using table and field comments</h3>
	<p id="1613930963">Once the database schema is made, the next step is to create the tables and corresponding columns. In doing so, it is suggested to include both table and column level contents at same time when creating a table, or anytime before the table is used elsewhere - even for foreign key constraint. The comments re-affirm the reasons for choosing the table and column design, and also acts as documentation for any one within and outside the team to understand the purpose of the table. The reason to define the table comment before the table is used elsewhere is to prevent the comment text from having an inconsistent content. Consider the example where a column of table-1 is used as a foreign key in table-2. For this to happen, table-1 must be defined before table-2. If that's the case, then how is it possible for table-1 comments, which should explain the purpose for having the table, contain text about table-2 or its descendents that are not yet defined. This inconsistency in the text content is avoided by having the table comment be defined before the table is used elsewhere.</p>
	
	<h3>Naming</h3>
	<h4>Table name</h4>
	<p id="1615260470">In a <a href="#1611110640" data-nav-id="1608344385">sub-section</a> under the object oriented programming paradigm in the architecture glossary, it is suggested that the class name must be single because as object of the class would represents one such real-world entity. Since ORMs map classes to database tables, a singular noun should be used for table name to achieve close match between the entity class name and the corresponding database table name. Even though ORMs provide the ability to have different names for the table and the corresponding entity, it is best if the two are kept same to avoid potential miscommunications.</p>
	
	<h4>Column name suffix</h4>
	<p id="1613932814">The <a href="#1613930963" data-nav-id="1609472905">previous section</a> suggests adding comments on all columns for a table to help communicate the role and use of a column. However, IDEs (i.e. integrated development environment, commonly used by software developers to improve coding process) don't have plugin to hook into the database and show these comments to user, and so, the intent of a column may not always get communicated to the developer during coding. To handle this scenario, it is suggested to use suitable suffixes in column name. For example, if a column stores datetime when an entry is created, then name it as "createDateTime" (if using camel case; for snake case, this can be "create_datetime"), rather than naming it as "createDate" or "createTime". Now, anyone looking at the data model will immediately realize that the field store dateTime value rather than a date or a time type data. If possible, the standardization of name suffixes and even of the complete column names should be pursued at the organization wide level. One more thing to keep in consideration is that since an <a href="https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping" target="_blank">ORM</a> maps the column to a field in the entity object, the column should be named such that it is a noun and not a verb. This is in keeping with naming practices for an object discussed <a href="#1611110640" data-nav-id="1608344385">in a subsection</a> within OOP section of the architecture glossary.</p>
	<ul id="1613946477">Some of the suffixes that can be standardized are:
		<li>Using "datetime" vs "date" vs "time" for column that correspondingly contain entries of type datetime, or date, or time. Also, be careful naming field that have a corollary in daily use, like, name as field as "birthDate" and not as "birthDay", even though in daily use, everyone says "birthDay" and not "birthDate".</li>
		<li>Using "code" or "type" for column containing enumerated type data - but pick one and use it consistently. More on enumerated type data is discussed <a href="#1613947022" data-nav-id="1609472905">later</a>. The suffix "name" and "description" also gets used when describing a particular enumerated date type entry. For example, the bank account type can be CHECKING or SAVING. These are 2 "type" or "code" values. An equally good alternative could have been to use code values "C" and "S" for the two bank account types. For type "C", the corresponding name can be something like "Preferred Checking Account Type" with a "description" field describing the features of the account.</li>
		<li>Use "indicator" or "flag" for storing boolean values.</li>
		<li>Use "uri" or "url" suffix if it contains information about the path to find some resource.</li>
		<li>Use context appropriate, unambiguous and non-abbreviated suffixes when possible. For example, using "phone_number" as field name or as a column name suffix if storing a phone number.</li>
		<li>Use suffixes that end with a number when storing a list or object type entry but when normalizing the columns to a separate table does not makes sense. For example, when storing the street address, one can have 2 columns and name them as "address_1" and "address_2".</li>
		<li>Using "id" or "identifier" for the column containing the identifier - but pick one and use it consistently. More on "identifier" column is discussed <a href="#1613947629" data-nav-id="1609472905">later</a>. If the identifier column is used as a foreign key, then name the corresponding column as`{tableName}Identifier`. For example, the column in "account transaction" table that is a foreign key to the account table should be named as "accountIdentifier" or "accountId"</li>
		<li>Using "slug" for a slug type column. More on "slug" column is discussed <a href="#1613946647" data-nav-id="1609472905">later</a>.</li>
	</ul>
	
	<h3>Table constraints</h3>
	<p id="1614191105">Constraints can be used to limit the type of data that can go into a table. This ensures the accuracy and reliability of the data in the table. Constraints can be applied at individual column level or at table level. The database rejects any <a href="#1611510020" data-nav-id="1611200362">transaction</a> made to add or modify data in a table such that the table constraints are violated. The "atomicity" (reference: <a href="#1612128885" data-nav-id="1611200362">ACID properties</a>) behavior of a transaction implies that when a transaction is rejected, then all changes made as part of the transaction is also rolled back. Since a transaction may itself comprise of multiples changes on one/many tables, a related question is if the constraint check is done after each change or after the transaction as a whole? This relates to the idea of "deferrable constraints", for example, as dicussed <a href="https://oracle-base.com/articles/8i/constraint-checking-updates#Deferred" target="_blank">here</a>. When adding constraints, a good idea is also to add corresponding details in table or field comments, <a href="#1613930963" data-nav-id="1609472905">discussed previously</a>. The available set of sql constraints are defined <a href="https://www.w3schools.com/sql/sql_constraints.asp" target="_blank">here</a>: Not-null, Default, Unique, Primary-key, Foreign-key, Check, Default.</p>
	
	<h4>Not-null constraint and Default</h4>
	<p id="1614198575">The <a href="https://www.w3schools.com/sql/sql_notnull.asp" target="_blank">not-null</a> constraint is a column level constrainst that enforces the column to always contain a value when inserting a new record, or when updating a record. If not set, the the column can store null values. If the business logic is such that a default value should be added if nothing is provided, then the "<a href="https://www.w3schools.com/sql/sql_default.asp" target="_blank">default</a>" constraint is applied. This means that there is never a case where both non-null and default constraints are applied to a column (I'm not sure if that'll raise an error, but it will definitely raise many eyebrows!!). <strong>If a column accepts null values, then, as much possible, strive to associate a default value to the column.</strong> This is because null values behave differently that non-null values (see <a href="https://www.sqlservercentral.com/articles/database-design-follies-null-vs-not-null" target="_blank">here</a>). The comparisions, query, updates will be lot more error free if a lesser number of nullable columns are used in a table.</p>
	
	<h4>Unique constraint</h4>
	<p id="1614197083">In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. This is enforced by defining a <a href="https://www.w3schools.com/sql/sql_unique.asp" target="_blank">unique constraint</a> on the table which ensures that all values in a column / columns over which the constraint is defined, are different. The uniqueness constraint itself utilizes a <a href="https://www.tutorialspoint.com/sql/sql-indexes.htm" target="_blank">table index</a> to identify that the entries are all unique. It should be noted that in the request processing pipeine, i.e. from user making a request, up to receiving response, the database is the first component that can identify whether an entry being persisted has duplicate value for a column / columns. Hence, <strong>extra code that is run web application should never be considered as a viable alternative instead of defining unique constraints.</strong></p>
	<ul id="1614199777">A few more things to keep in consideration when working with unique constraints:
		<li>If a table has more than one unique constraint, then it is either not 2NF and/or not 4NF normalized. As discussed <a href="#1613927237" data-nav-id="1609472905">previously</a>, this is not something that needs to be immediately corrected when developing codes based on agile practices. However, it should be rectified sooner than later.</li>
		<li>This is an important one: How does the unique constraint behave with null values? Since the database treats "null" as not being any value, 2 null values cannot be compared (reference: <a href="https://www.sqlservercentral.com/articles/database-design-follies-null-vs-not-null" target="_blank">here</a>; Also, this is why the SQL query for null checks use "{column} IS NULL" rather than "{column}=NULL"). Since the 2 null values cannot be compared, so "NULL == NULL" is false, which means <strong>one can add any number of null values in a column and they will all be considered unique!</strong> One can mitigate this behavior by adding not-null criteria over all columns on which the uniqueness is defined. On the other hand, this also gives a non-standard way to have a group level uniqueness. For example, let's say you are collecting information on different activity groups in a school, where one student is a president in each group. There is a notion of uniqueness in that no more than 1 student can be president. However, this uniqueness exists on a "per activity group" basis. One way to solve this is to define a uniqueness criteria over 2 fields, say (group-name, is-president), where group-name is string-valued, and is-president is boolean-valued, and the web-application either puts true (for student who is president) or null (for other students). This will still pass uniqueness criteria since only one student will have true value for it, and all others will be null. This being said, it's not a good practice to do so: (1) How will you now support 2 presidents and both should be different? (2) The solution relies on 2 null values being considered unique. This is not something that SQL standards support. Hence, the solution relies on database implementation quirks which may change in future, or even change from one database to another. (3) This solution itself won't support changing from one president to another within the same transaction unless deferred constraints are used, which does not work for certain databases, as discussed <a href="#1614193129" data-nav-id="1609472905">later</a>. (4) In addition to having unique constraint over (group-name, is-president), one can also define a unique constraint on same table over (group-name, student) since a student can join a group as a member only once. So now, same table has 2 unique constraints which is identified above as being an improper design. With all these problem points, is there an alternate option to use? Yes, it is discussed <a href="#1614440386" data-nav-id="1609472905">later</a>.</li>
	</ul>
	
	<h4>Primary key constraint</h4>
	<p id="1614196319">The <a href="https://www.w3schools.com/sql/sql_primarykey.asp" target="_blank">PRIMARY KEY constraint</a> uniquely identifies each record in a table. It defines the column/columns whose value uniquely identify a row in the table. For this reason, the primary key cannot be null, and must be unique. A <a href="https://www.javatpoint.com/sql-composite-key" target="_blank">composite primary key</a> is when a combination of two or more columns in a table are used to uniquely identify each row in the table. While the combined value must be unique, it is not necessary that the data in individual column is unique. One example is if combination of date and time columns (..rather than a single datetime column) is used to define uniqueness. Different entries can be made for the same date but different time, and also, multiple entries made at same time of day, but for different dates. In either case, the combination of date and time for each entry will be unique and can serve as a composite primary key.</p>
	<p id="1614202345">The column(s) being used for definition of the primary key can also be classified as being a "<a href="https://en.wikipedia.org/wiki/Natural_key" target="_blank">natural key</a>" or a "<a href="https://en.wikipedia.org/wiki/Surrogate_key" target="_blank">surrogate key</a>" (additional reference: <a href="https://www.mssqltips.com/sqlservertip/5431/surrogate-key-vs-natural-key-differences-and-when-to-use-in-sql-server/" target="_blank">here</a>). Let's use previous example and say that we need to use a combination of (date, time) as primary key. What's new is that the date portion must also have a text column which describes the date, like, for "2020-05-20", it says "5th of May, 2020". A simple fix is to make a new table, let's say "DescriptiveDate" which has 2 columns, 1 containing the date value "2020-05-20", and the other containing the text "5th of May, 2020". With this change, the new primary key can be made by using the combination of (<a href="#1614204120" data-nav-id="1609472905">foreign key</a> to "DescriptiveDate", time). Here's the question: Within the "DescriptiveDate" table, it is possible to either turn "2020-05-20" into a primary key; Or, add a new "identifier" column takes numeric value, and it can made into a "primary key", along with adding a uniqueness constraint on date column that contains "2020-05-20" value. Taking the first route of turning "2020-05-20" into a primary key is an example of natural key. Latter is the example of a surrogate key. This topic is discussed further in a <a href="#1614542613" data-nav-id="1609472905">later section</a> and it is suggested to <strong>always use a surrogate key and never a natural key.</strong></p>
	
	<h4>Foreign key constraint</h4>
	<p id="1614204120">A <a href="https://www.w3schools.com/sql/sql_foreignkey.asp" target="_blank">foreign key constraint</a> is used to link two tables together, with the foreign key value in one table referring to the <a href="#1614196319" data-nav-id="1609472905">primary key</a> in another table. In that another table, the entries being referred to are unique since they each have a different primary key. However, the foreign key column need not have unique entries. When the foreign key column is not constrained to be unique, then it forms a "Many-to-one" or "<a href="https://en.wikipedia.org/wiki/One-to-many_(data_model)" target="_blank">One-to-many</a>" relation between the two table. A good way to remember the relationship is by inserting words "this" and "that", i.e., rewording "One to many" as "One [of this] to many [of that]", which means, one entry in "this" table has a relationship to many entries in "that" table, which implies, "that" table has a foreign key column with non unique entries that contain primary key to "this" table entries. So, if table-A has "one to many" relation with table-B, then table-B has "many to one" relation with table-A. On the other hand, when a foreign key column is constrained to have unique entries, it is a "<a href="https://en.wikipedia.org/wiki/One-to-one_(data_model)" target="_blank">One to one</a>" relation between the two table. Just to mention again, there can be some cases where one may want to store the primary key for a table but without creating a foreign key relation, as described <a href="#1613443573" data-nav-id="1609472905">above</a>.</p>
	<p id="1614456323">Another question about foreign key: Should it be null? This is different from whether a foreign key column can be null, to which the answer is yes, it can be null. But even if allowed, should it be null? This <a href="https://stackoverflow.com/questions/7573590/can-a-foreign-key-be-null-and-or-duplicate" target="_blank">StackOverflow thread</a> contains real world example where foreign key can be null. However, I'd not recommend following the suggestions in the thread, and instead, would suggest to never allow a foreign key column to have null values. A foreign key is used to identify a "dependency" relation of one table (i.e., the one containing the foreign key column, also called as the child table) on another (i.e., the one whose primary key is used as a foreign key, also called the parent table). A null valued cell in foreign key column implies that there is no such relation. However, if there's no relation, then why even add a foreign key column? If there is a possibility that the child table can exist independently before it is related to the parent table, then instead of a null valued foreign key, a preferable design should be to have a join table that relates the various tables. This way, each table can exist independently and at some later point, also form a relation among them. As an example, consider <a href="https://stackoverflow.com/questions/7573590/can-a-foreign-key-be-null-and-or-duplicate/7574042#7574042" target="_blank">this post in the thread</a>. For this case, the reason to not have a nullable foreign key is in line with one of the comments for the post suggesting that a new "ProposalAssignedTo" table should be made. Additionally, the proposed design in the post is also not easily modifiable if the requirements suddenly change allowing for a sales proposal to be related to multiple sales representative. One more issue with the propsed design is that the sales table will have one unique constraint based on sales proposal, let's say a combination of (clientId, salesCampaignName), and then another unique criteria after the sales representative is identified, based on (clientId, salesCampaignName, salesRepresentativeId). As mentioned <a href="#1614199777" data-nav-id="1609472905">earlier</a>, if there are two unique constraints in a table, then it is likely not normalized. Hence if there is a table (table-A) such that: (1) it may or may not have a dependency on entry in another table (table-B), and, (2) it has a non-trivial business use for both cases, i.e. when its foreign key column is null or non null, then it is better to model it with 3 tables: table-A (Without foreign key column), table-B, and a table-C that has non-null columns for foreign key to table-A and table-B, and with the combination of the 2 foreign keys as being unique. Even with the changes, the criteria that only 1 sales representative can be assigned hasn't yet been incorporated. Doing so requires additional discussion which is covered <a href="#1614440386" data-nav-id="1609472905">later</a>. Another example that comes close to describing a valid case for using nullable foreign key is in a <a href="https://stackoverflow.com/questions/7573590/can-a-foreign-key-be-null-and-or-duplicate/34682951#34682951" target="_blank">different post in the same thread</a>. However, even for this situation one may avoid having a nullable foreign key column by using a multiple table inheritance design (discussed below <a href="#1615078115" data-nav-id="1609472905">here</a> and <a href="#1616192250" data-nav-id="1609472905">here</a>) rather than having a single table inheriance design as mentioned in the table. Additional discussion on this design topic is covered even later in <a href="#1616833826" data-nav-id="1609472905">this section</a>.</p>
	
	<h4>Check constraint</h4>
	<p id="1614440246">The <a href="https://www.w3schools.com/sql/sql_check.asp" target="_blank">check constraint</a> is used to limit the value range that can be placed in a column. It can be defined both at a table or at a column level. When defined on a single column, it allows only certain values for this column. When defined on a table, it limits the values in certain columns based on values in other columns for the entry. A simple use case is applying check constraint on column that store enumerated values. If one or multiple columns being used in the constraint can have null values, then do verify that the constraint is defined in a way such that it is upheld for null values. When defining check constraints, one must make sure that it relates to the field or table definition and not to business requirements. For example, if a table contains datetime when a particular bank employee clocked in and out for day, then a constraint requiring that clock in time be less than clock out time is a good check constraint because by definition, the clock in can never be more than clock out time. However, requiring that clock in is between 8:45AM to 9:15AM is a business requirement and this constraint should NOT be put at database level. There will be different places where this constraint will be defined; However, it should not be defined at the database level. The reason being that some or the other exception may arise requiring giving admin users an optional back channel to enter different value. For example, what if there was a sudden curfew in the city and bank can only open after 10:00AM! The thing about business requirements is that they model "majority" case, and not "all possible" case that can happen; There will be some exceptional cases that will require special handling by users with elevated access rights. However, putting a constraint at database level draws a line on the type of data that can be entered in the database and nothing else beyond that, and this precludes ability to handle special cases at all.</p>
	
	<h4>Deferred constraint and database dependency</h4>
	<p id="1614193129">Note that some databases, like MySQL, does not allow constraints to be deferred, as discussed in this <a href="https://stackoverflow.com/questions/5014700/in-mysql-can-i-defer-referential-integrity-checks-until-commit" target="_blank">StackOverflow post</a>. Hence, if your business logic requires making operations such that the constraint check should be deferred, then realize that the ability to complete the operation will get coupled together with the type of database being used. Since such couplings are not a good implementation practice because it prevents the application from changing / upgrading databases, so, it is strongly suggested to not use any business logic that requires deferred constraint. Another important reason to avoid having deferred constraints is that as the business operation grows, it might happen in future that a single service is split into 2 <a href="#1609350800" data-nav-id="1608344385">microservices</a>, and each given ownership of a portion of original data and corresponding tables. If the tables involved in some transaction gets split up between different microservice, then it won't be possible to maintain the contraints without performing a <a href="#1612128885" data-nav-id="1611200362">distributed transaction</a> which is an expensive and not a performant operation. Also, for microservice implementation, it is a good and recommended practice that one microservice does not directly touch the database / tables of another microservice. Bottom line: If you are using deferred constraint, then have a wider discussion with developers and product. Maybe there's a better implementation or maybe you realize that the product does not need the operation that calls for having a deferred constraint. If this doesn't work, then use deferred constraint (..because the business should continue) and write about it to inform others. I won't go further because I've always only ever had the need for adding a deferred constraint once, and in that case, I stopped at the first step.</p>
	
	<h3>Column data type</h3>
	<p>With the column name and constraints defined, a natural next step is to identify the type of data stored in a column. This section identified considerations that must be kept in mind regarding the type of data that should be stored for certain columns. 
	
	<h4>Identifier and Slug</h4>
	<p id="1613947629">Every table record must have a unique and non-null primary key associated with it. One way to do so is by defining a <a href="https://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_6015.htm" target="_blank">database sequence</a> and querying it for values. The values obtained from a sequence monotonically increases and is not rolled back even if the transaction fails. To keep this behavior consistent, the sequence should also be defined as being non-cyclic. This enables using a sequence to provide numeric values for use as primary key in one/many tables. I've not seen of any particular pro/cons of using same sequence to generate primary key for multiple table. As <a href="#1613946477" data-nav-id="1609472905">discussed previously</a>, a common convention is to name the table column that stores this value as "identifier" or "id". When defining the "identifier" column, it is a good practice to allow it to store large numbers (for example, using BigInteger data type), because you don't want to be in a stage where you initially defined it as integer type, forgot about it till you've had 2 billion table entries, and then suddenly the application stops because the upper limit of integer is hit and so, it is not allowing new entries to be stored. That would be bad because any table alteration done at that stage would need to run for all 2 billion entries - which is too much of a down time. Another important thing to simulatneously do is to add a constraint that the column values should be less than an upper limit. This goes in line with a discussion covered <a href="#1612756799" data-nav-id="1609472905">later</a> that all table columns should be constrained as much possible. Since the identifier column is getting values from a sequence with an upper limit, so, it is valid to assume that the column values will always be less than some upper limit. This also makes it explicit that the entity class being used to model the column should have a data type that can safely reach the corresponding limit.</p>
	<p id="1614542613">Defining the primary key using a sequence is an example of a surrogate key. A <a href="#1614202345" data-nav-id="1609472905">previous discussion</a> gives an example of using a unique, non-null data column in the table as primary key. A related question is that if the primary key constraint has the same behavior as a unique, non-null column (discussed <a href="#1614196319" data-nav-id="1609472905">previously</a>), and if every table should have at least one unique constraint (discussed <a href="#1614197083" data-nav-id="">previously</a>), then why not use the unique column data itself as a natural key for the primary key constraint? This are a couple of reasons for why natural key shouldn't be used and instead a surrogate key should be used for defining the primary key: (1) After the value in the unique column changes to a new unique value, and if natural key is used, then this will trigger cascading changes in all other tables that has a foreign key to this entry. This will slow down the database while the changes are being made and it can additionally interfere with other requests in flight. However, the cascading changes are avoided if the primary key and unique data columns are kept separate. (2) From the viewpoint of database, using a natural key makes it ambiguous if a request is trying to update the value of a unique column, or if it is trying to change the primary key of a record. Former is natural to occur for some business processing, but the latter is almost never done and so, it should raise a flag that likely some inappropriate operation is being done. By using a surrogate key, these two concerns are kept separate from one another. One may even develop the application in a way to never modify the primary key after a record has been made. (3) When the primary key constraint is defined, an underlying index is also made. <a href="https://dba.stackexchange.com/questions/137945/indexes-integer-vs-string-performance-if-the-number-of-nodes-is-the-same" target="_blank">This StackOverflow post</a> suggests that the index performance for numeric column is much better than a text or varchar type column. The performance downgrade from using a text valued natural key rather than a numeric valued surrogate key will further add up for every foreign key reference made to this table. (4) When developing in an agile environment, it may happen that a column that was initially identified as being unique no longer remains unique at a later point in time. Maybe, instead of one, it is a combination of two columns that end up defining uniqueness at a later time. Such changes are hard to incorporate if natural key was used for the primary key constraint, rather than using a surrogate key.</p>
	
	<h5>Slug</h5>
	<p id="1613946647">Let's say that a user made a request to create data in the database. To be able to retrieve the data in future, the server must return some value or token in the response that it sends to user, such that the value can be sent back to server in future requests to identify the data that has been created and to return it. The question is: what value should the server send back? One option is to send the primary key field itself because it is unique and identifies the data entry. However, as discussed in these two StackOverflow posts <a href="https://stackoverflow.com/questions/396164/exposing-database-ids-security-risk" target="_blank">here</a> and <a href="https://stackoverflow.com/questions/9904396/is-it-a-bad-practice-to-expose-db-internal-ids-in-urls" target="_blank">here</a>, <strong>it is a business intelligence risk to return the <a href="#1613947629" data-nav-id="1609472905">identifier column</a> values back to the user.</strong> As an alternative, the recommended practice is to send something called a "slug" back to the user. The term "slug" comes from the world of newspaper production and is an informal name given to a story during the production process. As an article / story winds its path from the reporter  through to editor through to the "printing presses", it is referenced by its slug. For example, instead of saying "Have you fixed the errors in story number 123", it is instead said "Have you fixed the errors in the 'kate-and-william' story?", with 'kate and william' being the slug (Reference: <a href="https://stackoverflow.com/questions/427102/what-is-a-slug-in-django" target="_blank">this StackOverflow post</a>; Although the term "slug" is more commonly used when developing using the Django framework, it's use in this ebook is general is nature. It is not meant to imply that the discussions related to "slug" and its use should be ignored is Django framework is not being used). For the purpose of current discussion, a "slug" is defined as a text valued, unique, non-null field that is associated with every database entry. It can be considered as a more human-friendly tag for a table data rather than referencing it via the number in "identifier" column which is more database friendly. However, in the absence of having a more business context appropriate way to generate slug for a database entry, a <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier" target="_blank">UUID</a> or text fields of certain length can also be used. Since slugs are random values, they don't leak business intelligence data that might happen when identifier column values are returned in response. Finally, since slugs are used to identify the data resource at the server, so they should always be unambiguous, and hence, should not be modified once they are created.</p>
	
	<h5>Identifier versus Slug</h5>
	<p id="1614571666">If slug field is unique and non-null, and can also be returned back to user for reference in future requests, then why even have a separate identifier column and why not only use a slug column? The main reason is that the slug field can be seen as a best-attempt to form a text valued natural key for a table entry. Thus, the reasons <a href="#1614542613" data-nav-id="1609472905">discussed above</a> for not using a natural key as a primary key constraint also applies towards reasons for not using a slug field as a replacement for the identified field. This also means that slug fields should not be used for foreign key relation, even though it is the slug value that is eventually returned to the user. However, this feature introduces a slight performance degradation when processing request. Let's say as a response to a request, the data in some child and parent table (a "child" table is one that contains foreign key to the parent table entry) needs to be returned back to user. Since it is the "slug" field which is returned in the response, so the database must perform a join operation to get the child table entry and the corresponding parent table entry, and then return the slugs for the entries in the response. Had it been ok to simply return the value in identifier column, that could have been read directly from the foreign key column of the child table entry. Hence, a slight database performance degration due to extra join since we want to return "slug" values rather than "identifiers". That being said, since the index over number valued columns are much more performant, it does not degrade the overall request processing performance. Also, in a request processing pipeline, making HTTP calls are many order of magnitudes slower than having to perform an extra join operation, and so business web application should not used the latter as a reason to instead return identifier values in response.</p>
	
	<h5>Three unique constraints per table</h5>
	<p id="1614573090">In a <a href="#1613709139" data-nav-id="1611200362">section</a> for database normalization under the data-storage glossary, it is suggested to always try to define for a unique combination for a record in the table. In a <a href="#1614199777" data-nav-id="1609472905">previous section</a>, this criteria is further strengthened and it is asserted that a normalized table should only have 1 unique constraint. However, with recent discussion about the identifier and slug columns, this criteria should be updated to: <strong> Each table should have 1 primary key constraint over a number valued column (which is unique and not null), 1 unique and not null constraint over slug field, and finally, one more unique constraint derived from the role of the table in the overall business process.</strong></p>
	
	<h4>Text optional-valued fields</h4>
	<p id="1614199557">Let's say you are trying to model a feedback form with an optional comment field. One way is to have a database table consist of this text response field along, a primary key, and a foreign key to user that is giving the feedback. Here's the question: When no feedback is given, then should the text response column be allowed to have null value, or should a default value of "empty string" be added. One may say that null value means the user hasn't yet answered the question (maybe, because they haven't seen it as yet), but then what does an empty string mean? ..that the user answered, and the answer they gave is nothing. And how is this different from a user that did not answer? Let's  ask a related question: Let's say a webpage is made to display this text data in a html &lt;input&gt; element. When the feedback field has no data, and let's say the corresponding value stored in table is null, then the html &lt;input&gt; element will still show an empty box, which is same as if it received empty string as the value from server. So, when the server data is presented on a website, having null versus an empty string for an optional text field does not make a difference. Hence, if a table column contains optional text, then a good design is to set a default value of empty string and not allow it to store null value. This also follows from a statement made <a href="#1614198575" data-nav-id="1609472905">earlier</a> that whenever possible, a default value should be added in the column. This suggestion is also mentioned in <a href="https://docs.djangoproject.com/en/3.1/ref/models/fields/#null" target="_blank">Django docs</a>. Above being said, it is also cautioned to not use it indiscriminately. Don't set any string valued database field to have a default value of empty. For example, a datetime column should allow for null values and not change it to empty string because an empty datetime string is an ill-formmated edatetime entry. Instead, a field should be nullified if no alue exists.</p>
	
	<h4>Date vs Datetime vs ZonedDateTime</h4>
	<p id="1614824110">"To time or not to time" would be one of the big questions you'll come across when developing schema. The advantage of not storing time, and just the date portion, is that the indexes will be comparatively smaller. It is easier to query for entries matching a particular date, rather than them having dateTime entries in range from midnight of a given date up to midnight of the next date. Try doing the same if you now want entries on one of the dates in a list, and it becomes clear very quickly that wherever possible, it is advantageous to only store date. That being said, storing date and not time, means there is a loss of data that could have been collected and probably could be useful later. Hence, "To time or not to time" is a question that will test your understanding of business requirements being modeled in database tables. The question becomes more pervasive with the realization that a "date" data-type does not define a timezone, but a "dateTime" does. Consider an extremely simple question just waiting to be answered: What is the date on 14th of March, 2021? Is the answer an obvious "14th of March, 2021"? Not quite. Let's expand the question: "What is the date in New Delhi (India) on 14th of March, 2021 in Seattle, Washington (US)?" Now the answer is not unambiguous. At 2AM on 14th of March, 2021 in Seattle, the date is 14th of March in New Delhi (India). But at 11PM on 14th of March, 2021 in Seattle, the date is 15th of March, 2021 in New Delhi (India). So, it seems that as long there is a time-component provided, everything is back to a happy state. How about "What is the date in New Delhi (India) on 14th of March, 2021 in Seattle, Washington (US) at 12:30AM"? The answer seems like a sureshot "14th of March, 2021", but chances are some applications would break - the ones which are good will break - because 14th of March, 2021 marks the start of daylight savings and so 12:30AM isn't uniquely defined. Is it 12:30AM Pacific Standard Time (or, PST), or 12:30AM Pacific Daylight Time (or, PDT)? This matters because the answer to "What is the date in New Delhi (India) on 14th of March, 2021 in Seattle, Washington (US) at 10:40AM PDT" is 14th of March, 2021 (because it'll be 11:10PM in India), but the answer to "What is the date in New Delhi (India) on 14th of March, 2021 in Seattle, Washington (US) at 10:40AM PST" is 15th of March, 2021 (because it'll be 12:10AM for the next day in India). Ok - but is it necessary to provide timezone and could this issue not be solved by simply using the timezone for the corresponding time, so 10:40AM on 14th of March, 2021 is clearly going to be in PDT and not PST? There are 2 issues: (1) The timezone isn't defined for when the timezone cross over is happening. (2) if a user queues up this request, say, on 1st of March, 2021, then what is the definition of "correct timezone to use" - should it be the date in the question (i.e., 14th of March, 2021) or date when the question was queued up (1st of March, 2021). There is no single answer for it because it depends on business use case. Bottom line: You either deal with "date without time zone" or "dateTime with time zone" - there's no middle.</p>
	<p id="1614827655">So, you started with wanting to store date, got some business use case and quickly switched to storing dateTime, just to find timezone come uninvited. What now? What now is to understand the devil. First thing first, timezone have traditionally been defined as the constant offset from the <a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time" target="_blank">UTC</a> (side-note, and to up the confusion: UTC is not <a href="https://en.wikipedia.org/wiki/Greenwich_Mean_Time" target="_blank">GMT</a>; side-note#2, and to some relief: UTC will be your best friend in dealing with the timezone craziness!). This is not totally true. As shown in above example, there are changes from daylight saving. For the same longitude, cities that lie close to Earth's equator, will typically not have daylight saving, whereas those close to poles will have it. And then there's <a href="https://stackoverflow.com/questions/35462876/python-pytz-timezone-function-returns-a-timezone-that-is-off-by-9-minutes/50613134#50613134" target="_blank">this StackOverflow post</a> which identifies that the definition of a timezone can change over time! With this understanding, here are some of the helpful tips to navigate this quagmire: (1) If you need to only store date and not time, then just store date. However, realize that you're missing out the time data. Also, with date alone, one cannot define timezone, and so "date" and "location" based queries won't mix. For example: If you want restaurants in Dallas, TX and San Francisco, CA that is open even after 11PM local time on a certain date, that'll be an ill formed query, because, as explained via example above, 11PM in San Francisco, CA means it's the next date in Dallas. The restrictions due to storing date type data does not mean that it's an all-out bad option. For one, you can always build your application with just date portion. When you hit a roadblock due to new business requirements, then modify to use a datetime column and append "00:00:00" (i.e. midnight) to all date entries, and you've got dateTime type data now. (2) All the examples above show that when storing dateTime, then timezone should also be stored. But how? Storing offset from UTC is not a correct way to store timezone, although that is what most database applications will offer. The suggested solution is a 2-part: (a) Always store all your dateTime entries in database in UTC, no exception, and, (b) add a separate timezone column in one or more database tables, wherever needed, and use it to translate from the UTC dateTime stored in database to the value expected by user, or vice-versa. Due to relation between different table, it might be possible that many child tables use the same timezone column defined in a parent table. So, realistically, you'll just have only a few timezone columns and not one for every dateTime column made in the schema. (3) For storing timezone values, use text-valued "TZ database name" from <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones" target="_blank">list of timezones</a> and don't use constant offset value. For example, use values like <code>America/Chicago</code> or "<code>Asia/Seoul</code>.</p>
	
	<h4>Enumerated data</h4>
	<p id="1613947022">An enumerated data is one that can only take certain fixed values. Almost always, they are text valued fields and are represented in the entity class using an <code>Enum</code> data type. These values can be used to associate special business related meaning to the table entry. In context of the <a href="#1612649521" data-nav-id="1612649521">example application</a>, particularly the "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" section, these values can be used to identify a bank account as either being a "CHECKING" or "SAVING" type account. As another example, let's consider the scenario described <a href="#1613440014" data-nav-id="1609472905">above</a> that suggests to store positive values if a deposit was done and negative values if a withdrawl is done. However, for someone looking it data for the first time, it can be confusing because a positive value might equally mean that money was given back to customer which is opposite of the intended use. Since "DEPOSIT" and "WITHDRAW" are a business concept / term in themselves, and the amount deposited/withdrawn is a different concept, a better design would be instead have two columns, one containing a non-negative amount transacted and the other being the transaction type whichcan be "DEPOSIT" or "WITHDRAW". Dong so makes the tables more intuitive. A word of caution: don't do both of having an enumerated deposit / withdraw type column, and also store the transacted amount as being positive or negative because then there is a correlation between the two columns (i.e. if transaction type is "DEPOSIT", then amount transacted is positive, and if transaction type is "WITHDRAW", then amount transacted is negative), and this breaks 3NF normalization.</p>
	
	<h5>How to implement?</h5>
	<p id="1615044545">A question: why use values like "CHECKING", "SAVING", rather than smaller codes like "C", "S", or even numbers like 0, 1? Compared to codes like "C", "S", the use of full name is better because it gives someone looking at database entries a quick idea about the data being stored. This can be useful in avoiding communication pitfalls, specially as the team grows. Additionally, as the functionalities offered by the web application increases, it is more probable for collisions between different small-length codes to happen compared to if the full code name is used (for example, "C" for credit card account?). It may also be possible that some other table ends up using same small code (like, "C" for child insurance that the member has selected) which has a different meaning than the code used in another table. Using same code values is just something that can increase the potential for miscommunication and for them leading to errors. How about using values like 0, 1 instead? This design also suffers from the same problem as using small codes; And one more problem that it suggests presence of an implicit order among different options which need not be true and/or may change in future. For example, let's say the codes 0, 1 are used for checking and savings account. Maybe a requirement comes to allow checking account to automatically pull money from savings to cover overdraft, but auto money movement from checking to savings is not allowed. Someone may look at the requirement, and account-codes, and deduce that an account type with a certain code can pull money from any account types with a higher code. This achieves the desired behavior, but is done by using an ordered relation between the values 0 (the code for checking account type) and 1 (the code for savings account type), which wasn't the original intention for using these code values. That can become a potential problem. Let's say in future, a "CREDIT-CARD" type account is made with code=2, then it will not be able to pull money from checking or savings. Maybe that's the intention. Or, maybe the intention is to allow it to do so, in which case someone needs to study the how the codes are being used throughout the codebase and identify that it should be given a value of -1. What if the goal is to allow these accounts to pull money from checking but not from savings? Therefore, if you're trying to model "enumerated" data, do not use "ordinal" values to achieve the goal.</p>
	<p id="1615044550">There are 2 ways to include enumerated data: (1) use an <code>Enum</code> field in the entity class that gets stored (or, technical term "serialized") in the database as a string, and, (2) create a new table containing these enumerated data in different rows and then add a foreign key reference to those rows wherever it's needed. In both cases, a <a href="#1614440246" data-nav-id="1609472905">check constraint</a> can also be added to the column which stores the name of enumerated type. An advantage of using the first option is that all the data is already on the server and in-memory when the application is deployed. The <code>Enum</code> entry to use is queried from the corresponding <code>Enum</code> class. This contrast with the second option of making a new table wherein a join operation must be done everytime it is referenced by some entity. Here, the enumerated data is obtained by querying from database. However, the fix to lower performance of second option due to join calls is simple: Cache all row from the corresponding enumerated data table when the application is deployed and read from it! ORMs provide ability to do so. An advanage of the second option is that it is possible to modify enumerated data details in the database while the application is running and the changes get automatically picked up in subsequent calls (for example, instead of labeling the account type as "SAVINGS", you want it labeled as "SAVING", without an extra "S" at end). If using Enum type data in the application, doing this change would require making a code change, committing it, and then deploying the code again. But then, doing a redeployment is not a hard thing. An advantage of using the first option is that if any table uses the enumerated field, then a default value can also be assigned to it (because all possible <code>Enum</code> values are already defined, and one of those can be used as a default). With the second option, it is still possible to assign default value but only if a natural key is used when defining the primary key for the new table. However, doing so goes against a <a href="#1614542613" data-nav-id="1609472905">previous suggestion</a> to only use numeric valued primary key. This being said, one must also be cognizant of issues around adding an enumerated default value for a column. One way to identify the default value is to not use a specific enum entry and instead use the corresponding string value with which the enum entry gets persisted in table. Doing so causes duplication, i.e. same string value is defined twice, once with the <code>Enum</code> entry and then as the string value for use as default value. This can be problematic because the relation may get broken in future. Other option is to define <code>Enum</code> class in the application and use of its entry as a default value. The problem here is that if the entries in the <code>Enum</code> class changes in future, then all historical <a href="#1614440610" data-nav-id="1609472905">migrations</a> done previously where that value could be used would need to be changed. Another point to consider is that when using the first option, then it is easier for the developers to see the list of enumerated options. However, when using the second option, it is easier for external teams to identify the enumerated data entries because it can be queried in the database, and they won't have to search for it in the codebase. In the end, there are positive and negative points to both approaches - pick the one that you feel most comfortable with, and then stick to that approach. A small digression: note that using the second option of creating a different table for low <a href="https://en.wikipedia.org/wiki/Cardinality_(SQL_statements)" target="_blank">cardinality</a> enumerated data is one of the few good use cases for having a 6NF normalization. Database schema normalization is otherwise stopped at 5NF normalization (<a href="#1613523454" data-nav-id="1611200362">reference</a>).</p>
	
	<h5>Enumerated data and Inheritance</h5>
	<p id="1615078115"><a href="#1613947022" data-nav-id="1609472905">Earlier discussions</a> identified the use of enumerated data type to capture type or status of some business process. Realize that by doing so, this field can be used to achieve "<a href="https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)" target="_blank">Inheritance</a>" behavior in entity class(es). For example, consider if "checking account" and "savings account" are defined as two concrete implementation of some "account" abstract class. One way to model this is by having the database schema contain two separate tables for checking and savings account. An alternate design is to use a single database table to store all account data, and to identify whether they are checking or savings type account by adding an enumerated "account type" column. This is called <a href="https://en.wikipedia.org/wiki/Single_Table_Inheritance" target="_blank">single table inheritance</a> design (additional reference: <a href="https://en.wikibooks.org/wiki/Java_Persistence/Inheritance#Single_Table_Inheritance" target="_blank">here</a>) which is typically the simplest and the best performing solution. Single table inheritance design can be contrasted the multiple table inheritance design (reference: <a href="https://en.wikibooks.org/wiki/Java_Persistence/Inheritance#Joined,_Multiple_Table_Inheritance" target="_blank">here</a>) where data columns that are common to all the concrete entity class implementations are stored in one table and the data columns unique to each entity is then stored in separate tables. This could be a preferred design is the different concrete implementation have very different columns and it is more intuitive and space saving compared to storing different fields in single table. Due to the need for joins, the multiple table inheritance design does not have good query performance compared to single table inheritance design (..that being said, don't let it stop you from exploring the design because database latencies form a very small fraction compared to network calls). </p>
	<p id="1615177377">Let's consider the "<a href="#1613439952" data-nav-id="1612649521">Requirements - Part II</a>" of the example application where it is asked that the users can create messages, that can then be followed up. The two types of message have different requirements on what additional information must be provided and who is allowed to follow up on the message. The wide difference between the two implementation details is a good reason to model it as a multiple table inheritance. One example on how this can be implemented is by having a "CommonMessage" table with a column for numeric valued identifier (that acts as primary key), a foreign key column for the backAccount of user who created the message, and an enumerated data column for the message type. Two separate tables, "OtherMessage" and "TransactionMessage", can be made such that "OtherMessage" table contains a foreign key to the customer service representative who handled the issue, and "TransactionMessage" table contains a non-nullable foreign key to the disputed transaction entry and a non-nullable foreign key to the bank official who handled the issue. Both tables also contain a foreign key column to an entry in the "CommonMessage" table. With this design, when user submits a message, then the web application code should either insert an "OtherMessage" and corresponding "CommonMessage" entry, or it should insert a "TransactionMessage" and the corresponding "CommonMessage" entry. When developing the application code, additional care must be taken that it is never allowed to directly insert/delete into the "CommonMessage" table. This ensures that for every "CommonMessage" entry, there is strictly one (i.e., no less than one, no more than one) of either an "OtherMessage" or a "TransactionMessage" entry. One more thing to note is that at every place where a foreign key column is used, it is also not allowed to have null values. This aligns with <a href="#1614456323" data-nav-id="1609472905">previous discussions</a> that foreign key columns should not be nullable. In addition to inserting records, another use case is that it should be possible to query all messages regardless of its type. How does this model support that use case? To do so, one must query on the "CommonMessage" table and then left join with "OtherMessage" and "TransactionMessage" table. As mentioned above, by controlling how entries are added to these tables, it is ensured that each "CommonMessage" entry will have either an "OtherMessage" entry or a "TransactionMessage" entry. Notice how the "CommonMessage" entity is never directly used for writing data to the database and is used only for reading data, and "OtherMessage" or "TransactionMessage" is not directly used for reading data from the database and is only used for writing data to the database. This notion of you using a different model to update information than the model used to read information is called <a href="https://martinfowler.com/bliki/CQRS.html" target="_blank">Command Query Responsibility Segregation, or CQRS</a>. This is a level-up from method level command-query separation within a single class, discussed in a <a href="#1610226800" data-nav-id="1608344385">sub-section</a> under OOP in the architecture glossary; In here, a different entity class (and not just a different method) is used when inserting or retrieving data. A heads up, this concept will get another level up in a <a href="#1615299781" data-nav-id="1615299814">later chapter</a>.</p>
	<p id="1616192250">For sake of discussion, let's consider what would happen is a single-table design were used to model the requirements. The single table design will need to have the 3 columns identified for "CommonMessage" table. Additionally, it will need a column with foreign key to the customer service representative who handled the message if it were an "Other" type message; And for messages relating to a transaction dispute, it would need a foreign key to the "transaction" entry and a foreign key to bank agent's profile who handled the issue. However, since the message can be only a single type, so two new constraints need to be put: (1) if the message type is "Other", then the foreign key to the custom representative is not null and the foreign key to the transaction and to the bank agent is null, and, (2) If the message type is "Transaction", then the foreign key to the custom representative is null and the foreign key to the transaction and to the bank agent is not null. This table is already beginning to be extremely complex. Consider how more convoluted it will get as new message and corresponding constraints are added. Another obsrvation that can be made is that for each entry, one of customer service representative foreign key or bank agent foreign key will always be null. This goes against the <a href="#1614456323" data-nav-id="1609472905">previous design suggestion</a> to never have a null value in foreign key. In that discussion, it was mentioned that one of the <a href="https://stackoverflow.com/questions/7573590/can-a-foreign-key-be-null-and-or-duplicate/34682951#34682951" target="_blank">post</a> on the stackOverflow page giving example of places where a nullable foreign key can instead be modeled using a multiple table inheritance design. This section shows that if a single table design is instead pursued, then it can get extremely hard and complex to manage and extend it.</p>
	<p id="1616194397">Consider a slightly different scenario, where it is needed to "capture" the id of peronnel who handled the message. So, capture the primary key of the custom representative if an "Other" type message comes, and capture the primary key of the bank agent if a "transaction" type message comes. Also, let's say that for now, there's no need to capture the primary key of the transaction being disputed when a "transaction dispute" type message is being made. In this case, an alternate design could be to have a column called "handled_identifier", which captures the primary key of the customer service representative or the bank agent. Anyone who reads the table record will know based on the message type whether the handler identifier belongs to the customer service representative or the bank agent. A related advantage is that this design can be easily extended to include new message types and corresponding handlers. So what's the trade off? This is an example of a "not-relational" design discussed <a href="#1613443573" data-nav-id="1609472905">previously</a>. The trade-off with this design is it causes no database relations to form between the message table and the corresponding handler table(s). Hence, he entries in each table will exists independently of the other. Constraints like protection on delete, or cascading delete cannot be applied in such cases.</p>
	
	<h3>Migration</h3>
	<p id="1614440610">After the logical design for a database has been made, it is realized within the database using database specific commands. This transference process is called "Migration". Note that the word is originally borrowed from <a href="https://docs.djangoproject.com/en/3.1/topics/migrations/#module-django.db.migrations" target="_blank">Django migrations</a>. Even though it is used in the book, I am not aware if it is also used generally. In addition to creating the tables, this process can also be used to add entries in <a href="#1615044550" data-nav-id="1609472905">tables containing enumerated data</a>, create user groups and add permissions. Generally, the application framework performing migration initiates the processby accepting a list of commands or codes from user. From the list, any commands that have already been applied to the database are ignored. The remaining ones are translated into DDL commands specific to the database provider being used by the web application, and finally, the translated DDL commands are applied the database. For example, <a href="https://www.liquibase.org/" target="_blank">Liquibase</a> works by translating commands given to it as xml or groovy into corresponding DDL statements specific to the database provider. The advantage of doing so is to decouple the code from the underlying database being used. With this decoupling, one may use different underlying database and the migration application (i.e., Liquibase, in above example) will simply run different database DDL commands specific to the database provider causing the same schema to be generated. Performing migrations via commands that are stored and tracked in the <a href="#1608564873" data-nav-id="1608344368">code repository</a> rather than making ad-hoc changes in the database has multiple advantages. It allows developers to understand past changes done on the database, if any migration might have been missed or is erroneous and to automatically set up new database instances on demand and setting the schema without manual intervention. On that last point, an in-memory database with correct schema can be setup every time functional tests are done. Thus, performing migrations rather than making one-off updates to the database enables performing more rigorous and thorough testing, which then enables <a href="#1608565983" data-nav-id="1608344368">continuous delivery</a>.</p>
	
	<h4>Migration in agile environment</h4>
	<p id="1616262915">When developing in an agile environment, the database schema can evolve over time. Table and columns can be added or removed or altered. There are two different ways in which these migrations are achieved based on the different ways in which the list of commands provided to the migration application are modified over time. In either case, the end goal is to add new commands at suitable location in the overall list of commands such that if the new complete list of commands is run again on a new database, then the newly formed schema will be similar to if only the new commands are run to update an existing schema. One way to do so if by adding new commands in way that it preserves the "relationship order" of tables. For example, since a parent-table must be made before it is referenced by a child table, so, all commands relating to the parent table are added in the list before all commands relating to the child table are added. If new commands relating to update of the parent table needs to be added onto the list in future, then those commands are added above any past or future commands relating to child table. By design, this way of migration keeps together all commands relating to formation of a particular table. Another way is to only append new commands at the bottom of list of existing commands. Doing so preserves the chronological ordering of commands executed on the database. By design, this way of migration produces same schema if the whole list of commands are run or if only the new commands are run on an existing schema. However, the trade-off is that the commands relating to a single table can get distributed at different locations in the complete list of migration commands, and so it can become more involved to track the evolution of a table over time.</p>
	<p id="1616265894">When performing migrations, it is strongly suggested to only use the latter way of migration, i.e. append new commands at the end of existing list. This is suggested because doing so strongly guarantees that a consistent schema is maintained over time. The other way of migration may look aesthetically pleasing because all commands relating to a single table are close to one another and can be easily located, but it cannot provide guarantees of a consistent schema. On the contrary, in some cases it may even preclude migrations from being applied in future. As mentioned earlier, the migration process also includes creating data records, and so, the commands to create, update, or delete data entries must also be appended to the full list in a similar fashion, and along with other migration commands. If the migration application allows adding tags or names to the command, then the software ticket name and/or software release version can be added as part of the name to help with auditing of the migration commands. To mention one more point explicitly: as much possible, do not delete a migration command entry after it has been added to the database. The main reason is that most migration applications keep a record of any commands they have previously run so that it can be ignored when migrations are re-run in future. Deleting a command from the migration command list can cause the application to behave unpredicatbly because it won't be able to find it. Another reason is that if a command is deleted, then it can never be said with full certainty that running the complete list of migrations on a new database will give the same schema as running only the newly added commands on the existing schema because the effect of the deleted command will never be realized. Lastly, deleting a command will hide that information from the developers. If the command introduced a bug then it will become hard to identify and debug the issue.</p>

	<h3>Entity class design</h3>
	<p>Up until now, the discussions centered around design of the database tables. If the web applications uses an object relational mapping tool, or ORM, to map a database table to a corresponding entity class, then the design considerations around database tabled discussed in sections above, also show up when creating the entity class design. This section and its subsections delve into additional considerations that must be kept in mind when designing the entity class.</p>
	
	<h4>Super class</h4>
	<p id="1616345107">In a <a href="#1614573090" data-nav-id="1609472905">previous discussion</a>, it is suggested that a numeric identifier and a unique slug should be added for all database records. In a <a href="#1613711464" data-nav-id="1609472905">separate discussion</a>, it is suggested that fields like record create datetime and last modified datetime can be stored with each record if it serves a business need. Such requirements are codified in a better manner by creating a super class and having the concrete class corresponding to the entity extend it. In doing so, these common behaviors get consistently applied across each entity class definitions.</p>
	
	<h4>Custom fields vs custom getters and setters</h4>
	<p id="1616347263">Consider when storing a datetime entry in database. At the code level, the corresponding field in the entity class is of <code>DateTime</code> type. However, when persisted in the database, it is generally saved as a string with a certain format, or may as the long value equivalent of a datetime. Either way, you don't worry about the type conversion because the ORM does it transparently. Consider the case: let's say, an entity class uses <code>Enum</code> type fields. How should this be stored in database? Should the enum's name be stored, or its value, or some other value? One way to handle such requirements is to define custom ORM field definitions that explicitly defines how to serialize a field value when it is being persisted to database and also how to deserialize it back after reading from the database. Another way to achieve the same result is by defining custom getters and setters for the field in the entity class. The getter methods act as a proxy layer between the values read from the database and the ones returned to any other method wanting to get the field value for an entity. It can be used be to customizing the field value sent out. Same can also be done when storing data into the database and customizations can be added by defining cutom setters. The advantage of defining a custom field rather than defining custom getters and setters is that it is more generic and the code can be reused.</p>
	<p id ="1616350214">An an example, let's say that the application is accepting sensitive data from the user, like, an image of their signature, or their social security number, date of birth, etc. For all these fields, it may be required (..or just a good practice even if not required) to encrypt it before saving it in database, rather than saving the data in clear text. Since there are multiple such data fields in one or many entity class that need to be handled in a similar manner, so it is preferable to define a custom ORM field that encrypts data before writing to database and decrypts it before handing out the data. Custom getters and setters can be used when a special behavior is needed for a specific field in an entity class and the code is not repeated at multiple places.  It is also perfectly ok for some code to start as a custom getter and then get refactored to form a new field definition because the code is getting reused at multiple places. An example for having a custom getter is there's a requirement to return the complete social security number only to an admin user, and otherwise only return the last 4 digits. Another example for using a custom getter is if a child entity extends a parent entity and a field is the child entity is modeled as overwriting value of similar field in the parent entity. In this case, a custom getter can be defined in the child entity that returns the value read from database, or if no value exists, then it returns the value for the field in the parent entity. An example of having a custom setter or even a custom constructor is when a default value for a field is programmatically added. For example, a table, let's call it, E1, is made to store enumerated entries, and another table, say, T1, has column that foreign keys into the E1 table. The E1 table has numeric valued primary key. The default foreign key value for the T1 table's column is determined by querying for a value from a unique, non-primary column in E1 table. As mentioned in a <a href="#1615044550" data-nav-id="1609472905">previous section</a>, this design doesn't allow a good way to set a default value for T1 column in DDL statement. In this case, a custom constructor for the entity class or the custom setter can be used.</p>
	
	<h4>Programmatic constraint</h4>
	<p id="1616555826"><a href="#1614440246" data-nav-id="1609472905">Check constraints</a> are an important sub-type of constraints used to limit the type of data entering the table. They can be applied both at table row level and at individual field in the row. However, certain cases may not be constrained via check constraints and are instead enforced programmatically. This section covers such cases. Hence, a programmatic constraint can be thought of as filling the gap in defining data constraints when a check constraint couldn't be defined due to limitations of the SQL language (..or maybe the developer didn't realize that a check constraint could have been defined)! A pre-requisite for being able to robustly enforce programmatic constraints is that all create or update or partial update of an entity class should be done via a single method. This single method provides a unique location where the programmatic constraints can be defined and consistetly applied on every data-entry and for every operation. Also, to mention explicitly, just like check constraints, the programmatic constraints should be based on field definitions and not on the business requirements.</p>
	
	<h5>Prefer check constraint if possible</h5>
	<p id="1616556905">An unfortunate case that most often happens is that the <a href="#1614440610" data-nav-id="1609472905">migration</a> application does not allow defining check constraints, forcing for the entity class to define programmatic constraints. When adding programmatic constraints, it is strongly suggested to spare some time on whether it is really needed to add programmatic constraints, or if it is possible to modify the migration code manually and include check constraints. If possible, always prefer adding check constraints because they apply at the database level and strongly ensure the validity of data in the database, regardless of the application that is creating or updating it.</p>
	<p id="1616637839">Above being said, programmatic constraints can be helpful in improving data consistency of existing tables that did not define check constraint and maybe couldn't do it anymore. One example would be <a href="#1616192250" data-nav-id="1609472905">use of single table</a> to store entities with different fields / constraints in each concrete implementation. By adding a giant "if-elseif-else" branching statement performing validations specific to an individual implementation, an effect can be obtained similar to validating the data against corresponding check constraint and before saving it in the database.</p>
	
	<h5>Referential checks</h5>
	<p id="1616634984">Consider the "<a href="#1613439952" data-nav-id="1612649521">Requirements - Part II</a>" of the example application. By that point, there is already a <code>User</code> and <code>BankAccount</code> table. Let's say that based on user interaction research, it is identified that users would want to see the most recent transaction and they do so much more often and frequently that actually making a transaction. Let's also consider the case that there are a lot of users for the bank. With this setup, if the <code>AccountTransaction</code> table is made such that it has foreign key to the <code>BankAccount</code> table, which itself has a foreign key to the <code>User</code> table, then it may be not be a very performant design. This is because for each request, the database will first have to find <code>BankAccount</code> for the user making the request, and then perform a query over <code>AccountTransaction</code> table using the identifier for the bank account. It is identified in a <a href="#1611408137" data-nav-id="1611200362">sub section</a> with the data-storage glossary that it is expected for normalization to hurt performace, and the way to get better performance is via denormalization. Applying this knowledge to the problem, an alternate solution can be identified where a foreign key to the <code>User</code> table is stored in the <code>AccountTransaction</code>, in addition to also storing a foreign key to the <code>BankAccount</code> table. Now, one can directly query the latest <code>AccountTransaction</code> entry for a <code>User</code>. However, doing so leave open the possibility of having inconsistent data relations. Rather than throwing away the alternate design using denormalized schema, let's consider the following: if it can be guaranteed that every time an <code>AccountTransaction</code> entry is created or updated, then an extra check is done to verify that the <code>User</code> entry associated to the <code>AccountTransaction</code> is same as the <code>User</code> entry associated to the <code>BankAccount</code> entry associated to the <code>AccountTransaction</code> entry, then the data in the tables will always be consistent; And with there being much more requests to read the latest transaction than to create a new one, the performance benefit from faster reads over the denormalized schema will outweigh the performance reduction in doing the extra check when transaction is created. This extra check is called a referential check because it checks the consistency of various references, and this is an example of having a constraint get enforced via code even though it is not present in the database.</p>
	<p id="1616807737">In a previous section, the concept of a "<a href="#1613443573" data-nav-id="1609472905">Not-relational</a>" table was introduced. One example of its use is in making <a href="#1613443385" data-nav-id="1609472905">audit table</a> where a single table can store details about add / update operation done on entries in other table. The "not-relational" design was used to otherwise prevent a multitude of different tables from getting made. Similar design is also seen at <a href="#1616194397" data-nav-id="1609472905">another place</a> when a single table design is used to store entries corresponding to different concrete implementations of a single base class, each entry identified using a different enumerated value. Consider the case where the code for deletion of a table entry is written in a way such that all audit table entries are also deleted within the same transaction (..not that the suggestion is to delete entries from audit table, but just consider if someone codes it that way). This extra code makes the audit table "programmatically behave" as if it did have a relational behavior with the corresponding table, even though no such relations exist. Similar linking can also be done in the example of the single table design. This shows that programmatic constraints can be used to realize "relations" between tables that aren't defined in the database schema. However, it is strongly suggested that as much possible, this should not be turned into a mainstream use-pattern because one loses the benefit of defining data relationship and consistency checks provided by the database. A single slip in the application code where the relations are not accounted for will let bad data creep inside the database table; And with the growth in application features, it is just a matter of time before an accident like this happens.</p>
	
	<h5>Constraint on create and update</h5>
	<p id="1613746290">In a <a href="#1613520117" data-nav-id="1609472905">previous section</a>, it is identified how a denormalized design can get imposed on to meet business requirements. Programmatic constraints can be used to restore normalization in the way the application interacts with the database. Consider the example where a database table needs to store both the last modified datetime and the last modified date of the entry. The denormalization is coming from the fact that same data, i.e., the last modified datetime, is being stored in two different formats. One way to restore the normalization is to only define a getter for the last modified date, and not define a setter for it (or define the setter that does not do anything), and define a setter for the last modified datetime field that updates both the last modified datetime and the last modified date at same time. With this change, the values in the two fields will never get out of sync with each other, and will maintain data consistency. A database level check constraint can also be added to ensure that the date portion of the 2 columns are always same.</p>
	
	<h5>Modeling locks</h5>
	<p id="1616833826">Consider the example discussed in a <a href="#1614456323" data-nav-id="1609472905">previous section</a> discussing scenarios where foreign key can be null. The design suggestion is to make a <code>Client</code> table, a <code>SalesRepresentative</code> table, and when a sales representative is associated to the client, then create an entry in the <code>SalesCampaign</code> table with non-nullable foreign key to the corresponding entries in <code>Client</code> and <code>SalesRepresentative</code> tables. Based on the discussions in the <a href="#1615177377" data-nav-id="1609472905">enumerated data table design</a> section and previous subsections on programmatic constraint, it can be seen that creating an entry in <code>SalesCampaign</code> table when a sales representative is assigned to a client has similar data and relational content if the <code>SalesCampaign</code> is not made and instead a nullable <code>SalesRepresentative</code> foreign key is added to the <code>Client</code> table (as suggested in the corresponding StackOverflow answer); Also that this is done with the understanding that if the <code>SalesRepresentative</code> foreign key is null, then the <code>Client</code> exists but no sales representative has been assigned. Doing this change is like going away from a multi table design corresponding to the assigned and non-assigned status of the client, and instead using a single table design. Two additional optimization are applied: (1) Since the client status can either be that they haven't been assigned a sales representative, or that they have been assigned one, so the value of foreign key being nullable or not is used as a proxy to identify the status, and no extra <code>status</code> column in made in the <code>Client</code> table; (2) In this example, there can only be one sales representative associated to a client. Again, this matches what has already been mentioned in the corresponding StackOverflow post. There's nothing new, except an understanding that within the constraints of the problem, the solution in the post and the one mentioned in this ebook are similar.</p>
	<p id="1616835133">Let's expand on the requirements to see if we can get more insights. Let's say that for each client, two sales respresentative must be assigned before any work starts. This assignment is done by some administrator who should be able to see the list of clients and the 0-2 sales representative associated to them. How should this be modeled? A quick but important note: This requirement of gathering multiple entities so that they can be assigned on some task is called "locking". I am not sure if this is standard term in database modeling, but it does relate to similar feature being provided by various programming languages. Coming back to the discussion: If we're being absolutely stickler about "foreign keys cannot be nullable" rule (discussed <a href="#1614456323" data-nav-id="1609472905">previously</a>), then a way to design it is by having a <code>Client</code> table, but with an extra column containing the count or text status of the assigned agent, and with default value of 0. Next, two sales assignment tables will be needed, say, <code>OneRepresentativeSalesCampaign</code> conatining one column with foreign key to the <code>SalesRepresentative</code> table, and, <code>TwoRepresentativesSalescampaign</code> containing two columns with foreign keys to the <code>SalesRepresentative</code> table. When one sales representative is assigned, then the assigned count in <code>Client</code> can be updated to 1 and an entry of the assigned sales representative can be made in the <code>OneRepresentativeSalesCampaign</code> table. When one more sales representative is assigned, then the assigned count in <code>Client</code> can be updated to 2, the previous entry of the first assigned sales representative in the <code>OneRepresentativeSalesCampaign</code> table can be deleted, and a new entry in <code>TwoRepresentativeSalesCampaign</code> table can be made with foreign key to the 2 assigned sales representatives. Getting a list of all clients and corresponding assigned sales representative would require having a separate view that can join with correct table based on the assigned count in the <code>Client</code> table. This being a multi table design, additional constraints specific to each table can be easily added. For example, a check constraint can be added on the <code>Client</code> table that the assigned count can only have values of 0, 1, 2. A check constraint can also be added to <code>TwoRepresentativeSalesCampaign</code> table that the two foreign keys are not the same, i.e. the same sales representative is not assigned doubly, because that would be absurd. If the sales representatives can belong to some sales department, then the departments of the two sales representatives can be verified to be same. Thus, it is possible to implement the requirement such that there are no nullable foreign keys. The downside is that if the requirement changes to allowing 3 or 4 representatives to be associated, then the table count proliferates, even though for a single <code>Client</code>, there will be an entry in just one of the various tables.</p>
	<p id="1616836683">Let's consider some alternate designs to achieve the same requirement, and also allowing the foreign key columns to be nullable. One possibility is to apply the single table design by enhancing the <code>Client</code> table to contain two extra columns that foreign keys to the <code>SalesRepresentative</code> table. These two columns are also allowed to be nullable. In previous <a href="#1616192250" data-nav-id="1609472905">section</a>, it was shown that adding a check constraint for single table can get progressively complex and unmaintainable, so let's not add any check constraint to the <code>Client</code> table. With this design, the table can be easily queried to obtain all client records and the corresponding sales representatives associated with them. New representatives can be easily added or replaced. However, since the database check constraints aren't applied in this design, the web application must instead used programmatic constraints to maintain data consistency. For example, checking that the two sales representatives are not same, and belong to the same sales department is checked programmatically. If a "sales campaign start date" field is defined as the first time when two sales representaives are assigned, then this field must be populated by programmatically checking if the condition holds. This check can be done by the mathod that persists the entity onto the database. An advantage of using this design is that the count of tables do not proliferate if the requirement is changed to allowing multiple representatives to be associated. A disadvantage is that the data consistency validations are maintained at the web application level and not at the data level.</p>
	<p id="1616892068">A follow up question to the design in the previous paragraph: Does adding two new columns in the <code>Client</code> table deviates away from a normalized design? Should the design instead be that a new <code>SalesCampaign</code> table is made with foreign keys to the <code>Client</code> and <code>SalesRepresentative</code> entries; And the <code>SalesCampaign</code> table identifies the sales representative associated to the client. The answer is yes - a new <code>SalesCampaign</code> table shold be made. However, adding two columns to the <code>Client</code> table is something that easily be corrected later on and without any data loss. As mentioned <a href="#1613442382" data-nav-id="1609472905">earlier</a>, when developing in agile environment, it is possible for database to not be fully normalized, and this is ok to happen. Let's say that we want to use <code>SalesCampaign</code> table. In this case, how can it be constrained that one client can only be assigned up to two sales representatives? One option is to have a programmatic constraint verify that when adding a sales representatives, then no more than two sales representatives are associated to the client. Another option is to store the count of associated sales representatives in <code>Client</code>, update this value every time a sales representative is associated to or unassigned from the client, and restrict this count to be 0, 1, 2 using a check constraint defined on the <code>Client</code> table. The advantage of the former option is that it is simpler to execute. The advantage of the latter option is that it makes transparent to others reading the schema that some relation exists between the <code>Client</code> and the <code>SalesCampaign</code> table and that a constraint is made on it.</p>
	<p id="1616902428">In the above paragraphs, different ways to model the locking requirement is provided. Generally speaking, same considerations also apply when designing for a situation where an enumerated data column identifies the one among multiple concrete implementation that should be used for defining the entity. Why is it that the data modeling guidelines for other situations there are clear cut, but it becomes very vague when modeling the locking requirement. I believe it is because of 2 reasons. One is that for such cases, it is relatively easy to switch from one design to another without losing any data and so the advantage of chosing a design over another isn't clear cut. Another reason is that it is ambiguous to model an entity which goes through different stages between it's initial and final form. For example, a client entity starts its lifecycle with no sales respresentatives being associated with it. Then, it can have one representative, which is still a valid stage in the lifecycle of the client entity, but is not a final stage. Only when it has two representatives associated to it does it come to its final form signalling that additional work can now be done on it (i.e, sales campaign for the client can start). Here's the question: at the time when the client has one sales representative associated with it, should it be treated as an altogether different entity than its start and end stage, or should all three stages be treated as same entity with just some information missing? If it is the latter then what constraints apply on the table at all time versus what constraints are specific to an intermediary stage? And is there a way to define any intermediary stage constraints on the table itself, or should it only be enforced via programmatic constraints? And finally, does the answer to above question depends on how many intermediary stages are there? Would one design be preferred if there are 2-3 intermediary stages, and would another one be preferred if there are 20-30 stages? To matters a bit worse, development in an agile environment means that new stages can come up in future. Maybe something started as a good choice but would later need to be refactored! My suggestion would be to just start with one of many possible designs to handle the solution. The worst thing to do would be to have hair splitting architectural discussions and not have a developed product in time.</p>
	
	<h4>Non-updatable field</h4>
	<p id="1616830940">ORM framework provide capability to identify a table field as something that should only be created but can never be updated again. This behavior of not being able to update a field can be used in different scenarios. For example, disallowing update of the identifier column of a table, based on <a href="#1614542613" data-nav-id="1609472905">previous discussion</a> which identified that a good practice is to never update the identifier of a table entry. Anothe example is to disable updates for all column of the <a href="#1613443385" data-nav-id="1609472905">audit table</a> because the entries in an audit table should not be changed once it is created. A third example could be to disallow update of values that strongly relate to entry creation event, like, the entry create datetime. There's no reason to modify it and it should always be set just once.</p>
	
	<h4>Constraining vs Saving</h4>
	<p id="1616831542">It is mentioned <a href="#1616556905" data-nav-id="1609472905">above</a> that a pre-requisite for being able to robustly enforce programmatic constraints is that all create or update or partial update of an entity object should be done via a single method. Another method that should occur exactly once within the entity lifecycle, whether creating or updating or partial updating an entity object is the <code>save</code>, i.e. the method to actually persist the new or changed values in the database. Due to this correlation, many a time, there is a confusion in the way these methods are defined and the logic for one is added to the other. This section recomends keeping the logic for programmatic constraint and validation separate from the logic of saving an entity. I know that at least in Django, this is made exlicit by having separate <code><a href="https://docs.djangoproject.com/en/3.1/ref/models/instances/#django.db.models.Model.clean" target="_blank">clean()</a></code> and <code><a href="https://docs.djangoproject.com/en/3.1/ref/models/instances/#django.db.models.Model.save" target="_blank">save()</a></code> methods. The reason for the difference is that one of them applies the programmatic constraint validation and the other does additional tasks that must be executed when saving data. Saving the last modified date based on the value of last modified datetime is one such process that is better done as part of saving the entity rather than as part of constraint validation. Adding a process to create thumbnail of a profile image based on the image provided by the user is another example of process that sould be done when saving the entity, and not when performing validations on it.</p>
	
	<h3>Keep entity as much constrained</h3>
	<p id="1612756799">In context of the <a href="#1612649521" data-nav-id="1612649521">example application</a>, particularly the "<a href="#1612650690" data-nav-id="1612649521">Requirements - Part I</a>" section, it is mentioned that a "user" will have a username. Let's say the username is stored as a string within the entity, and as a text in database, as is generally done. Here's a question: should the username allow having all <a href="https://home.unicode.org/" target="_blank">unicode characters</a>, or just a-z? How about A-Z in capitals? What about special characters like &gt;, &lt;, etc.? At least for the special characters, we know that if those are allowed, then the application may become vulnerable to <a href="#1608866075" data-nav-id="1608343369">XSS attack</a>. Let's say that the username field is allowed to have a-z, A-Z, 0-9 characters, and this worked good initially. However, when your business expanded to Germany, the users complained about not being able to add umlauts. Should you as the developer have anticipated that the application can be used in Germany and so the username field should be coded to enable storing umlauts? The answer is: No. Generally, <strong>one must NOT let a possibility of future use deviate the application from being designed, code and constrained to only support the known and current use cases.</strong> Only after a new requirement or after a user complaint comes, then the definitions of the entities being used in the application should be expanded and the constrainst relaxed; Do not do it pre-emptively when a feature is not being asked for. This also helps in restricting the scope of work being done by developers to only code and add unit tests for the features needed and no more. Not doing more work that needed is a good practice because with extra work that nobody asked for comes extra features and complexities that nobody wants which are hard to maintain, waste time and money, and generally get removed in future. This being said, if you feel that adding a feature would help the product become better and more robust, then discuss the idea with the product managers and the senior teachnical leads. Maybe, they'll like and want to inlude it, or maybe you had a misunderstanding about how the product works and the extra feature is not needed, or maybe they are aware of it and waiting for a more proper time when the new feature can be introduced. A quick side note: Preventing XSS attack by constraining the text that goes in the database is a side benefit of having a constrained design. The prevention should be seen as a primary reason to constrain the design. The primary reason to constrain the design is to provide clear product goals to the developers so they can code as needed.</p>
	<p id="1616906931">Other example of entity level data constraints are: allowing text data in specified format only, numeric entries should be within some reasonable minimum and maximum value and numeric value precision should be up to specified decimals and not arbitrary. <a href="#1614191105" data-nav-id="1609472905">Table and column constraints</a> and <a href="#1616555826" data-nav-id="1609472905">programmatic constraints</a> also help in constraining the entity definition. Also, <a href="#1614440246" data-nav-id="1609472905">as mentioned earlier</a>, when defining entity constraints, one must make sure that it relates to the field or table definition and not to business requirements.</p>
</article>
