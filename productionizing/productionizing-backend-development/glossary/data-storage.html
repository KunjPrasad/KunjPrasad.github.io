<!--
    Productionizing Backend Development - Data storage glossary, by Kunj Prasad on Github.
    Copyright (C) 2020  Kunj Prasad

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published
    by the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-->
<html lang="en-us">
	<head>
		<meta charset="utf-8">
		<title>Productionizing Backend Development - Data storage glossary</title>
		<meta name="description" content="Glossary for the book on Productionizing Backend Development containing concepts and terms related to data storage, like, on memory, disk, database and cache.">
		<meta name="author" content="Kunj Prasad">
	
		<!-- Meta with information that otherwise should have come in request headers -->
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<meta http-equiv="Pragma" content="no-cache">
		<meta http-equiv="Cache-Control" content="no-cache">
		
		<!-- Browser related meta -->
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
		<meta http-equiv="X-UA-Compatible" content="IE=Edge">
		
		<!-- OpenGraph related meta -->
		<meta property="og:url" content="https://kunjprasad.github.io/productionizing/productionizing-backend-development/glossary/data-storage.html">
		<meta property="og:site_name" content="Productionizing Backend Development book on Kunj Prasad's website">
		<!-- Not yet added image: <meta property="og:image" content="https://kunjprasad.github.io/assets/social_media_logo.png"> -->
		<meta property="og:title" content="Productionizing Backend Development - Data storage glossary">
		<meta property="og:description" content="Glossary for the book on Productionizing Backend Development containing concepts and terms related to data storage, like, on memory, disk, database and cache.">
		<meta property="og:locale" content="en_US">
		<meta property="og:type" content="article">
		<meta property="article:publisher" content="Kunj Prasad">
		<meta property="article:published_time" content="2022-02-28T00:00:00+00:00">
		<meta property="article:modified_time" content="2022-02-28T00:00:00+00:00">
		
		<link rel="stylesheet" href="/utilities/common-styles.css" type="text/css">
	</head>
	
	<body>
	
		<header>
			<h1>Data storage glossary</h1>
			<ol class="breadcrumb-container">
				<li><a href="/productionizing/productionizing-backend-development/">Home</a></li>
				<li><a href="/productionizing/productionizing-backend-development/glossary/">Glossary</a></li>
				<li>Data storage glossary</li>
			</ol>
		</header>
		
		<div id="note-status" class="note-status-sticky-header alert"><!-- The content here is filled dynamically by the script and gives information on notes, and file uploads, or unsaved changes --></div>
		
		<nav>
			<h2>Table of contents</h2>
			<ul>
				<li><a href="#introduction">Introduction</a></li>
				<li><a href="#memory">Memory, or primary storage</a></li>
				<li><a href="#secondary-storage">Secondary storage</a></li>
				<li><a href="#file-system-storage">File system storage</a></li>
				<li><a href="#database">Database</a><ul>
					<li><a href="#database-types">Type of database</a><ul>
						<li><a href="#rdbms">Relational database, or RDBMS</a></li>
						<li><a href="#nosql-db">Non relational database, or NoSQL database</a></li>
						<li><a href="#cache">Cache</a></li>
						<li><a href="#rdbms-vs-nosql">Relational vs Non relational database</a></li>
						<li><a href="#db-vs-fs">Database vs File system</a></li>
						<li><a href="#cache-vs-db">Primary storage database vs secondary storage database</a></li>
					</ul></li>
					<li><a href="#db-design-concepts">Database design concepts</a><ul>
						<li><a href="#db-schema">Database schema</a></li>
						<li><a href="#normalization">Database normalization</a></li>
						<li><a href="#denormalization">Database de-normalization</a></li>
						<li><a href="#transaction">Transaction</a></li>
						<li><a href="#cap">CAP theorem</a></li>
						<li><a href="#"></a></li>
					</ul></li>
				</ul></li>
				
				<li><a href="#"></a></li>
				<li><a href="#"></a></li>
				<li><a href="#"></a></li>
				<li><a href="#"></a></li>
				<li><a href="#"></a></li>
				<li><a href="#"></a></li>
				<li><a href="#"></a></li>
				<li><a href="#"></a></li>
			</ul>
		</nav>
		
		<main>
			<h2 id="introduction">Introduction</h2>
				<p id="1618627233">This page lists the various terms that relate to data storage. Although data storage is part of supporting infrastructure needed to host the web application, it is a big topic in itself and so, the various data storage related terms are discussed here, rather than in the <a href="/productionizing/productionizing-backend-development/glossary/infrastructure.html">infrastructure glossary</a>.</p>
				<p id="1611200928">An application capable of supporting a business must be able to interact with individual customer and provide services needed by them individually. Serving same set of data to everyone and everytime (..like this ebook) can't grow as a business because it ignores individual needs of someone who'd be willing to pay for the customized service. Since <a href="/productionizing/productionizing-backend-development/glossary/req-resp.html#http">HTTP requests are in themselves stateless</a>, so, it is necessary to have a "data-repository" where user specific data can be saved, and served back to the same user at a later time.</p>
			
			<h2 id="memory">Memory, or primary storage</h2>
				<p id="1611201475">(Reference: <a href="https://en.wikipedia.org/wiki/Computer_memory" target="_blank" rel="noopener noreferrer">Wikipedia</a>) Memory refers to a device that is used to store information for immediate use in a computer. The term "memory" is often synonymous with the term <a href="https://en.wikipedia.org/wiki/Computer_data_storage#Primary_storage" target="_blank" rel="noopener noreferrer">"primary storage"</a>. It operates at a high speed and is directly available to the CPU. An example of computer memory is a <a href="https://en.wikipedia.org/wiki/Random-access_memory" target="_blank" rel="noopener noreferrer">random-access memory</a> that allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory. The flip side of this high speed is that memory storage is very costly. As soon as the business gains some traction and the user data starts to increase, then it becomes exteremely costly to store all the data in memory. Worse, the data in memory is volatile and is lost if the application stops, crashes or if the power goes out.</p>
				
			<h2 id="secondary-storage">Secondary storage</h2>
				<p id="1611202564"><a href="https://en.wikipedia.org/wiki/Computer_data_storage#Secondary_storage" target="_blank" rel="noopener noreferrer">Secondary storage</a> differs from <a href="#memory">primary storage</a> in that it is not directly accessible by the CPU. The computer usually uses an input or output channels to access secondary storage and transfer the desired data to primary storage. Compared to the primary storage, the data access rate for secondary storage is much slower. However, secondary storage has a huge advantage of being non-volatile, i.e. it retains data when its power is shut off. Also, for storage of similar size data, secondary storages are much cheaper compared to a primary storage. For these reasons, secondary storage is primarily used to store data for a web application. In modern computers, <a href="https://en.wikipedia.org/wiki/Hard_disk_drive" target="_blank" rel="noopener noreferrer">hard disk drives (HDDs)</a> or <a href="https://en.wikipedia.org/wiki/Solid-state_drive" target="_blank" rel="noopener noreferrer">solid-state drives (SSDs)</a> are usually used as secondary storage. The access time per byte for HDDs or SSDs is typically measured in milliseconds (one thousandth seconds), while the access time per byte for primary storage is measured in nanoseconds (one billionth seconds). Between SSDs and HDDs, SSDs have smaller access time compared to HDDs, but are more costly, but, SSDs are still less costly compared to memory. For this reason, a web application may be designed to store frequently accessed or modified data in SSD storage, and move archived or unchanging data to HDDs. Other common options for secondary storage devices include USB flash drives, rotating optical storage devices (like, CDs and DVDs).</p>
				
			<h2 id="file-system-storage">File system storage</h2>
				<p id="1611499255">(Reference: <a href="https://en.wikipedia.org/wiki/File_system" target="_blank" rel="noopener noreferrer">Filesystem</a>)  A file system is a method and data structure that the operating system uses to control how data is stored and retrieved. Without a file system, data placed in a storage medium would be one large body of data with no way to tell where one piece of data stops and the next begins. By separating the data into pieces and giving each piece a name, the data is easily isolated and identified. The file system is responsible for organizing files and directories, and keeping track of which areas of the media belong to which file and which are not being used. Conceptually, the design and terms used in computer file system closely follows the method of storing and retrieving paper documents before the advent of computers. For example, each group of data is called a "file", and collection of related data forms a "directory". However, from an implementation perspective, a working computer file system resembles more as a notebook, where data chunks corresponding to a file are written on one or more pages that may be consecutive or non-consecutive, and there is an index section containing a mapping of file name and the corresponding sequence of page numbers. It should also be notes that although file system is most commonly implemented on secondary storage, it is also possible to define one on primary storage, as done by Linux's <a href="https://en.wikipedia.org/wiki/Tmpfs" target="_blank" rel="noopener noreferrer">tmpfs</a>.</p>
				<p id="1611502622">To understand how file systems work with an example, consider yourself as a note keeper. Let's say the first note you make is from your friends who asks you to save "This is the friend's note" with file name "friend.txt". You do this by writing "This is the friend's note|" text on page-1 of your notebook, and adding an entry on the notebook's index page that "friend.txt" entries are on page-1. The index page in this example maps to an <a href="https://en.wikipedia.org/wiki/Inode" target="_blank" rel="noopener noreferrer">inode</a> in a <a href="https://en.wikipedia.org/wiki/Unix-like" target="_blank" rel="noopener noreferrer">Unix-like</a> file system, and the page maps to <a href="https://en.wikipedia.org/wiki/Disk_sector" target="_blank" rel="noopener noreferrer">disk sector</a>, and the file system in this example is you! Note that the "|" sign at end is not a typo, an its use is discussed later. In this example, even though there many be more space left on page-1, it is not used to write any new note because according to the index entry, any and all entry on page-1 related to "friend.txt". This wasted space is called <a href="https://en.wikipedia.org/wiki/Slack_space" target="_blank" rel="noopener noreferrer">slack space</a>. At least for windows OS, I know that you can right click on a file, go down to "Properties" and then look at the number under "Size" and "Size on disk"; former will always be less than or equal to the latter because the latter also includes the slack space. Let's say that sometime later, the same friend asks you to get the note for "friend.txt". You first look at the index and see that the entry is on page-1. You go to page-1, read up to the first "|" sign, which is "This is friend's note|", and then return everything before the "|" sign. So you return "This is friend's note". That's the role of "|" sign, in that it marks the end of your note. In computer, the corollary is a <a href="https://en.wikipedia.org/wiki/Null-terminated_string" target="_blank" rel="noopener noreferrer">null termination character</a>. So you only read up to it. Alternately, in your index, you can store additional information about the total length of the file and then having "|" will not be needed. In computer file system, doing so maps to storing <a href="https://en.wikipedia.org/wiki/File_system#Metadata" target="_blank" rel="noopener noreferrer">metadata</a> in file system. There are some more uses of "|" sign which is discussed later. Consider another scenario where your friend asks to get the note for "new-note.txt". In this case, then you look at the index and don't find any entries. So, you just say that you don't have that value. This is how file system is able to identify if a file is missing. From a security perspective, only access by file name is allowed and not by disk sector storing the data.</p>
				<p id="1611503723">Let's consider another example: The same friend comes back and asks you to delete "friend.txt". Since you always check the entries in the index page to identify if a file is existing, so you take a short cut where you only delete the index entry for "friend.txt", and do not clear the actual "This is friend's note|" data on page-1. Now, if you're asked for "friend.txt" note, you won't find the entry in index and will say that the note is not found. Let's say your friend now now asks you to write "new-note" and save it under file name "new-note.txt". From the index page, you notice that page-1 is not linked to any file name. So, you write "new-note|" onto it . But page-1 already had some old data. With new note written on same page, page-1 now reads "new-note|riend's note|"; The new data simply overwrites the existing old data only as much needed. You also make an entry in the index that "new-note.txt" is on page-1. When your friend asks for "new-note.txt" data, you check the index to see that it is on page-1. On page-1, you now only read up to the first "|" sign, i.e. "new-note|", and return everything before "|", i.e. you return "new-note". Here, everything after the first "|", i.e. "riend's note|" is garbage data. Similar handling of data also happens in a computer file system where storage data is not proactively deleted when a file is deleted (<a href="https://searchstorage.techtarget.com/definition/solid-state-storage-SSS-garbage-collection" target="_blank" rel="noopener noreferrer">reference</a>).</p>
				<p id="1611503730">Now, let's say that your sister asks you to store a poem under "sister.txt". It take complete page-2, page-3 and small part of page-4. In the index, you mark "sister.txt" with value 2, 3, 4. Just a small referesh, here, page-4 has a slack space, but pages 2 and 3 do not have any slack space. Let's say your friend asks you to update "new-note.txt" and gives a long todo list to store. You write it on page-1. Then you notice that pages 2-4 are already filled and so you write the remaining story on page 5. You update the index with "new-note.txt" having data on page-1 and page- 5. Note that even though you can retrieve the "new-note.txt" and return it back to your friend as a single text, it is not necessary that it be stored in consecutive pages. You simply compensate for it by sequentially reading the data chunks regardless of whether they are consecutive or not. For whatever reason, you could have stored the todo list starting with page-5 and then write the remaining on page-1, and that's still ok because then, you'll read page-5 before page-1, and the index entry will also be updated correspondingly. For a computer file system to read the complete data stored in non consecutive disk sectors requires "hopping" from one to another sector and this is something that <a href="https://en.wikipedia.org/wiki/Solid-state_drive" target="_blank" rel="noopener noreferrer">SSDs</a> do faster than <a href="https://en.wikipedia.org/wiki/Hard_disk_drive" target="_blank" rel="noopener noreferrer">HDDs</a>, and that's why former is faster than latter. Do note that reading data in consecutiv disk sectors does not cause hopping. Hence, for reading data in "sister.txt", a HDD will have same performance as a SDD, even though it is distributed across multiple pages, i.e. disk sectors. Let's say that your sister now asks you to delete "sister.txt". If you now look at your friend's note, i.e. "new-note.txt", on how it's stored, you'll notice that even though it is a single file, it is starts on page-1 and then continues on page-5. After deleting "sister.txt", here is no longer any non-garbage data on pages 2-4. Had your friend asked you to make the todo list after your sister deleted her poem, it would have been on pages 1-2, rather than "fragmented" across non continuous pages. This is corollary to <a href="https://en.wikipedia.org/wiki/File_system_fragmentation" target="_blank" rel="noopener noreferrer">disk fragmentation</a>. Fragmentation naturally occurs when a file system has been in use for some time, and it hurts average speed of data retrieval from disk because retrieving data for a single file requires hopping from one disk sector to another. At least for HDDs, having data on consecutive disck sectors reads much faster than if they are on different sectors.</p>
				
			<h2 id="database">Database</h2>
				<p id="1608527531">See article about databases on <a href="https://en.wikipedia.org/wiki/Database" target="_blank" rel="noopener noreferrer">Wikipedia</a> and on <a href="https://www.oracle.com/database/what-is-database/" target="_blank" rel="noopener noreferrer">Oracle</a>. A database enables storage of "records", i.e., either structured or semi-structured data, so it can be read at a later time. Most databases store data on a <a href="#secondary-storage">secondary storage</a>, but it is also possible to have in-memory database that store data on <a href="#memory">primary storage</a>. For example, let's say you are watching a Batman movie, and the corresponding data to store is <code>(you, Batman-movie)</code>. At a later time, maybe you'd be watching a Superman movie and your friend is the one who's now watching the Batman movie that you previously watched. The corresponding data are: <code>(you, Superman-movie)</code> and <code>(your-friend, Batman-movie)</code>. In this example, the database would store three entries about the person who saw the movie and the movie that was seen.</p>
				
				<h3 id="database-types">Type of database</h3>
					<p id="1642782460">From the articles <a href="https://www.indeed.com/career-advice/career-development/types-of-databases" target="_blank" rel="noopener noreferrer">here</a>, <a href="https://www.matillion.com/resources/blog/the-types-of-databases-with-examples" target="_blank" rel="noopener noreferrer">here</a>, <a href="http://www.astera.com/type/blog/a-quick-overview-of-different-types-of-databases/" target="_blank" rel="noopener noreferrer">here</a> and <a href="https://www.geeksforgeeks.org/types-of-databases/" target="_blank" rel="noopener noreferrer">here</a>, it can be observed that there are various types of databases available. Depending on the business use case, one may be more suited than others. The most broad division is that of relational vs non-relational databases. and they are discussed below. Other classification categories also exist, like, if the database is on-premise vs on-cloud. Or, if the database stores data in row format, or in column format. For data stored in row-format, it is easy to get all fields corresponding to a particular record. This is the traditional maner in which databases store data. If a table column does not have many unique values, i.e., it has low cardinality (reference: <a href="https://en.wikipedia.org/wiki/Cardinality_(data_modeling)" target="_blank" rel="noopener noreferrer">Wikipedia</a>, <a href="https://stackoverflow.com/questions/10621077/what-is-cardinality-in-databases" target="_blank" rel="noopener noreferrer">StackOverflow</a>), then column storage allows for a more compact storage.</p>
					
					<h4 id="rdbms">Relational database, or RDBMS</h4>
						<p id="1608528587">See article about relational database on <a href="https://en.wikipedia.org/wiki/Relational_database" target="_blank" rel="noopener noreferrer">Wikipedia</a>. The "relational" adjective is used because the data is stored within the database in a manner to bring out the relations between different data pieces. Many relational database systems use <a href="https://en.wikipedia.org/wiki/SQL" target="_blank" rel="noopener noreferrer">Structured Query Language, or SQL</a>, for adding and querying relational data in the database. Using the example of users and movies in the <a href="#1608527531">previous section</a>, note that the data contains "Batman-movie" twice because there is just 1 such movie which is watched twice. One way to make this relation more explicit is by not storing individual data as-is, but instead making 3 "database-tables" of <code>viewer, movie, movie-view</code>, with "viewer" table containing 2 entries for <code>you, your-friend</code>, "movie" table containing 2 entries for <code>Batman-movie, Superman-movie</code>, and "movie-view" table containing 3 entries for <code>(viewer-1, movie-1), (viewer-1, movie-2), (viewer-2, movie-1)</code>. This design is better able to bring out the relationship between various data elements. For example, the design is able to convey the idea that the Batman-movie which was watched both by you and your-friend is the same movie.</p>
						<p id="1611406053">In addition to capturing and making visible the relationship between different data pieces, a relational structure also reduces data duplication. For example, if it is realized later that the "Batman-movie" is better identified instead as a "Batgirl-movie", then updating the data requires touching only 1 row in one table. Had the data been stored as-is and not in relational form, making this change would have required going through the entire database to make this update. Capturing data-relations also allows extending the data-model to easily include new relations. For example, let's say we want to capture the release date and the lead actors in the movie. Now, the "movie" table can be extended to include a year. For adding actor data, a different technique could be to make a new "actor" table can be made containing the actor name, and link them to the movie they are in; And this can be done without touching the "movie", "viewer" or "movie-view" table. A later discussion on <a href="#normalization">database normalization</a> discusses concepts to help identify when a new column can be made in a table vs when a new table should be made.</p>
						<p id="1611408137">With its awesome advantages, storing data relationship also comes with a disadvantage that it can hurt performance. With above example, let's say that our business model is that user provides us with some "movie-view-id", and we return details about the movie and viewer. Now, everytime this call is made, the database with first look in "movie-view" table to get an entry for the provided "movie-view-id", which will be like <code>(viewer-1, movie-1)</code>. However, the user doesn't understand what "viewer-1" or "movie-1" means. So, the database will first go to "viewer" table to get the information for "viewer-1", which is <code>you</code>, and then to "movie" table to get the information for "movie-1", which is <code>Batman-movie</code>. Combining these data pieces, the user can now be told that the entry they are looking for is <code>(you, Batman-movie)</code>. Contrast it with the case if the data wasn't normalized and there was just one table with duplicated (viewer, movie) entry. It would have required just 1 database call to get the required information compared to making 3 calls and then <a href="https://en.wikipedia.org/wiki/Join_(SQL)" target="_blank" rel="noopener noreferrer">"joining"</a> the data-pieces together. That being said, note that relation database makes extensive use of indexes to speed up joins (see section on <a href="#database-performance">database performance</a>).</p>
	
					<h4 id="nosql-db">Non relational database, or NoSQL database</h4>
						<p id="1608529017">See article about non relational database on <a href="https://en.wikipedia.org/wiki/NoSQL" target="_blank" rel="noopener noreferrer">Wikipedia</a>, <a href="https://www.mongodb.com/nosql-explained" target="_blank" rel="noopener noreferrer">MongoDB</a> and <a href="https://aws.amazon.com/nosql/" target="_blank" rel="noopener noreferrer">AWS</a>. In the previous discussion on relational database, it is identified that storing data in a relational manner promote data integrity and reduces data duplication (see <a href="#1611406053">here</a>), but it comes at cost of performance (see <a href="#1611408137">here</a>). Non-relational database takes the opposite route, prioritizing performance over relations. Although most articles on the web further decompose non relational database further in four subtypes, i.e. as a key–value pair store, wide column or a column-family store, document-store or graph store, I believe that the non-relation database is best seen only as a key-value store. If the value becomes a xml or json document containing multiple fields then the non-relational database becomes a <a href="https://en.wikipedia.org/wiki/Document-oriented_database" target="_blank" rel="noopener noreferrer">document-oriented database</a>. If instead of one "document", the database allows for multiple documents with similar structure and that can be identified based on a certain value, then it becomes a <a href="https://en.wikipedia.org/wiki/Wide-column_store" target="_blank" rel="noopener noreferrer">column-family store</a>. Take a key-value pair non-relational database and also store the relations between any 2 values, then it becomes a <a href="https://en.wikipedia.org/wiki/Graph_databases" target="_blank" rel="noopener noreferrer">graph database</a> (Reference: <a href="https://neo4j.com/developer/graph-db-vs-rdbms/#rdbms-graph-model" target="_blank" rel="noopener noreferrer">Neo4j docs</a>). At the end of day, each non-relational database requires you to give it a key, for which it will give a "value" back.</p>
						<p id="1642784692">On a theoretical level, different non-relational database can be seen as a key-value store. However, in practice, each of them are tuned to solving a specific business use case. Thus, using a Graph database where a document database is needed, or vice versa, is not recommended. Each database also come with special utilities that make it more preferable than others when targeting a particular business need. Since the primary use case for using a non-relational databases is to achieve a very fast store and query of key-value like data, that is added to database in high volume and at a very high rate, so, the non-relational databases are designed to also easily and quickly scale out horizontally. Similar to the relational databases, the non-relational database can also be "partitioned", so that the key-value pairs in a particular range are stored and queried in a particular shard; Doing so improves the database performance.</p>
						
					<h4 id="cache">Cache</h4>
						<p id="1608530099">See article about cahces on <a href="https://en.wikipedia.org/wiki/Cache_(computing)" target="_blank" rel="noopener noreferrer">Wikipedia</a>, <a href="https://aws.amazon.com/caching/" target="_blank" rel="noopener noreferrer">AWS</a>. A cache is a <strong>hardware or software</strong> component that stores data so that future requests for that data can be served faster; the data stored in a cache might be the result of an earlier computation or a copy of data stored elsewhere. An important precaution when using cache is to ensure that stale data is not being sent to user in a manner unexpected by user. Hardware components can include having L1 cache, L2 cache, etc. (reference: <a href="https://www.extremetech.com/extreme/188776-how-l1-and-l2-cpu-caches-work-and-why-theyre-an-essential-part-of-modern-chips" target="_blank" rel="noopener noreferrer">here</a> and <a href="https://stackoverflow.com/questions/3699582/what-is-the-difference-between-l1-cache-and-l2-cache" target="_blank" rel="noopener noreferrer">here</a>). Software components include adding code which checks for data in memory before checking on the hard disk drive (HDD), or storing highly reused data on a faster solid state drive (SDD) and keeping archived and infrequently accessed data on HDD.</p>
						<p id="1644365140">Caches can be set up anywhere there is a temporal correlation in responses. It enables speeding up the overall processing by returning a previous copy of the response rather than the alternate process of re-computing the response result from zero. A "cache hit" occurs when the requested data can be found in a cache, while a cache miss occurs when it cannot. For the cache to improve the overall processing response, its size should be of the order of request rate multiplied by the temporal correlation period of the response. Hence, for a highly repeating request, having even a small size cache would be sufficent to notice improvements, but for high request rate or not repeating request, even a large size cache wouldn't be helpful. As the cache gets full, it starts to remove old (i.e., least recently used) or unused (i.e., least frequently used) data on a "cache miss", so that new data can be stored, with the expectation that it will get requested for again. The process of removing data from cache is called "evication". Reuse of cache data defines its "hit rate". Optimizing a cache involves analyzing the way cache is used to ensure a high hit rate and with a low eviction rate (to get the benefit of cache use rather than terms getting constantly evicted and then re-loaded). A cache can also be configured as a distributed store wherein one cache node returns data corresponding to a particular "shard" or "partition" of entire dataset.</p>
						<p id="1644365230">Various types of caches can be added at different stages in a request processing, like, to store data pulled from database, or to store user profile for corresponding cookie, or even <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching" target="_blank" rel="noopener noreferrer">at front end to reuse previous responses</a>. As an in-memory key-value store, a cache can be used as a NoSQL database (<a href="https://www.infoq.com/news/2011/11/distributed-cache-nosql-data-sto/" target="_blank" rel="noopener noreferrer">reference</a>). One such example is <a href="https://redis.io/" target="_blank" rel="noopener noreferrer">Redis</a>. On the other hand, <a href="https://www.h2database.com/html/main.html" target="_blank" rel="noopener noreferrer">H2</a>, <a href="http://hsqldb.org/" target="_blank" rel="noopener noreferrer">HSQL</a>, <a href="https://db.apache.org/derby/" target="_blank" rel="noopener noreferrer">Apache Derby</a> and <a href="https://www.sqlite.org/index.html" target="_blank" rel="noopener noreferrer">SQLite</a> are some SQL database examples that can run in-memory.</p>

					<h4 id="rdbms-vs-nosql">Relational vs Non relational database</h4>
						<p id="1611510050">With the database category named as "relational" or "non-relational", it seems very easy to make a <a href="https://www.vocabulary.com/dictionary/reductive" target="_blank" rel="noopener noreferrer">reductive argument</a> that if relations are needed, then relational database should be used, and use non-relational ones for semi-structured or unstructured data because they don't enforce relations! But what if someone wants to use Oracle database, which is a relational database, and make a table containing 2 columns, one with a numeric "id" and other with a xml or json text? With this design, the Oracle databse, which is a relational database, how now been designed to store semi-structured information! On the other hand, note that graph database also stores relations just like relational databases, but the former is a non-relational database! Another example if using a non-relation database, like Cassandra, which is a column family store, and programmatically store data within it in a normalized form! On the other hand, an Oracle database can be used to store denormalized data, and it won't be that the database will somehow stop working! So, what's the difference between the two? To me, the difference between the two is not about "what is one that is not in another", but instead, "what one can do better, out of the box, without less work from developers, than the other", which further relates to "which database suits the use case better". If your business requires good data integrity and an ability to expand database tables as the business grows and the data model gets richer and complex, go with relational database. If your business is getting hosed with data, and the user just expects you to save it, then using a key-value store is a good way to proceed. Another important question to ask is any business processes will need a <a href="#1611510020">multi-table transaction allowing ACID guarantees</a>? This capability is provided by relational databases. If using distributed databases, which is generally the case happens when using non-relational databases, then ensure that the business requirements do not break because of <a href="#1611510040">CAP</a> restrictions. One more note: this <a href="https://medium.com/moveax/how-postgresql-replication-works-6288b3e6000e" target="_blank" rel="noopener noreferrer">Medium post</a> describes how replication works for PostgreSQL. I would highly suggested reading it to gain an understanding of related terms discussed above.</p>
	
					<h4 id="db-vs-fs">Database vs File system</h4>
						<p id="1611508641">Consider the following question: In the <a href="#1608527531">above example of database</a>, rather than using a database, why don't I simply make a file system directory called "database", and within it I store 3 files, "watch-1" file containing data (you, Batman-movie), "watch-2" file containing data (you, Superman-movie), and "watch-3" file containing data (your-friend, Batman-movie). With this alternate design, all user data is persisted without needing to pay for a database software! So, is there any advantage of having a database over a file system? To me, the best answers for <a href="#database">database</a> vs <a href="#file-system-storage">file system</a> are mentioned in these two StackOverflow posts: <a href="https://stackoverflow.com/questions/38120895/database-vs-file-system-storage/64654674#64654674" target="_blank" rel="noopener noreferrer">here</a> and <a href="https://stackoverflow.com/questions/38120895/database-vs-file-system-storage/43910719#43910719" target="_blank" rel="noopener noreferrer">here</a>. A huge benefit provided by database software is that rather than making huge amount of small files which will eventually bring down the OS and filesystem performance, a database enables saving millions of record and without hurting filesystem performance. It also provides additional services that can be used out of the box, like having a <a href="#1611510020">transaction with ACID guarantees</a>, creation and automatic update of <a href="#1611510010">indexes</a> to improve search performance, performance optimization by using system memory to store frequently used data and relatively easier management of <a href="#db-schema">database schema</a>. For these additional and important services, it may be preferable to use a database software rather than only relying a filesystem.</p>
						
					<h4 id="cache-vs-db">Primary storage database vs secondary storage database</h4>
						<p id="1644370267">As discussed in earlier sections on <a href="#memory">primary storage</a> and <a href="#secondary-storage">secondary storage</a>, the decision to use one versus the other is an exercise in cost-benefit analysis. Similar logic also applies when deciding between using a primary or secondary storage for database. In-memory databases and caches are very fast, but for the same price, they can hold much less data compared to databases using the secondary storage. Hence, if the business revenue gain from serving data fast surpasses the expense associated with using an in-memory database, then it becomes worthwhile to invest in them. One use case for having only in-memory database is when performing a <a href="/productionizing/productionizing-backend-development/glossary/testing.html#functional-test">functional test</a>, where setting a databse on secondary storage would simply hurt the testing speed in setting up the data for each test, retrieving data during the test, and clearing the data after each test.</p>
	
				<h3 id="db-design-concepts">Database design concepts</h3>
				
					<h4 id="db-schema">Database schema</h4>
						<p id="1611510000">The first step towards database design is to identify the structure of the information to be held in the database, also called the <a href="https://en.wikipedia.org/wiki/Conceptual_schema" target="_blank" rel="noopener noreferrer">conceptual data model</a>. Using the business requirements as inputs, this step identifies the real-world entities with which the business will interact, and the relationships and constraints among/within entities. <a href="/productionizing/productionizing-backend-development/glossary/architecture.html#ddd">Domain driven design</a> is applied in this stage. In the next step, the conceptual data model entities are further developed and the model is either <a href="#normalization">normalized</a>, or <a href="#denormalization">denormalized</a> depending on the business needs. Individual properties associated with each entity is identified, and the relations and constrainst among/within entities is defined in terms of these columns. This is the <a href="https://en.wikipedia.org/wiki/Logical_schema" target="_blank" rel="noopener noreferrer">logical data model</a>. Finally, database specific commands are used to create tables, thereby, realizing the logical data model. The <a href="https://en.wikipedia.org/wiki/Database_schema" target="_blank" rel="noopener noreferrer">database schema</a> is this final structure that mirrors the logical data model and is described in a formal language supported by the database. At this point, the database is ready to receive user data.</p>
				
					<h4 id="normalization">Database normalization</h4>
						<p id="1611407572">See article about database normalization on <a href="https://en.wikipedia.org/wiki/Database_normalization" target="_blank" rel="noopener noreferrer">Wikipedia</a>. Database normalization is the process of structuring the data in a manner that brings out various relations amongst the data pieces, eliminates data redundancy and improves data integrity. Bringing out the relations helps the team (including, developers, testers, designers and managers) realize that the database design conceptual schema. Reducing data redundancy is important so that if the data is changed, then their will be just one unique place where the change needs to be made. If there is data redundancy, then all other places where the data is stored would need to be synced as soon as a change is made at any one place, and this is cumbersome and error prone. While there are use cases for using a denormalized design, it is generally the case that a normalized design should be used. Also, it is a good practice to start with a normalized design, confirm that it matches the expected conceptual model, and then denormalize it to meet the business requirements.</p>
						<p id="1613523454">The <a href="https://en.wikipedia.org/wiki/Database_normalization" target="_blank" rel="noopener noreferrer">Wikipedia</a> article is a great reference to understand about normalization, and particularly helpful is the <a href="https://en.wikipedia.org/wiki/Database_normalization#Example_of_a_step_by_step_normalization" target="_blank" rel="noopener noreferrer">example</a> section showing how to achieve different normal forms. Rather than repeating the same information and not doing a good job at it in a misguided attempt to shorten this important and length discussion, I strongly encourage the readers to refer to the article. In here, I would like to provide an alternate understanding of the normal forms. I did not see the "normal forms" being presented in this manner anywhere else, so there's a slight risk that I may be incorrect, or maybe I don't know of a proper reference. It does sound correct to me, but I ask readers to exercise caution. So, here it is: Using the <a href="https://en.wikipedia.org/wiki/Database_normalization#Example_of_a_step_by_step_normalization" target="_blank" rel="noopener noreferrer">example in the Wikipedia article</a>, application of 1NF can be seen as defining a "data" row in a database as something that should map to a "single" real world object and not have multiplicty within it. If some kind of data-multiplicity needs to be modeled, then that should instead be done by using a foreign key relation. With every real world object, some features can be defined that make it unique. For example, the name of this book "Productionizing backend development" is unique. But what if I write a new edition of same book? Then the combination of book name and its edition is unique. What defines a real world object as unique depends on the object and how it is used in context of business application, but there will always be some unique aspect to data. 2NF form can be seen as implying that other columns for a give database table row must relate to the "whole" unique combination. So, if (name, edition) defines the uniqueness of a book, then other columns in book table except the name and edition, must relate to the (name, edition) value, and not just to name or to edition alone. 3NF can be seen as making 2NF stricter and implying that all other columns for a database table row that don't form part of the unique combination, they must only relate to the unique combination and not have any relation to any other columns. Thus, except the columns used in the unique combination, other columns for a row can take any possible value. This helps in better identifying the features of real world object that makes it unique and different from others. 4NF onwards the focus not goes to the unique combination. 4NF can be seen as requiring that the unique combination cannot be decomposed further into independent tables. 5NF makes this stricter and requires that the columns in unique combination should not have any relations; Each column of unique combination can take any value possible. As mentioned in the Wikipedia article, a database table in 5NF is one that is truly "normalized". Going to 6NF is based on realization that every column can itself be changed to a 1-column table (along with an extra id rown in each table), and the data-record table simple contains foreign key to these extremely slim tables. For a record-based design, as is always the case with the <a href="/productionizing/productionizing-backend-development/glossary/req-resp.html#oltp-olap">OLTP</a> requests, this creates unnecessary performance  overheads. I agree with the article's suggestion of going up to 5NF, i.e. fifth normal form, when designing database schema.</p>
						<p id="1613709139">To highlight an important point that was quickly mentioned above and wasn't emphasized more: <strong>When designing your tables, always seek to identify the combination of fields in a record that make it unique.</strong> It may not be always possible, but that's for very very few cases, but much more often than not, it should be possible to do so. Since real world data almost always have a unique reason on why it is made, having a unique combination in a data record is a way of acknowledging the cause for creating the data. This also aligns with one of the main goals of database normalization which is to remove data redundancy. An additional benefit of doing so is that it provides stability under concurrent request processing, i.e., if multiple requests comes to server at same time to add same data, then only the first of those requests will get processed. Any subsequent ones will fal because the database will report failure of uniqueness constraint since a record with intended data already exists in the database.</p>
				
					<h4 id="denormalization">Database de-normalization</h4>
						<p id="1644374821">A similar reason to that presented <a href="#rdbms-vs-nosql">earlier</a> for choosing between a relational vs a non-relational database also applies when considering a normalized vs a denormalized database design. My suggestion is to always start with a normalized design, to confirm that it matches the expected conceptual model. A normalized design will have various join operations which hurt performance; But also note that trying to depart from the normalized design will require extra effort on the software to ensure that the data integraity is maintained, and that also hurts performance. Denormalizing is the processing of weighing these two competing choices and concluding that for the business cases of interest, it is a better compromise to break off from normal structure and fine-tune the database table design to those certain business requirements only. This said, note that more often than not, businesses should use a normalized design and not use a denormalized design.</p>
						
					<h4 id="transaction">Transaction</h4>
						<p id="1611510020">A <a href="https://en.wikipedia.org/wiki/Database_transaction" target="_blank" rel="noopener noreferrer">database transaction</a> refers to a logical unit of work, made up of one or multiple operations, performed on one or multiple tables in a database. This operations in a transaction can include either only reading data from database, or making changes to database entries, or do both read and write operations. A database transaction, by definition, must be atomic (it must either complete in its entirety or have no effect whatsoever), consistent (it must conform to existing constraints in the database), isolated (it must not affect other transactions) and durable (it must get written to persistent storage, and if there is any outage after the trnsaction, then the modifications applied during the transaction must not get undone). These four properties are commonly referred using the acronym of <a href="https://en.wikipedia.org/wiki/ACID" target="_blank" rel="noopener noreferrer">ACID</a> properties. Atomicity and durability properties of a transaction enables data reliability in recovering from failures, i.e. if the database stops working and is then restarted, then the data in the databse would represent a transaction as either been applied or not applied in its entirity. Atomicity and durability are primarily enabled via use of a <a href="https://en.wikipedia.org/wiki/Write-ahead_logging" target="_blank" rel="noopener noreferrer">write ahead log</a>. The isolation property enables having a reliable outcome as a result of concurrent read and/or write operations done "concurrently" on the database; That being said, a fully concurrent safe processing is also slow on performance and so, SQL standard itself allows for different isolation levels having corresponding performance behavior, with <a href="https://en.wikipedia.org/wiki/Isolation_(database_systems)#Read_uncommitted" target="_blank" rel="noopener noreferrer">uncommitted reads</a> being very quick but allowing for unsafe data read, and <a href="https://en.wikipedia.org/wiki/Isolation_(database_systems)#Serializable" target="_blank" rel="noopener noreferrer">serializable processing</a> being slowest and strongest among the isolation levels. Note that the default behavior of almost all database is to NOT perform the transaction with the strongest isolation guarentee. Within a transaction, isolation in achieved by using read/write locks at table or page or row level; It can also be simulated on the database record by either using optimistic locking or pessimistic locking depending on the use case (locking reference: <a href="https://stackoverflow.com/questions/129329/optimistic-vs-pessimistic-locking" target="_blank" rel="noopener noreferrer">a StackOverflow post</a>, <a href="https://convincedcoder.com/2018/09/01/Optimistic-pessimistic-locking-sql/" target="_blank" rel="noopener noreferrer">a blog post</a>).</p>
						<p id="1612128885">A really good reference to understand about how ACID guarantees are preserved for a transaction is <a href="http://web.archive.org/web/20120827100207/http://www.cbare.org/writing/Transactions/transactions.html" target="_blank" rel="noopener noreferrer">here</a>, and the link was itself obtained from <a href="https://stackoverflow.com/questions/3466632/database-transactions-how-do-they-work" target="_blank" rel="noopener noreferrer">this StackOverflow post</a>. A "transaction manager" is the central component that enables transaction processing. A database may itself be using a transaction manager to enable changes being done on it to be executed as a transaction. Some web applications may also use a different type of transaction manager to coordinate a <a href="https://en.wikipedia.org/wiki/Distributed_transaction" target="_blank" rel="noopener noreferrer">distributed transaction</a>, which can include one or more databases, or message queues, or any other components enabling transaction. These distributed transaction managers leverage a different mechanisms like <a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol" target="_blank" rel="noopener noreferrer">2 Phase commit</a> or a more robust <a href="https://en.wikipedia.org/wiki/Three-phase_commit_protocol" target="_blank" rel="noopener noreferrer">3 phase commit</a> to ensure that the corresponding changes are applied in all components involved in the distributed transaction.</p>
						<p id="1612131223">Heads up: The comments in this paragraph is something that I stand by; However, it is not something that most of the articles on internet will agree with. So, please take it with extra skepticism. Note that above paragraphs mention ACID as a property of a transaction and not of database. This viewpoint means that both a relational and non-relational database can have a transaction and satisfy ACID constraints. To me, it is not that a non-relational database cannot have ACID transaction; But, it is the scope of ACID behavior in a transaction performed by non-relational database that is very different and reduced compared to the transactions done in relational database. A relational database can provide atomicity spanning over multiple rows in multiple tables. However, since non-relational databases can effectively be viewed as a key-value store (discussed <a href="#rdbms-vs-nosql">above</a>), so, the best atomicity that a transaction on a non-relational database can guarantee is only over a single key! Since every entry and every table in a non-relational database is designed to be independent, so the concept of "consistency" does not exist; There are no relations between any two tables that need to be checked. Also, for each key, a single value is stored (which can be a complex structured object, but is still one unit from the perspective of the non-relational database), and so, there is no concept of consistency check for that value. Isolation is a tricky topic in transaction and even relational databases provide varying degree of isolation. It comes down to how the database, both relation or non-relation, handles concurrent read and write operations; But there's nothing preventing a non-relational database to provide strong isolation guarantees. Non-relational databases can guarantee durability by persisting data, at least in the write-ahead log. Hence, my point, that even non-relational dtaabases can have transactions with ACID properties, because, as I said <a href="#1611510020">earlier</a>, a transaction must, by definition, have ACID property. It is just the scope of ACID behavior that is different between the two. This idea is also discussed in <a href="https://stackoverflow.com/questions/2608103/is-there-any-nosql-data-store-that-is-acid-compliant/22105320" target="_blank" rel="noopener noreferrer">this StackOverflow post</a>. All above being said, I do notice 2 biggest source of confusion in most of the online discussions on non-relational databases and transactions. First, the discussion mix the concept of ACID properties of transaction with discussion of <a href="#cap">CAP theorem</a> (discussed next), which, to me, is not a correct path to follow. Due to the two concepts getting repeatedly mixed when discussing non-relational database,this question is revisited under the discussion on CAP theorem. Second, a transaction must not be confused with a batch operation. A batch operation is where a sequence of commands are issued to the database that can be executed in multiple transactions. Generally, I've noticed non-relational database providers provide the option for batch operations (For example: <a href="https://docs.datastax.com/en/cql-oss/3.3/cql/cql_using/useBatch.html" target="_blank" rel="noopener noreferrer">Cassanda</a> and <a href="https://docs.mongodb.com/manual/reference/method/Bulk/" target="_blank" rel="noopener noreferrer">MongoDB</a>). The batch operations are designed to behavior similar-looking to a multi-change transaction of relational database; And they are also aggresively marketed as behaving like multi-change transaction of relational database. However, this similarity is not exact and is dependent on how the non-relational database is designed. Hence, the interchangable use of batch commands as equivalent of relational database transaction ambiguate the concept of a transaction as a logical unit of work having ACID behavior.</p>
						
					<h4 id="cap">CAP theorem</h4>
						<p id="1611510040">The <a href="https://en.wikipedia.org/wiki/CAP_theorem" target="_blank" rel="noopener noreferrer">CAP theorem</a>, also known as Brewer's theorem, states that it is impossible for a <strong>distributed</strong> data store to simultaneously provide more than two out of the following three guarantees: Consistency (i.e., every read receives the most recent write or an error; Also note that this is NOT the "C" in ACID property of a <a href="#transaction">transaction</a>, as mentioned in this <a href="https://en.wikipedia.org/wiki/Consistency_(database_systems)#As_a_CAP_trade-off" target="_blank" rel="noopener noreferrer">reference</a>), Availability (i.e., every request receives a non-error response, but the response received may not correspond to the most recent write), and Partition tolerance (i.e., the system continues to operate despite an arbitrary number of messages being dropped or delayed by the network between nodes). Since in the real world cases, systems partition failures are rare, so the design generally comes down to identifying whether sacrificing consistency or availability would be in best interest of the business use case.</p>
						<p id="1612134800">As discussed <a href="#nosql-db">previously</a>, the primary use case for using a non-relational databases is to achieve a quick store or retrieval of high volume data coming at very high rate. For this reason, the data is stored as a key-value pair, and so, a non-relational databases can effectively be viewed as a key-value store (discussed <a href="#rdbms-vs-nosql">above</a>). To accommodate this business use case, non-relational databases are designed so that it can be scaled out horizontally in a very quick and easy manner; And, it is because of the "distributed" nature of non-relational databases, it gets subjected to the CAP theorem. What is unfortunate though is that because non-relational databases are generally used in settings that make them subjected to CAP constraints, it has becomes a norm to say that non-relation databases, by design, are constrained by CAP theorem, which is wrong! If a non-relational database is operated on just one machine, then it is not a distributed database and so, it will not get subjected to CAP theorem. What is even more unfortunate is that form some reason, it is justified that since non-relational database are subject to CAP theorem, so they don't provide ACID guarantees - which is a totally different thing, at least to me (see <a href="#1612131223">above</a>). On the other hand, even relational databases can get subjected to CAP constraints if multiple of them are connected together as distributed data store. While distributed transaction manager can do their best to ensure that a distributed transaction spanning multiple relational databases is executed using 2-phase commit protocol, these distributed transactions have no partition tolerance and it is hard to recover from failures if one or more database(s) are not available. Distributed transactions are also slow to execute and don't match with the business use case for using non-relational databases, i.e., be able to handle a very high velocity data and be robust enough to respond even if some nodes fail. Hence, non-relational databases do not use 2-phase commit or 3-phase commit, and instead rely on alternate protocols like <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)" target="_blank" rel="noopener noreferrer">Paxos</a> and <a href="https://en.wikipedia.org/wiki/Raft_(algorithm)" target="_blank" rel="noopener noreferrer">RAFT</a> for any conflict resolution and to form consensus on state of the data.  <a href="https://medium.com/@predrag.gruevski/learn-by-example-how-paxos-and-two-phase-commit-differ-c9b139b700ef">This article on Medium</a> covers the difference between 2-phase commit vs Paxos, and how they are applicable to different scenarios. Finally, I want to mention about <a href="https://stackoverflow.com/questions/2608103/is-there-any-nosql-data-store-that-is-acid-compliant/3014601#3014601" target="_blank" rel="noopener noreferrer">this StackOverflow answer</a> as one of the few posts I've seen that clarifies the confusion between ACID vs CAP!</p>
				
				
				
				
				
				
				
				TODO -- define index in database design section.. it's useful for constraints, search. Differentiate between SQL vs NoSQL indexes -- latter ones are more like buckets. Update reference for index in page. Update table of contents
				
	
	<h3 id="database-performance">Database performance</h3>
					<p id="1642781296">As records are added to a database, both the read and write performance can reduce over time. The most common way to improve read performance is by adding an <a href="#1611510010">index</a> over a column of a database table. To enable storing large amounts of data while keeping the read and write operations efficient, a database table can be <a href="https://www.sqlshack.com/database-table-partitioning-sql-server/" target="_blank" rel="noopener noreferrer">"sharded" or "partitioned" into smaller units</a> that deal with the table data in a smaller range. Like <a href="https://en.wikipedia.org/wiki/Bucket_sort" target="_blank" rel="noopener noreferrer">bucket sort</a>, sharding improves read performance because only a smaller range of data needs to be searched to identify the record of interest. For example, if the movie name starts with A-N, then search in database table partition#1, else search in partition#2. So, just by the movie name, we'll know that the entry for "Batman-movie" (watched by you and later, by your friend) is in partition#1, and the entry for Superman-movie watched by you is in partition#2. It is also possible to add a "replica" of entire database, so that read queries can be handled by different replicas, reducing the overall query load seen on one server. Replicas also provide fail-safe against data loss if for any reason the data in the database is corrupted.</p>
					
					
					
					<!-- TODO
					
			
			don't change id once it is set
			As much possible, always have a unique combination based on data fields.. unless there are some cases where it is not possible: link to part-1/entity in backend-dev
			
			
			DB:
			--Link to Glossary on Prod back dev for DB
			-- one jira ticket should result in 1 migration. on the migration file, add ticket name and briefly what it does - for easy tracking/identifying. No need to go full detail as git blame can be used to do so
			-- You can change character-set in MySQL columns.. but best to have charset as utf8mb4 — **IMPORTANT**: Not utf8.. in MySQL, utf8 is utf8mb3 (3 bytes of data). Even worse, it can drop string data — MySQL historically set around 767 bytes for indexing. Since most string columns are 255 string size, so MySQL decided that they’ll assign 3 bytes per string. So, if there is a larger data sent.. it gets dropped
			-- Discuss how RDBMS can still store semi-structured data and be denormalized!! What makes NoSQL as NoSQL is that it's a distributed map.
			
			--  Alter table: 2 things to note. Both relate to fact that “Alter table”, when executed, makes copy of original, then changes references to refer to the new table. So:
1) If trying to do multiple “ALTER TABLE” commands, best to collect all of them in a single statement t prevent performance degradation by multiple operations
2) Historically, Alter table would lock the table while alteration is being done. Recent versions have improved it by trying to queue the changes and in the mean time allowing external reads to happen.. but this is still slow!
			
			-- LIMIT command has another form that takes 2 values, 1 is offset and other is the number of entries returned - but under covers this is not performance.. as it first selects everything and then throws offset data out. Better way to paginate is to first filter using WHERE clause, and then use limit.. and then change the input to WHERE for next iteration accordingly.
			
			
			-- SELF-JOIN: table joining on itself. Good for join to get a hierarchy or time-window relation. In this case, for disambiguation, use “AS” clause
			-- See StackOverflow https://stackoverflow.com/questions/3856164/sql-joins-vs-sql-subqueries-performance — in that joins can be faster than sub select
			
			
			1) If you have, say, "N entries" out of which you want only 1 to be active at a time.. then one way is to have say an "active" field that can be true for just one entry. For all others, it should be null. The "null" isn't used in unique and so it behaves as if there's just one active at a time.
			--|---- HOWEVER, it feels like cheating and is not a portable behavior (https://stackoverflow.com/questions/20154033/allow-null-in-unique-column). A downside is that if within the group, you want to set an active value to null and some other null value to active, then you'll have to defer consistency till after transaction - which MySQL doesn't allow. So, some restrictions may come - but still, there's workaround.. use 2 transactions - if doing so, set the intermediate value to false, and change it back to null. From application perspective it should still work. Also, for the set of unique values that can be put, try to keep it limited, best if this is done on a boolean field so it can take on true/false value. 
			--|---- Another approach can be to enforce the check using optimistic or pessimistic locking. If using optimistic lock, it may help to have a top level record that defines the version.
			--|---- Use of null valued columns for group uniqueness. BUT, they will cause error if you want to change a different value in group to be true within single transaction.
			
			-- DB unique constraint in design :: Start by adding as strong of a constraint as possible.. relax later if need comes. Don't start with a weak unique constraint (i.e. one based on multiple fields rather than just a single field)
			--|---- Design it with view to enforce uniqueness of created data, hence it solves problem of race condition in creating new data - where DB raises error. 
			--|---- Does this (https://dba.stackexchange.com/questions/210949/why-does-this-query-result-in-deadlock) mean that in absence of unique constraint adding / updating 2 entries can cause deadlock!! - another reason to always keep separate numeric id
			
			--storing string, null vs empty
			-- Be careful defining cascade behavior for deletion. safest is always to disable cascade - so that if such a behavior is needed, then application specifically does so
			-- When having db model where lower table has columns that override value of column in a higher table -- then: (1) use column-name in lower table as `{high-column-name}_override` add @property named `{high-column-name}` in lower table that defines the value as using the overriden value if available else using the higher table value.
			
			
			-- UTF-8 based security issue + using utfmb4 type in MySQL:
* https://mathiasbynens.be/notes/mysql-utf8mb4
* https://speakerdeck.com/mathiasbynens/hacking-with-unicode   (See https://engineering.atspotify.com/2013/06/18/creative-usernames/  )
* https://stackoverflow.com/questions/2241348/what-is-unicode-utf-8-utf-16
			
			
			
			Advanced SQL: Get nth smallest or largest
* https://stackoverflow.com/questions/463054/sql-select-nth-member-of-group
* https://stackoverflow.com/questions/16994871/sql-is-there-any-efficient-way-to-find-second-lowest-value
* https://www.xaprb.com/blog/2008/08/08/how-to-select-the-nth-greatestleastfirstlast-row-in-sql/


SQL:
See https://stackoverflow.com/questions/24741051/order-by-before-select
-- SQL first selects all data, then orders it.. that's why "order by"
goes after "where" clause.. and that's why just in comparing "order +
limit" to get something going vs using "where".. use "where". Why? -
because SQL needs to get the entire data before it can order it.
reference: http://use-the-index-luke.com/sql/partial-results/top-n-queries
-- related: if you are trying to set some variable for each iteration,
then that will get set before the order is done. So, if you do:
    select t.id, @curRank := @curRank + 1 as rank
    from table t, (SELECT @curRank := 0) r
    order by t.id desc
.. then you won't get @curRank=1 for last t.id. The rank will be 1 for
lowest id, but now the first result will have last id and
correspondingly, highest rank

-- Followup: what happens when no "order" is specified.. don't assume
it will go by "id" as default order. See
https://www.exacthelp.com/2012/10/default-order-of-select-statement-in.html

-- SQL way of getting now number::
https://stackoverflow.com/questions/1895110/row-number-in-mysql  ---
IMPORTANT: this can even be used to reset row number for every group
change, you need to use 2 variables, and reset when the value of 2nd
variable (set in past) does not match the column being grouped on
which will be near boundary.. else set the 2nd variable to group
column value
select
    @numWithinGroup := IF(@groupColumnValue = t.group_column,
@numWithinGroup+1, 1) as number_within_group,
    @groupColumnValue := t.group_column /* NOTE: If you do this before
@numWithinGroup update, then the intent of query will fail. Order
matters */
from
    table t,
    (SELECT @numWithinGroup := 0, @groupColumnValue := '') tSupport
order by ?? <-- what order. see previous comment, best to order the
data first before starting this
			
			-->
					
	
	
	
	<p id="1611510010">
		[[[[TODO: Add <a href="https://stackoverflow.com/questions/1108/how-does-database-indexing-work" target="_blank" rel="noopener noreferrer">StackOverflow</a>]]]]
		sql vs no-sql indexes (distributed, more like a "grouping" than a search - column family; (cassandra, MongoDB)
	
		In addition to tables, columns, constraints and relations, the database schema defines many other terms. One important term used extensively in backend development is an "index". A <a href="https://en.wikipedia.org/wiki/Database_index" target="_blank" rel="noopener noreferrer">database index</a> is a data structure, separate from tables, that is constructed using values of one or more columns for all rows. It improves the speed of data retrieval operations on a database table by identifying the row(s) containing a particular value for the column(s). Since it is a separate structure, it costs additonal space and it also needs to be updated everytime a new row is added/deleted. They are particularly useful if the business application has more reads than writes. In relational databases, an index is automatically made for the primary key because it helps with speeding up <a href="https://en.wikipedia.org/wiki/Join_(SQL)" target="_blank" rel="noopener noreferrer">joining</a> different relations. Note that while the use of indexes is standard in relational database to achieve performance boost, its use among the non relational databases is not consistent (Reference: <a href="https://stackoverflow.com/questions/10085022/do-nosql-databases-use-or-need-indexes" target="_blank" rel="noopener noreferrer">Stackoverflow</a>). As discussed <a href="#1608529017" data-nav-id="1611200362">previously</a>, all non relational databases can be thought of as a key-value store. Their primary use case is that they'll be provided with a particular key, for which they need to return the corresponding value. This allows them to store a large amount of data and at a fast throughput rate. That being said, specific non relational database implementation may choose to provide custom utilities, one of them being the ability to create index over content of the values. Most likely, it is because the value (for a given key) is in a semi-structured form and allows creating indexes; Or, because the database is designed for use cases where the total count of individual keys won't be so large to preclude having some indexing data structure; Or because the column being indexed on will not have lot of unique values. Even when a database implementation allows creating index, it is strongly suggested to rethink if an index should be made and used for the volume and throughput of data that the application will see because doing so for non relational databases will immediately start showing up in degraded performance.
	</p>
	
	
				
				
				
				
				
				
				
		</main>
		
		<footer></footer>
		
		<script src="https://code.jquery.com/jquery-3.5.1.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
		<script type="module">
			import {onNonHomepageLoad} from "../scripts.js";
			$(document ).ready(onNonHomepageLoad);
		</script>
		
	</body>
	
</html>
