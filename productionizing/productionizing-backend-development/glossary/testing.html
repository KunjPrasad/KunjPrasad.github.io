<!--
    HTML book section: Testing related terms glossary to Productionizing Backend Development, by Kunj Prasad on Github.
    Copyright (C) 2020  Kunj Prasad

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published
    by the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-->
<article>
	<h2>Testing related terms</h2>
	<p id="1610856118">This page lists the various terms related to testing of a software application. This isn't an exhaustive list but only contains terms that I feel are of most importance. For a more detailed lists of different tests, see this article at <a href="https://www.atlassian.com/continuous-delivery/software-testing/types-of-software-testing" target="_blank">Atlassian</a>. Tests are an integral part of software development because they give confidence in code implementation as being bug free and covering all of the expected code development requirements. It is exteremely useful during code review, or to identify code as not implementing certain required features, or for a new developer reading the code for the first time and trying to understand its intent. Unlike the name for a class method, a unit test method name can be long, and generally, it is always long to convey sufficient information about the feature being tested and the expected behavior of the test. <a href="https://stackoverflow.com/questions/155436/unit-test-naming-best-practices" target="_blank">This</a> is a good post on StackOverflow that discusses the naming convention for unit tests. Realize that when making tests, one must not just test that an expected behavior is observed, but also that unexpected behaviors raise exceptions, or disallow processing (i.e., negative tests).</p>
	<p>Thankfully, there isn't much that can go wrong in writing tests as long as some of the basics of testing are covered. This book does not cover all of the terms because related details can easily be obtained from basic search. Nonetheless, it is important to be aware of these terms and what they mean. Heads up, beyond unit and functional test, there may not be whole lot of consensus on definition of other tests. My suggestion would be to focus on what a test does and why it is important, rather than on what it is named, and then go with the name used by the team. Another important disclosure: this chapter covers "testing" related terms and not "<a href="#1608686638" data-nav-id="1608344358">application monitoring</a>" related terms. It's best if the code for application monitoring is not covered with tests, else the tests can quickly become very complex to keep up with all the monitoring data getting captured at various locations in the code.</p>
	
	<nav class="article-toc">
		<h3>Table of contents</h3>
		<ul>
			<li><a href="#1608660132" data-nav-id="1608344347">Static code analysis</a></li>
			<li><a href="#1608654390" data-nav-id="1608344347">Code coverage</a></li>
			<li><a href="#1608654300" data-nav-id="1608344347">Unit test</a></li>
			<li><a href="#1608654990" data-nav-id="1608344347">Functional test</a><ul>
				<li><a href="#1608655325" data-nav-id="1608344347">Test data provider</a></li>
				<li><a href="#1608655586" data-nav-id="1608344347">Background job test</a></li>
				<li><a href="#1608656300" data-nav-id="1608344347">Third party api test</a></li>
				<li><a href="#1619215806" data-nav-id="1608344347">Unit test vs Functional test</a></li>
			</ul></li>
			<li><a href="#1608656723" data-nav-id="1608344347">Integration test</a></li>
			<li><a href="#1608659343" data-nav-id="1608344347">Code review</a></li>
			<li><a href="#1608657637" data-nav-id="1608344347">End-to-end test</a></li>
			<li><a href="#1608658136" data-nav-id="1608344347">Load test</a></li>
			<li><a href="#1610066426" data-nav-id="1608344347">Test-driven development, or TDD</a></li>
		</ul>
	</nav>
	
	<h3>Static code analysis</h3>
	<p id="1608660132"><a href="https://en.wikipedia.org/wiki/Static_program_analysis" target="_blank">Static program analysis</a> is the analysis of computer software that is performed without actually executing programs. It is is usually applied to the analysis performed by an automated tool. This is in contrast with dynamic analysis, which is analysis performed on programs while they are executing. A primary benefit of using static analysis tools is that it discovers bugs before they are released into production. Some examples of static analysis tools are formatters, linters and static vulnerability analyzers. Formatters automatically style code to improve readability and consistency without modifying how code is executed. Linters look for <a href="https://en.wikipedia.org/wiki/Code_smell" target="_blank">code smells</a>, defects and can also detect some bugs. Static vulnerability analysis tools warn you if you are using a package version that has known security vulnerabilities. Its execution can be integrated within the software development workflow via the pre-commit hooks, for example: <a href="https://levelup.gitconnected.com/how-to-run-eslint-using-pre-commit-hook-25984fbce17e" target="_blank">running ESLint over Javascript code during commit in Git</a>, <a href="https://towardsdatascience.com/ci-cd-by-example-in-python-46f1533cb09d" target="_blank">configuring static analysis for Python</a>.</p>
	
	<h3>Code coverage</h3>
	<p id="1608654390">A metric closely asociated with code testing is "code coverage". See article about code coverage on <a href="https://en.wikipedia.org/wiki/Code_coverage" target="_blank">Wikipedia</a>. It is the percentage of code that has been tested by unit tests. While a high code coverage does not necessarily means that the application is bug-free (..and that's why other tests also exist, as mentioned below), a low coverage does erode confidence in ability of the code to be bug-free. From experience, I notice that aspring for a 85% or better of code coverage is a good starting point. Code coverage further breaks into 2 parts: line coverage and branch coverage. Branch coverage includes tests covering the ranched code execution, like, loops, if-else, switch-case, exception, etc.</p>
	
	<h3>Unit test</h3>
	<p id="1608654300">See article about unit testing on <a href="https://en.wikipedia.org/wiki/Unit_testing" target="_blank">Wikipedia</a>. In writing a code, many public methods get defined. To put simply, unit tests are to test that all the public methods in the code are behaving as expected. These tests "mock" out any dependency objects and public methods used within the code being tested and focus on a small section of the code for testing. It may also use advanced mocks, like, mocking system methods (getting system date, etc.) because even these are external dependencies to the code being tested. The <a href="https://docs.microsoft.com/en-us/visualstudio/test/unit-test-basics?view=vs-2019#write-your-tests" target="_blank">AAA (Arrange, Act, Assert) pattern</a> is a common way of writing unit tests for a method under test. The Arrange section of a unit test method initializes objects and sets the value of the data that is passed to the method under test. The Act section invokes the method under test with the arranged parameters. The Assert section verifies that the action of the method under test behaves as expected.</p>
	
	<h3>Functional test</h3>
	<p id="1608654990">See article about functional testing on <a href="https://en.wikipedia.org/wiki/Functional_testing" target="_blank">Wikipedia</a>. Functional testing is used to verify that a user interacting with the web application sees an expected response. So, this testing occurs on the request/response level. Almost all web application development frameworks also provide testing utilities to set up a mock server to which requests can be made as if done by a real user. The mock server processes this request and returns a response. The test compares the returned response to verify if it is matches the expectation. To facilitate this testing, the utilities also provide or allow adding mock databases. Unlike the unit test, some functional behavior can be more involved and continuing to use the AAA (Arrange, Act, Assert) pattern may not always apply. Even in such cases, one should aim to keep individual tests scoped to smallest possible independent feature within the application. For example, testing of a "cash transfer" feature between 2 bank accounts should continue to work for multiple times as long as the transferring account has sufficient balance. Here, testing the "...for multiple times" requirement phrase requires multiple Act, Assert steps before the final failure due to insufficient balance.</p>
	
	<h4>Test data provider</h4>
	<p id="1608655325">Since functional tests aim to mimick a user interaction as closely possible, it is necessary that the test data added in database also mirrors exactly to what it might be in a real use case. Hence, it is a good idea to use a centralized data provider that prepares consistent and correct data for each functional test. However, depending on the overall business process, there may be one or more of such providers.</p>
	
	<h4>Background job test</h4>
	<p id="1608655586">The complete web application may involve background processing in addition to handling web requests from users. If these tasks modify database entries made in some previous request, or prepare data without which future requests may fail, then they have an indirect interaction with the user and so, they must be tested. Testing of these tasks may require making custom test utilities that simulate as if the background task was run, or actually run them on the mock test server. Test assertions must be made on application state (i.e., most likely, database entries) both before and after the task was run.</p>
	
	<h4>Third party api test</h4>
	<p id="1608656300">If the web application makes a third party api call, either as part of a request processing, or from a background task, then such behaviors of the web application must also be tested. Testing third party integration most likely will require making custom class to mock the actual api being used. Testing may involve either verifying that a call was made to these APIs. If making a call to these APIs can also cause a change in application state (i.e., most likely, database entries), then test assertions must be made to verify the behavior. It may also be the case that these third party api calls are being done within the background tasks. In this case, the test must invoke the background task and verify the effects of third party api call.</p>
	
	<h4>Unit test vs Functional test</h4>
	<p id="1619215806">Since unit tests focus on a small code section, they can be very useful in identifying the location of bug, if one is found. However, for same reason, any code rearrangement or refactor can end up causing the tests to become obsolete and require having new unit tests coded. On the other hand, functional tests mimic a user request and whether it is causing an expected response to be returned back. These tests are really helpful when refactoring code because it instills confidence that the end user will not get adversely affected by the change. However, the down side is that they do not identify where in code the bug occurred, or also, if there are 2 bugs that are compensating each other! Since unit tests reside close to the codebase than functional tests, it comes down to the developer to write proper unit tests. For functional tests, since it resides closer to business requirements, it is possible to have 2 people work simultaneously, a developer generating the code, and a tester that is independently adding tests based only on ticket requirements. The downside is that the functional tests won't cover if the code has been written with poor design that can be hard to maintain or refactor in future.</p>
	<p id="1619216563">Above said, one must not attempt to view unit or functional test as being more rigorous or complete than the other.Ideally, every line of code in a codebase that does not contribute to observability must be testable. I've sometimes seen statements like "unit test can be more rigorous than functional test", which, to me, translates as "I'm going to add more code features than needed and then write unit tests for it", or, "I am not not going to write functional tests for certain features", and both of these are wrong approaches to testing. Personally, I prefer functional tests over unit tests because at the end of day, it's about the business being able to sell a product with which customers can interact, and, the functional tests verify that the customer interaction is not breaking; And use <a href="#1608659343" data-nav-id="1608344347">code reviews</a> to ensure that proper coding designs are being used. A word of caution if you're planning to write unit tests, just like you won't break a single user request in smaller portions so that it improves testing (because if you do so, you may irk the users that they now have to make extra calls), similarly, you shouldn't just break a public method so that the individual portions can be tested. A good rule of thumb is that if you feel comfortable adding a a method in some interface definition (Reference: <a href="https://docs.oracle.com/javase/tutorial/java/concepts/interface.html" target="_blank">interface, in Java</a>), then it can be tested.</p>
	
	<h3>Integration test</h3>
	<p id="1608656723">In real life, the interaction of a user with a web-application will never be restricted to just a single request. The data exchanged between user and web application in some request will also get directly or indirectly exchanged in some different call. Or, maybe, it opens or closes future interaction cases between the user and the business application. The simplest example is that a user may be not be allowed to access web application without having a profile. After a profile is made, they may be allowed access to only some requests. When their authorization status is changed, they can then access more requests. And if their profile is suddenly deleted, they will again be unable to access the application. An integration test can be seen as a multi-functional test intends to perform a sequence of calls to cover a business processing chain and verify that each step works as intended. Due to the nature of these tests as being defined on workflow, these will hardly conform to the AAA (Arrange, Act, Assert) pattern used for unit and functional tests. For these tests, it is beneficial to only test the high-impact workflows which generally center around "happy path", i.e. if the user gives correct data, then the server return with correct and expected response over the sequence of calls forming the workflow, rather than testing fringe conditions that will have a small business impact.</p>
	
	<h3>Code review</h3>
	<p id="1608659343">At this point of software development, the developer would have added all the tests than can be made via coding. The subsequent set of tests are done over the code deployed on server(s) that mimick as if they are like production, but aren't open to public users. The last testing that may happen before code gets pushed further is the code review stage. Unlike previous tests, this is more qualitative in nature, where team members go through the newly added code to identify possible bugs, missed behaviors, adherance to team standards and best practices, etc. It also provides a quick venue for other developers to keep pace with changes occurring at a difference place in code, and to improve their coding skills through discussion with others. It can suffer from a few drawbacks like peers may not be fully vested in doing a review and may sign off of the code, or maybe a member's opinions are disregarded as non-conforming to majority opinion, or multiple back and forth code changes extending the time-gap between initial code completion and its subsequent deployment. In both these cases, it is not the code review process that is itself bad, but it is something the team that must discuss on how to overcome to make the code review process more productive in achieving its goal, i.e. better and business-goal driven code.</p>
	
	<h3>End-to-end test</h3>
	<p id="1608657637">The simplest way to think of an end-to-end testing is as an integration test, but without any mocks. These tests are run on actual deployed software application, actual third party api and background task. Additional effort is needed to ensure that database has entries which help in doing the end-to-end testing but which do become accessible to the user. These are usually done in a quality check environment to ensure that the actual web application, without any mocked tests and components, works as intended. When a product is getting deployed for the first time, it may be useful to do this test once in production environment before opening the product to users. Like <a href="#1608656723" data-nav-id="1608344347">integration tests</a>, it is suggested to only focus on high-impact workflows within these tests.</p>
	
	<h3>Load test</h3>
	<p id="1608658136">See this article about load testing on <a href="https://en.wikipedia.org/wiki/Load_testing" target="_blank">Wikipedia</a>. Load test involves simulating an actual request load from expected count of different users to the system, and to then verify if the system behaves as expected. The metric of most importance from a business viewpoint is whether the latency in serving the response is below a maximum target, and if the environment can handle the requests in expected manner. Preparation for load test involves creating a testing environment with similar count and specification of server as would run in production environment. The group of servers that emulate users should be such that they are able to simulate multiple users making simultaneous request to test server without themselves getting limited by context switching. Also, the network latency between these user-emulating servers and the one getting load tested should be considered when analyzing the results. As part of test result analysis, it should be verified the servers getting load tested have low latency in responding back and also have optimal cpu and memory usage, while returning expected successful response. Of particular importance is the fact that this the only class of test that can identify concurrency related bugs (like, race conditions in code, or third party api, or any other connection causing unexpected behavior) which would otherwise not show up in any other tests. While load tests can be skipped by new business because they will likely not see a huge workload for some time, it is an absolute must for important web applications relied on by many.</p>
	
	<h3>Test-driven development, or TDD</h3>
	<p id="1610066426">An important term related to software testing is <a href="https://en.wikipedia.org/wiki/Test-driven_development" target="_blank">Test-driven development, or TDD</a>. It is not a type of testing, as discussed previously, but is a way of thinking about adding tests within a code. It suggests convertingn software requirements for a task to corresponding test cases before the task to implement the features begin, and tracking all software development by repeatedly testing the software against all test cases, marking the task as complete when all tests are successfully passed. This is opposed to software being developed first and test cases created later. The motivation for doing so is that unlike the actual code, it is much easier to write functional and integration level tests based on the requirements of the task since the tests are written against user request and expected response. Also, it becomes much easier to identify how much of the overall development effort is pending or if there's a particular thorny issue in the eature being developed that is slowing down the development. This can be done by simply looking at failing test cases. Since the first steps in feature development involves adding test cases, it keeps out personal bias and need to push out a feature that may prevent a developer from thoroughly testing the feature against all edge cases.</p>
	<p id="1610066882">Despite its advantages, there are also cons of adopting TDD. The primary con is that if same developer is writing the code and also the test cases, then there will always be a bias, regardless of what happens first. Hence, best use of TDD comes if two developers can simulatenously profress on a feature: one of them writing the code and other writing the tests. This ensures that at a later time when the code is run on test, then the developer can get an unbiased feedback by looking at failing tests if certain functions have not been added. For this to happen, the coding requirements must have been solidified before any development begins. However, in real world, this is not always assured. As development proceeds, new issues might be found, or new interactions between different business services may be identified that need handling. Maybe the structure of request and response body isn't defined when the coding started, or, maybe the development is moved to code branch for a separate ticket. It may also be the case the feature being developed is experimental in nature and likely to change in future. In this case, TDD doubly hurts because it takes developer time away from feature development and later on, when the behavior is changed, then the old tests need to deleted and rewritten. TDD, by its nature, can test for positive cases and not test strongly for negative cases because feature requirements generally cover when new behavior is needed and not what's not needed. Without having any perspective of the underlying code, it is impossible to test all set of negative test cases that can arise. Also, if goal of entire exercise is to verify that code has been written properly, and meets the technical levels expected by team, and sufficient positive and negative tests have been made, then a robust code review practice is also necessary and TDD by itself isn't sufficent. So, while TDD may be a good practice, it shouldn't be used as a silver bullet.</p>
	
	<aside class="shown-individually-but-hidden-in-ebook"><i><strong>Read this article, and more, in ebook <a href="/productionizing/productionizing-backend-development/#1608344347">here</a>.</strong></i></aside>
</article>
